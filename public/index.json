[{"content":"Need to downgrade a Linode server? No longer need a large Linode plan? Not using all of that storage, RAM, or CPU like you thought you would? Maybe the workload of your Linode server has changed. In any case, you can easily downgrade the plan that you use on Linode.\nIf you are thinking about using Linode but don\u0026rsquo;t have an account yet. Take advantage of the free $100 60-day credit using this link. Plus, you’re helping me to keep creating content.\nUpgrading on Linode is even easier since Linode handles resizing the disk for you. However, when downgrading, there is just a small amount of manual work required.\nCheck how much storage you currently use.\nAre you using less storage than the plan you want to downgrade to allows?\nIf you are, resize the disk.\nNow you can downgrade the Linode plan you are on.\nIt\u0026rsquo;s not too bad and I\u0026rsquo;ll walk you through resizing your Linode step by step and then how to downgrade a Linode plan. Let\u0026rsquo;s get started.\nCheck Linode Storage Usage We first need to check that we are not using more space than the small Linode we want to downgrade to allows. In this case, we are downgrading from the 2GB Linode, which offers 50GB of storage space, to the smaller 1GB Linode which offers 25GB of storage.\nWe can check the current amount of storage that we are using by connecting to the Linode server via SSH and running the following command.\ndf -h The \u0026ldquo;-h\u0026rdquo; option will print the drive space in gigabytes so it\u0026rsquo;s easier to read. After running this command, a disk usage summary will be printed out. We are interested in this one: \u0026ldquo;/dev/sda\u0026rdquo;.\nWe can see that in our case, we are only using 7.6 gigabytes of space. So we are under the 25GB limit of the Linode plan we want to downgrade to. This means we can proceed with downgrading. If you are over the limit of the smaller plan, you will want to delete data that may no longer be needed or consider that a downgrade is not an option.\nResize Linode Storage The next step in the process is to resize the disk to match the plan we are downgrading to. In our case, this will be 25GB. Head over to the Linode dashboard for your server.\nYou will have to power off your server in order to resize the current disk. So go ahead and power it down.\nOnce your server is powered down, click the Storage link in the Linode dashboard. You should then see your disk listed along with a resize button.\nGo ahead and click on resize, then type in the new disk size, for our example this will be 25GB.\nOnce this is done, you will see a bar that will update you with the progress of the resize. Once this is finished, you can proceed with the downgrade in the Linode Dashboard.\nDowngrade a Linode Plan Now you are finally ready to downgrade or change the Linode plan that your server uses. From the Linode dashboard, click the 3 dots at the top right to drop down the menu. Make sure you are on the Linode instance that you want to change the plan for. Choose to resize from the menu.\nYou will get a popup that lists the available Linode plans, choose the one you wish to downgrade to.\nAfter starting the resize of your Linode, it may take a minute or two before you see anything happen, but soon you will see the status change to resizing.\nOnce the resizing is finished, your Linode server will be returned to the last state it was in, so it may be powered off. Go ahead and power the server on and confirm everything is working as expected, such as SSH and whatever services you were running.\nConclusion That wasn\u0026rsquo;t too bad, right? You have successfully downgraded and resized your Linode server. Upgrading is much easier, as Linode will dynamically resize the disk to be larger for you.\nHave questions about Linode? Let me know in the comments. Don\u0026rsquo;t forget to check out the Linode series if you\u0026rsquo;re interested in setting up your own Linode Linux VPS.\n","permalink":"http://localhost:1313/fix-virtual-keyboard-in-chromium-apps-in-kde-wayland/","summary":"Need to downgrade a Linode server? No longer need a large Linode plan? Not using all of that storage, RAM, or CPU like you thought you would? Maybe the workload of your Linode server has changed. In any case, you can easily downgrade the plan that you use on Linode.\nIf you are thinking about using Linode but don\u0026rsquo;t have an account yet. Take advantage of the free $100 60-day credit using this link.","title":"Fix Virtual Keyboard in Chromium Apps in KDE Wayland"},{"content":"Hypervisors are software that enable virtualization, the process of creating and running multiple virtual machines (VMs) on a single physical server. Virtualization can improve the efficiency, scalability, and security of your IT infrastructure, but choosing the right hypervisor can be challenging. In this post, we will compare two popular hypervisors: Proxmox and Hyper-V. We will look at their features, pros and cons, and use cases to help you decide which one is best for your needs.\nWhat is Proxmox? Proxmox is an open-source, Debian-based hypervisor that supports both KVM and LXC virtualization technologies. Proxmox has a web-based interface that allows you to manage VMs, containers, clusters, and backups with ease. Proxmox also has a strong community support and extensive documentation.\nIf you want a quickstart guide on installing a setting up Proxmox at home, check out our video guide. What is Hyper-V? Hyper-V is a Microsoft product that allows you to create VMs on Windows-based systems. Hyper-V integrates well with other Microsoft products and services, and offers advanced security features, such as Shielded VMs and Host Guardian Service. Hyper-V also supports live migration and load balancing of VMs.\nProxmox vs Hyper-V: Features Comparison Here is a table that summarizes the main features of Proxmox and Hyper-V:\nFeature Proxmox Hyper-V Software Type Open source Proprietary BaseOS Debian Linux + KVM Windows Server, 10, 11 Central Management Yes Yes Clustering Yes Yes High Availability Yes Yes Storage and Backup API Yes Yes Live Migrations Yes Yes VM Load Balancing Yes Yes Virtualized Networking Yes Yes GPU Passthrough Yes Yes Snapshots Yes Yes ZFS Storage Support Yes No Management Web Based, Shell Graphical Interface, PowerShell Proxmox vs Hyper-V: Pros and Cons Both Proxmox and Hyper-V have their advantages and disadvantages, depending on your specific requirements and preferences. Here are some of the pros and cons of each hypervisor:\nProxmox Pros Free to use with full features Supports both KVM and LXC virtualization User-friendly web interface Cluster management and high availability features Strong community support and documentation Proxmox Cons Steeper learning curve for users unfamiliar with Linux Limited support for Windows virtualization Less enterprise-grade support options Hyper-V Pros Seamless integration with Microsoft products and services Excellent support for Windows-based workloads Advanced security features, such as Shielded VMs and Host Guardian Service Live migration and load balancing features Multiple pricing plans and support options Hyper-V Cons Higher licensing costs Limited compatibility with older hardware configurations Less support for Linux and other non-Windows operating systems GPU Passthrough There are many cases where you may want to passthrough a GPU from the host device to your VMs. GPU Passthrough is possibility in both Promox and Hyper-V, although the process has some differences.\nProxmox GPU Passthrough To enable GPU passthrough on Proxmox, you need to have a compatible CPU, motherboard, and GPU that support IOMMU and interrupt remapping. You also need to enable these features in your BIOS or UEFI settings. Then, you need to add some parameters to the boot file of Proxmox, such as intel_iommu=on or amd_iommu=on, depending on your processor. You also need to blacklist the drivers of the GPU on the host system, so that it is not used by Proxmox. Finally, you need to add the GPU device to the VM configuration, using the hostpci option. You can find more details and examples on how to do this in the Proxmox wiki.\nHyper-V GPU Passthrough There are different methods to enable GPU passthrough on Hyper-V, depending on the version of Windows and the type of graphics card you have. Here are some of the possible options:\nRemoteFX: This is an older feature that was removed from Windows 10 and Windows Server 2019 due to a security issue. It allowed you to add a RemoteFX Video Adapter to a VM and use the host’s GPU to accelerate graphics rendering. You can still use this feature on Windows Server 2016 or earlier, or on Windows 10 version 1803 or earlier, but it is not recommended for security reasons. Discrete Device Assignment (DDA): This is a feature that allows you to pass an entire PCIe device into a VM. It works with most graphics cards that support Single Root I/O Virtualization (SR-IOV). You need to configure the VM for DDA, dismount the device from the host, and assign the device to the guest. You can find more details on how to do this here: Discrete Device Assignment. GPU Partitioning: This is a newer feature that allows you to partition off resources from your graphics card and share them among multiple VMs. It works with some graphics cards that support GPU-PV technology. You need to enable the GPU partitioning driver on the host, add a GPU partition adapter to the VM, and update the GPU driver on the guest. You can find more details on how to do this here: GPU Partitioning. Proxmox vs Hyper-V: Use Cases The best hypervisor for you depends on your use case and the type of workloads you want to run. Here are some general guidelines to help you choose between Proxmox and Hyper-V:\nChoose Proxmox if you want a free, open-source, and flexible hypervisor that supports both KVM and LXC virtualization. Proxmox is ideal for Linux-based workloads, and for users who are comfortable with Linux administration and command-line interface. Choose Hyper-V if you want a Microsoft product that integrates well with other Microsoft products and services. Hyper-V is ideal for Windows-based workloads, and for users who prefer a graphical user interface and Windows PowerShell. Conclusion Proxmox and Hyper-V are both powerful and popular hypervisors that offer a range of features and benefits for virtualization. However, they also have their limitations and trade-offs, depending on your use case and preferences. Therefore, you should carefully evaluate your needs and compare the pros and cons of each hypervisor before making a decision.\nPersonally, I have used both and while Proxmox has more features and is easy to manage from the web based interface, Hyper-V is something you will more than likey run into in the workplace. Even more common Hypervisors in the workplace are VMware ESXi and Citrix using Vitual Machine Manager.\nWe hope this post has helped you understand the differences between Proxmox and Hyper-V, and how to choose the best hypervisor for your needs. If you have any questions or feedback, please let us know in the comments below. Thank you for reading!\n","permalink":"http://localhost:1313/proxmox-vs-hyper-v/","summary":"Hypervisors are software that enable virtualization, the process of creating and running multiple virtual machines (VMs) on a single physical server. Virtualization can improve the efficiency, scalability, and security of your IT infrastructure, but choosing the right hypervisor can be challenging. In this post, we will compare two popular hypervisors: Proxmox and Hyper-V. We will look at their features, pros and cons, and use cases to help you decide which one is best for your needs.","title":"Proxmox VS Hyper-V - Which Hypervisor Should You Choose?"},{"content":"","permalink":"http://localhost:1313/2023-12-07-testpage/","summary":"","title":"testpage"},{"content":"CPU schedulers are algorithms that determine how the CPU allocates its time and resources to the processes that are running on a system. CPU schedulers are essential for ensuring that the system can perform efficiently, fairly, and responsively. Different CPU schedulers have different goals and strategies, and they can affect the performance and behavior of the system in various ways. In this blog post, I will explain why CPU schedulers are important, and compare the top three schedulers for Linux: CFS, BFS, and MuQSS.\nWhy CPU Schedulers are Important CPU schedulers are important for several reasons:\nThey can improve the throughput of the system, which is the total amount of work completed per unit of time. By choosing the most suitable process for execution at each moment, the CPU scheduler can maximize the utilization of the CPU and avoid wasting time on idle or low-priority processes. They can reduce the waiting time and response time of the processes, which are the time intervals from when a process becomes ready to execute until it starts or finishes execution. By minimizing these time intervals, the CPU scheduler can improve the user experience and satisfaction, especially for interactive and real-time applications that require timely feedback and results. They can ensure fairness and balance among the processes, which means that each process receives an appropriate share of the CPU time according to its priority, workload, and resource requirements. By enforcing fairness and balance, the CPU scheduler can prevent starvation and favoritism, and maintain the stability and harmony of the system. How to Choose the Best CPU Scheduler for Linux Linux is a versatile and customizable operating system that supports multiple CPU schedulers. The default CPU scheduler for Linux is the Completely Fair Scheduler (CFS), which aims to provide proportional and fair CPU time to each process based on its weight and demand. CFS uses a red-black tree data structure to keep track of the virtual run time of each process, which is the amount of CPU time that the process would have received on an ideal system with infinite CPUs. CFS selects the process with the lowest virtual run time for execution, and updates the virtual run time of the running and waiting processes accordingly. CFS also implements features such as group scheduling, load balancing, and cgroup integration to enhance its functionality and performance.\nHowever, CFS is not the only option for Linux users. There are alternative CPU schedulers that offer different advantages and trade-offs. Two of the most popular alternatives are the Brain Fuck Scheduler (BFS), also known as the Basically Fair Scheduler, and the Multiple Queue Skiplist Scheduler (MuQSS).\nBFS is a CPU scheduler that focuses on low-latency and responsiveness for desktop and interactive systems. BFS uses a single run queue for all processes, and selects the process with the highest priority for execution. BFS does not use any complex data structures or calculations, and relies on simple heuristics and timers to manage the processes. BFS also implements features such as preemption, deadline scheduling, and soft affinity to improve its performance. BFS is designed to work well for systems with up to 16 CPUs, and can handle up to 512 CPUs with some degradation.\nMuQSS is a CPU scheduler that is based on BFS, but extends and improves it for modern systems. MuQSS uses multiple run queues for each CPU, and selects the process with the highest priority and the lowest latency for execution. MuQSS uses a skiplist data structure to store and access the processes, which allows for faster and more efficient operations. MuQSS also implements features such as interactivity estimation, adaptive yield, and frequency scaling to enhance its performance. MuQSS is designed to work well for systems with up to 64 CPUs, and can handle up to 2048 CPUs with some degradation.\nThe choice of the best CPU scheduler for Linux depends on the needs and preferences of the user and the system. There is no definitive answer, as each CPU scheduler has its own strengths and weaknesses, and may perform differently under different workloads and scenarios. However, some general guidelines are:\nIf the user values fairness and proportionality over responsiveness and latency, and has a system with many CPUs and processes, CFS may be the best option. If the user values responsiveness and latency over fairness and proportionality, and has a system with few CPUs and processes, BFS may be the best option. If the user wants a balance between responsiveness and fairness, and has a system with moderate CPUs and processes, MuQSS may be the best option. Of course, the user can also experiment with different CPU schedulers and compare their results and experiences. Linux allows the user to change the CPU scheduler at run time, by using the chrt command or the schedtool utility. The user can also compile a custom kernel with a different CPU scheduler, by using the menuconfig or xconfig tools.\nBest Linux CPU Scheduler for Gaming There is no definitive answer to this question, as different CPU schedulers may have different effects on gaming performance depending on the system configuration, the game, and the workload. However, some general factors that may influence the choice of CPU scheduler are:\nLatency: This is the time interval from when a process becomes ready to execute until it starts execution. Low latency is desirable for gaming, as it means that the game can respond quickly to user input and events. CPU schedulers that prioritize latency over throughput, such as BFS and MuQSS, may be better for gaming than CPU schedulers that aim for fairness and proportionality, such as CFS. Responsiveness: This is the ability of the system to handle multiple processes and tasks without noticeable delays or lags. High responsiveness is important for gaming, as it means that the game can run smoothly and consistently without interruptions or stutters. CPU schedulers that balance the load and resources among the processes, such as CFS and MuQSS, may be better for gaming than CPU schedulers that favor a single process or task, such as BFS. Stability: This is the reliability and robustness of the system and the CPU scheduler. High stability is essential for gaming, as it means that the system and the game can run without crashes, errors, or glitches. CPU schedulers that are well-tested and widely-used, such as CFS, may be better for gaming than CPU schedulers that are experimental or customized, such as BFS and MuQSS. Based on these factors, some possible recommendations are:\nIf the user values low latency and responsiveness over stability and fairness, and has a system with few CPUs and processes, BFS may be the best option. If the user values high responsiveness and stability over low latency and fairness, and has a system with moderate CPUs and processes, MuQSS may be the best option. If the user values high stability and fairness over low latency and responsiveness, and has a system with many CPUs and processes, CFS may be the best option. How Do You Change the CPU Scheduler? This exact process will vary between Linux distributions and is out of the scope of this article. Generally speaking, you will use a patched Linux kernel that includes the scheduler that you want to use. For example, the zen-kernel is available and popular for Linux Gaming. The Zen kernel uses the MuQSS CPU scheduler and BFQ I/O sheduler. Another example would be the Nobara Linux Distribution which uses a customized kernal that includes the BFS scheduler and BFQ I/O scheduler.\nConclusion CPU schedulers are important for managing the execution of processes on a system, and can affect the performance and behavior of the system in various ways. Linux supports multiple CPU schedulers, each with its own goals and strategies. The user can choose the best CPU scheduler for Linux based on their needs and preferences, or try different CPU schedulers and see what works best for them.\n","permalink":"http://localhost:1313/linux-cpu-schedulers-gaming-cpu-scheduler/","summary":"CPU schedulers are algorithms that determine how the CPU allocates its time and resources to the processes that are running on a system. CPU schedulers are essential for ensuring that the system can perform efficiently, fairly, and responsively. Different CPU schedulers have different goals and strategies, and they can affect the performance and behavior of the system in various ways. In this blog post, I will explain why CPU schedulers are important, and compare the top three schedulers for Linux: CFS, BFS, and MuQSS.","title":"Linux CPU Schedulers and Why They Are Important"},{"content":"Congratulations on landing your first IT job! You must be excited and nervous at the same time. Don\u0026rsquo;t worry, you\u0026rsquo;re not alone. Many people feel overwhelmed when they start working in the IT field, especially if they don\u0026rsquo;t have a lot of experience or formal education. But don\u0026rsquo;t let that stop you from succeeding and growing in your career. Here are some tips on how to make the most of your first IT job and learn as much as you can.\nMy Background It wouldn\u0026rsquo;t be good for me to hand out tips if I didn\u0026rsquo;t experience it myself, so allow me to give you a little background on me. I started my first IT job without any formal education other than high school and only personal experience through my own experimenting with computers throughout my life.\nWhen I started this job, I was about 28 years old and working as a desktop support technician. Within the company, this was a fairly general role. I was setting up desktop and laptop computers for employees using Symantec Ghost and later Microsoft SCCM. I would also act as a middle man for off-site networking and server teams by racking and connecting servers and networking equipment. Some work with Cisco phone systems and softphone software.\nFast-forward many years, I\u0026rsquo;m still with the same company, and I\u0026rsquo;ve held various IT roles since then. Presently, I\u0026rsquo;m a solutions architect, helping the company find creative solutions using technology. I also provide expertise on a few things such as information protections tools like Microsoft Purview and endpoint management using Microsoft Intune.\nThe advice given here is based on my experience over the years and how I was able to grow my career.\n1. Take Notes This may sound obvious, but it\u0026rsquo;s very important to keep track of everything you learn and do in your job. You\u0026rsquo;ll encounter a lot of new terms, concepts, tools, and technologies that you may not be familiar with. Don\u0026rsquo;t be afraid to ask questions, but also write down the answers and explanations you get. You can use a notebook, a digital app, or whatever works best for you. Just make sure you organize your notes well and review them regularly. This will help you remember what you learned and apply it to your work.\nI have and still do make heavy use of OneNote, where I have notes going back many years, which I refer back to often. I also use a to-do list to keep track of what I\u0026rsquo;m working on and what is outstanding. This helps me stay organized as many times I will be shifting throughout the day, week and month to various different projects and tasks.\n2. Research Don\u0026rsquo;t be afraid to use the internet to research topics that run across. Whenever I would hear a new term or technology that I didn\u0026rsquo;t already know about, I would research it online to get a better understanding of it. There are plenty of online resources that can help you learn about IT topics, such as blogs, podcasts, videos, courses, books, etc. You can also use online forums, communities, and social media to ask questions and get feedback from other IT professionals. Reddit and Twitter are usually good resources, if it\u0026rsquo;s about a Microsoft topic, check out the Microsoft Learn site as well. Just be careful to check the credibility and accuracy of the sources you use.\n3. Self-learning One of the best ways to improve your skills and knowledge in IT is to learn on your own. You don\u0026rsquo;t have to wait for someone to teach you or assign you a task. You can take initiative and explore topics that interest you or are relevant to your job. You can also work on personal projects or challenges that test your abilities and creativity. This is where a homelab comes into play, exploring technologies in a safe environment like your home is a great option. Set up virtual machines and servers to explore different software, tools and solutions. Self-learning shows that you are motivated, curious, and eager to grow in your field.\nYour employer may set you up with an account for an online learning platform such as CBT Nuggets or Udemy, be sure to ask about that. If not, you can always do this on your own. If nothing else, YouTube is also a great way to learn.\nCertifications are great as well and your company will likely reimburse you for the cost once you pass. Don\u0026rsquo;t overlook these, as they can be vital to your next IT role, but they are not the end all be all either. You will want to gain some experience along with the certification.\nHomelabs are great, and I have used one a lot in my career. You can get evaluation versions of Microsoft Server, which can be used to create Active Directory servers as home. You can expand into the cloud with the Microsoft E5 Developer Program with is free or use free credits on Azure and AWS. This is just one example, if networking is more your thing, you can find decommissioned Cisco switched on eBay fairly cheap or use simulation software such as Cisco Packet Tracer.\n4. Find your niche IT is a very broad and diverse field that encompasses many different domains, such as web development, data science, cybersecurity, cloud computing, etc. You may not be able to master all of them, but you can find one or a few that suit your interests and strengths. Finding your niche will help you focus your learning and career goals, as well as make you stand out from the crowd. You can find your niche by experimenting with different technologies, taking online courses or certifications, joining online communities or events, or talking to mentors or peers.\n5. Connect the Dots Understanding how technologies connect together not only helps you troubleshoot them when something goes wrong, but it will also help you stand out in the crowd. I\u0026rsquo;ve also taken time to figure out how all the pieces fit together. Many times a solution that the company uses involves many parts, knowing how they work together is very valuable.\nConclusion These are some of the tips that can help you succeed in your first IT job. Remember that learning is a continuous process that never ends in IT. You\u0026rsquo;ll always face new challenges and opportunities that will require you to adapt and grow. But don\u0026rsquo;t be intimidated by that. Instead, embrace it and enjoy it. After all, IT is a fun and rewarding field that can offer you many benefits and possibilities.\n","permalink":"http://localhost:1313/5-steps-to-succeed-in-your-first-it-job/","summary":"Congratulations on landing your first IT job! You must be excited and nervous at the same time. Don\u0026rsquo;t worry, you\u0026rsquo;re not alone. Many people feel overwhelmed when they start working in the IT field, especially if they don\u0026rsquo;t have a lot of experience or formal education. But don\u0026rsquo;t let that stop you from succeeding and growing in your career. Here are some tips on how to make the most of your first IT job and learn as much as you can.","title":"5 Steps To Succeed In Your First IT Job"},{"content":"I\u0026rsquo;m not much of gamer but I do enjoy a few games such as Diablo and Hearthstone. Luckily, I can play these games on Linux, typically through Lutris. Today, I want to show you the process of getting Battle.net installed on Linux using Bottles instead of Lutris.\nVideo Guide If you would prefer a video guide, I have one availble on YouTube. What is Bottles? Bottles is similar to Lutris, it is an application that makes it simple for you to run Windows applications and games on Linux. This is done using Windows prefixes (think of this as a Windows installation) and allowing you have multiple Windows environments, which are called Bottles. The Bottles application is a client to manage those Bottles or Windows Environments.\nDownload Bottles Your first step in this process is to download Bottles. The easiest method and the way I install Bottles is through Flatpak. This is also the way that the Bottles creators recommend as well.\nThe Flatpak version can be used on most Linux distributions and also the Steam Deck\nBottles Flatpak\nInstall Additional Runner ","permalink":"http://localhost:1313/running-battle.net-games-on-linux-using-bottles/","summary":"I\u0026rsquo;m not much of gamer but I do enjoy a few games such as Diablo and Hearthstone. Luckily, I can play these games on Linux, typically through Lutris. Today, I want to show you the process of getting Battle.net installed on Linux using Bottles instead of Lutris.\nVideo Guide If you would prefer a video guide, I have one availble on YouTube. What is Bottles? Bottles is similar to Lutris, it is an application that makes it simple for you to run Windows applications and games on Linux.","title":"Running Battle.net Games on Linux using Bottles"},{"content":"In this article, I will guide you through the process of setting up a Synology NAS (Network Attached Storage) on Proxmox in a virtual machine (VM). This setup is often referred to as a \u0026ldquo;Poor Man\u0026rsquo;s Synology\u0026rdquo; because it allows you to create your own NAS using affordable hardware and open-source software.\nVideo Guide If you would prefer a video guide, I have one availble on YouTube. Downloading the Bootloader You have a few options for bootloaders such as the Arc Bootloader and the ARPL Bootloader. I used the Arc Bootloader, you will need to download the .img.zip file from the releases page on the Github site.\nOnce you have this downloaded, you will need to extract the zip file and upload the .img file to Promox just like you do an ISO file. If you\u0026rsquo;re not familiar with uploading an ISO, you can see that process in a previous post about setting up a Ubuntu VM on Proxmox.\nArc Bootloader\nARPL Bootloader\nCreate the Proxmox VM for Synology Next, we need to create a VM on Promox that will run our Synology NAS. We will create the base VM and then make modifications to the disks to get this working.\nVM Setup Configuration\nOS: Choose \u0026ldquo;Do not use any media\u0026rdquo; and leave the guest OS on Linux. System: Keep all of the defaults. Disks: Remove the default device so the VM has no drives. CPU: Up to you but I would suggest 2 cores minimum. Memory: 4GB Minimum Network: Keep defaults or configure as needed Importing the Bootloader Image The first step is to import the bootloader image into the VM that we just created. To do this, you need to open the Proxmox shell and locate the image file you uploaded earlier.\nTo get to the shell, click on your Promox host node on the left, then choose Shell.\nIn my case, the .img file I uploaded is located in /mnt/pve/ISO_Storage/template/iso/arc.IMG. However, it may be in a different location for you, such as CD /var/lib/vz/template/iso. Once you have located the image file, in the shell and run the following command:\nqm disk import \u0026lt;VM_ID\u0026gt; \u0026lt;image_file_path\u0026gt; \u0026lt;storage\u0026gt; Replace \u0026lt;VM_ID\u0026gt; with the ID of your VM (in this case, 107), \u0026lt;image_file\u0026gt; with the path to the arc.IMG file, and \u0026lt;storage\u0026gt; with the storage location where you want to create the hard disk. The storage location can be found in the left menu, in my case I chose ds1 which you can see in the screenshot.\nIf you go back to the VM you created and click on the hardware tab, you should now see an unused disk, which is the one you just created from the .img file.\nYou need to select this disk and choose edit from the menu at the top. Change the BusDevice to be SATA and the Cache to Write Back.\nConfiguring the Hard Disks After importing the bootloader image, we need to configure the hard disks for the Synology NAS. In my case, I have two disks that I want to add to the NAS, each are 2TB and are connected to my Proxmox server as SATA devices. To find the IDs of these disks, run the following command in the shell:\nls /dev/disk/by-id This will display a list of all the disks available in your system. Look for the disks you want to add (e.g., sde and sdf) and copy their IDs.\nNext, we need to attach the disks to the VM. Run the following command in the shell:\nqm set -sata1 /dev/disk/by-id/\u0026lt;disk1_ID\u0026gt; Replace \u0026lt;VM_ID\u0026gt; with the ID of your VM and \u0026lt;disk1_ID\u0026gt; with the ID of the first disk. Repeat this command for each disk you want to add, changing the SATA number (-sata1, -sata2, etc.) and disk ID accordingly. Sata0 is already used by the .img file you imported earlier as a disk.\nSetting the Boot Order To ensure that the Synology NAS boots from the correct disk, we need to set the boot order in the VM settings. Go to the \u0026ldquo;Options\u0026rdquo; tab of your VM, then \u0026ldquo;Boot Order\u0026rdquo;. Uncheck the existing boot options and check the SATA0 option. Move it to the top of the list and click \u0026ldquo;OK\u0026rdquo;.\nAssigning a Static IP Address This isn\u0026rsquo;t necessarily required but it is highly suggested so the IP of your Synology doesn\u0026rsquo;t change.\nTo assign a static IP address to the Synology NAS, we need to copy the MAC address of the VM. Go to the \u0026ldquo;Hardware\u0026rdquo; tab, select the network device, and click \u0026ldquo;Edit\u0026rdquo;. Copy the MAC address.\nNext, go to your pfSense server (if you have one) and navigate to Services \u0026gt; DHCP Server. Scroll down to the bottom and click \u0026ldquo;Add\u0026rdquo;. Paste the MAC address and assign an IP address and hostname for the NAS. This will ensure that the VM is assigned the same IP address every time it boots up.\nIf you don\u0026rsquo;t have pfSense, you should be able to configure this on your router, refer to it\u0026rsquo;s documentation or search online for specific instructions.\nStarting the Synology NAS Now that we have configured the VM and attached the hard disks, we can start the Synology NAS. Go to the \u0026ldquo;Console\u0026rdquo; tab and click \u0026ldquo;Start\u0026rdquo;. Wait for the VM to boot up and obtain the static IP address that you assigned.\nYou should come to the Synology bootloader options screen.\nFrom there, choose option 1 and choose the model of Synology that you want to emulate. I chose DS423+, you can choose whichever you want.\nYou will then be asked to choose a version, this is referring the the DSM (Disk Station Manager) software version. Choose 7.2 or the highest version number available.\nNext it will assess the system and let you know the number of disks that it detected, in my case it was 3. One disks is the bootloader, the other 2 are the 2TB disks I added to the VM.\nOn the next screen of the bootloader config you will have the option to select DSM extensions. These are optional.\nNext, you will be asked if you want to build the bootloader. Choose option 1 for yes and press enter.\nNow you will be asked if you want to boot into the DSM bootloader, choose yes and press enter. The VM will reboot, which take a moment. You should eventually get to a screen like the one shown below.\nAccessing the Synology NAS Interface To access the Synology NAS interface, open a web browser and enter the IP address of the NAS followed by port 5000 (e.g., http://\u0026lt;NAS_IP\u0026gt;:5000). This will take you to the Synology DSM setup page.\nOn the setup page, click \u0026ldquo;Install\u0026rdquo; and follow the prompts to set up the NAS. You will see a progress screen and the device will reboot. When it comes back up, click \u0026ldquo;Setup\u0026rdquo; and follow the prompts. You will need to provide a name for the device, create an administrator account, and set a secure password. Choose to notify you of updates and do not use automatic updates. You can skip setting up a Synology account, it typically won\u0026rsquo;t work for this setup anyways.\nOnce the setup is complete, you will be able to access the Synology DSM interface and start exploring its features. You can configure network settings, create shared folders, and more.\nConclusion Setting up a Synology NAS on Proxmox is a cost-effective way to create your own NAS using affordable hardware and open-source software. By following the steps outlined in this article, you can import the bootloader image, configure the hard disks, set the boot order, assign a static IP address, start the Synology NAS, and access its interface.\nIf you have any experiences or information about Synology NAS that you would like to share, please leave a comment below. Thank you for reading, and I hope you found this article helpful.\n","permalink":"http://localhost:1313/how-to-install-synology-nas-on-proxmox/","summary":"In this article, I will guide you through the process of setting up a Synology NAS (Network Attached Storage) on Proxmox in a virtual machine (VM). This setup is often referred to as a \u0026ldquo;Poor Man\u0026rsquo;s Synology\u0026rdquo; because it allows you to create your own NAS using affordable hardware and open-source software.\nVideo Guide If you would prefer a video guide, I have one availble on YouTube. Downloading the Bootloader You have a few options for bootloaders such as the Arc Bootloader and the ARPL Bootloader.","title":"How to Install Synology NAS on Proxmox"},{"content":" Download the ADAM Tool Here: https://github.com/adamwhiles/Azure-Device-Group-Assignment-Management-Tool/releases\nIf you have been using Intune for any amount of time, you have probably found a need at some point to find out what Intune applications, configuration profiles, etc. are assigned to a specific Azure AD group. I have found myself in this position many times and unfortunately Microsoft does not offer any built in ability to do this. Really, your only option is to go through ever app, profile etc. and see what groups they are assigned to. This is not user friendly at all.\nI present to you today, a tool that will do just that. The tool is the Azure Device-Group Assignment Management Tool, or ADAM Tool for short. The ADAM Tool allows you to input an Azure AD group and it will return the applications, configuration profiles, remediations, scripts and policies that are assigned to that group. It does this in under 30 seconds as well, saving you a lot of time.\nHow Does the ADAM Tool Work? Using the Graph API and the SDK for .NET, it collects all of the necessary date from Microsoft Intune.\nHow Do I Use the ADAM Tool? Once you have downloaded the ADAM Tool, you will need to install it using the provided MSI. Next, run the application as admin, this is only necessary for the first run configuration of the tenant ID and application ID.\nYou are going to need to create an Azure App Registration in order to get a client app ID. You don\u0026rsquo;t need to assign any permissions to the app, just create the registration and get the application ID.\nYou will also need your Azure tenant ID.\nOnce you have these and have launch the app as admin, click the settings button and insert your ID\u0026rsquo;s. After this the app will save those and close. You can now relaunch the app without being admin.\nPut the name of the group you want to search in the box and hit lookup. You will now need to authenticate with your Azure tenant. MFA and FIDO2 keys are supported, or you can use your username/password.\nThe information will being populating as it\u0026rsquo;s collected. That\u0026rsquo;s it, simple right?\nAny Plans for Future Improvements? Yes, there are plans for a few improvements.\nCollect information on app dependencies. Implement export function to export all of the data to csv or Excel. If you have ideas for other improvements, reach out and let me know!\n","permalink":"http://localhost:1313/find-apps-and-policies-assigned-to-azure-ad-groups/","summary":"Download the ADAM Tool Here: https://github.com/adamwhiles/Azure-Device-Group-Assignment-Management-Tool/releases\nIf you have been using Intune for any amount of time, you have probably found a need at some point to find out what Intune applications, configuration profiles, etc. are assigned to a specific Azure AD group. I have found myself in this position many times and unfortunately Microsoft does not offer any built in ability to do this. Really, your only option is to go through ever app, profile etc.","title":"Find Apps and Policies Assigned to Azure AD Groups"},{"content":"Maybe you have had shared hosting for a while or just signed up, in any case, now you have the desire to use NodeJS for your project. Many shared hosting providers will tell you that NodeJS is not supported on share hosting plans. Not supported doesn\u0026rsquo;t mean that it isn\u0026rsquo;t possible though.\nIn today\u0026rsquo;s guide, I will show you how to install NodeJS on shared hosting such as SiteGround. This guide may work for other share hosts as well, so give it a try and leave feedback in the comments. All you need is SSH access, which many shared hosts provide.\nStep 1: Enable SSH Enabling SSH will be different for every hosting provider but you should be able to find a guide online for doing this on your provider, if it is supported. If SSH is not supported, you will not be able to use this method for install NodeJS.\nFor SiteGround, you login to your customer portal, head to your website and you should have a \u0026ldquo;devs\u0026rdquo; section where you can generate an SSH key. SiteGround doesn\u0026rsquo;t support SSH using a password so you must generate a key and use that to connect.\nStep 2: Connect to SSH The details of how to connect to a server over SSH are out of the scope of this guide. There are countless documents already online that describe this process in detail. Nonetheless, get connected via SSH and move on to the next step.\nStep 3: Download NodeJS Now that you are connect to SSH, we can download NodeJS. You can use curl or wget to accomplish this from the terminal. As of this writing, the current LTS release of NodeJS is v18.18 which is what we will download.\nwget https://nodejs.org/dist/v18.18.0/node-v18.18.0-linux-x64.tar.xz curl https://nodejs.org/dist/v18.18.0/node-v18.18.0-linux-x64.tar.xz Next, we need to extract this file and we\u0026rsquo;ll rename the folder to make it easier to work with in the terminal.\ntar -xvf node-v18.18.0-linux-x64.tar.xz mv node-v18.18.0-linux-x64 nodejs Step 4: Use NodeJS on Shared Hosting Now that we have NodeJS downloaded on our shared hosting provider, we need to pull out the binaries for node and npm and put them in their own directory. After this we will add that directory to the path so we can use them in the terminal.\nmkdir ~/bin cp nodejs/bin/node ~/bin cd ~/bin ln -s ../nodejs/lib/node_modules/npm/bin/npm-cli.js npm PATH=\u0026#34;$PATH:~/bin/\u0026#34; You should now be able to use node and npm from your terminal. Congratulations, you now have NodeJS installed on your share hosting provider. This guide was written using SiteGround, so there are not guarantees that these exact commands or process will work with other hosting providers.\n","permalink":"http://localhost:1313/how-to-add-nodejs-to-siteground-shared-hosting/","summary":"Maybe you have had shared hosting for a while or just signed up, in any case, now you have the desire to use NodeJS for your project. Many shared hosting providers will tell you that NodeJS is not supported on share hosting plans. Not supported doesn\u0026rsquo;t mean that it isn\u0026rsquo;t possible though.\nIn today\u0026rsquo;s guide, I will show you how to install NodeJS on shared hosting such as SiteGround. This guide may work for other share hosts as well, so give it a try and leave feedback in the comments.","title":"How to Add NodeJS to SiteGround Shared Hosting"},{"content":"I recently install the latest release of Manjaro GNOME edition and when doing my typical device setup I found that OBS Studio wasn\u0026rsquo;t fully working out of the box. Luckily it wasn\u0026rsquo;t a difficult fix to get everything going and I wanted to quickly share the solution with everyone.\nOBS Install I typically install OBS as a flatpak from flathub since it tends to provide the best experience for me, so that it what I used in this new setup as well. If you don\u0026rsquo;t already have flatpak setup on Manjaro, you can checkout our guide here.\nOBS Black Screen Issue If you launch OBS and add a screen capture to your scene, you may find that only a black screen is shown instead of the desktop/window that you are expecting. If this happens to you, the fix is simple.\nIn your terminal, run the following command to install full pipewire support in Manjaro, which is what OBS needs.\npamac install --as-deps pipewire-v4l2 pipewire-zeroconf wireplumber qpwgraph manjaro-pipewire Once you have done this, restart your system and OBS should now be working and no more black screen.\nAlternative Solutions If you still see a black screen there are 2 other things you can try in order to resolve the black screen.\nSolution 1: Remove the screen capture source and re-add it again.\nSolution 2: Right-Click on the screen capture source and from the transform menu option, choose the fit to screen option.\n","permalink":"http://localhost:1313/fix-obs-studio-black-screen-on-manjaro-gnome-edition/","summary":"I recently install the latest release of Manjaro GNOME edition and when doing my typical device setup I found that OBS Studio wasn\u0026rsquo;t fully working out of the box. Luckily it wasn\u0026rsquo;t a difficult fix to get everything going and I wanted to quickly share the solution with everyone.\nOBS Install I typically install OBS as a flatpak from flathub since it tends to provide the best experience for me, so that it what I used in this new setup as well.","title":"Fix OBS Studio Black Screen on Manjaro GNOME Edition"},{"content":"One of the noticeable drawbacks when moving from Config Manager (SCCM) to Intune is the lack of device collections based on software installed on endpoints. Like many other things in Intune, this can be overcome with a bit of creativity and PowerShell scripts.\nThere are multiple ways you could go about this but the way I am going to show you involves running a PowerShell script on your devices that will check if the software you are looking for is installed and if it is, the script will add the machine to the Azure device group of your choice.\nFor this to work, you will need an Azure app registration that has permissions for \u0026ldquo;Device.Read.All\u0026rdquo; and \u0026ldquo;GroupMember.ReadWrite.All\u0026rdquo; in the Microsoft Graph API. Don\u0026rsquo;t worry if you are unfamiliar with that part, I will show you step-by-step how to set that up.\nStep 1 - Create an Azure App Registration Before creating the PowerShell script, we will make the Azure app registration that will give our script permissions to access the tenant and the Graph API.\nHead over to the Azure Portal and then Azure Active Directory. Once there, find \u0026ldquo;App registrations\u0026rdquo; in the menu.\nOn the app registration page, click \u0026ldquo;New Registration\u0026rdquo; found at the top. Fill in a name, this can be anything you want. The account access selection can be left as the default option unless you need something specific. When finished, click \u0026ldquo;Register\u0026rdquo; at the bottom.\nOn the next page, choose \u0026ldquo;API permissions\u0026rdquo; from the left-side menu.\nNext, choose \u0026ldquo;Add Permission\u0026rdquo;.\nIn the API popup, choose \u0026ldquo;Microsoft Graph\u0026rdquo;, then choose \u0026ldquo;Application Permissions\u0026rdquo;. You should then see a list of permissions. To make it easier, just search for \u0026ldquo;Device.Read.All\u0026rdquo; and \u0026ldquo;GroupMember.ReadWrite.All\u0026rdquo;. Click the boxes next to them to add those permissions. When finished, click the \u0026ldquo;Add permissions\u0026rdquo; button. You should now see that new permissions have been added to your Azure app registration.\nYou\u0026rsquo;ll notice there is an alert next to the permissions we just added. This is because they need admin consent. Click the button highlighted in the screenshot above to grant admin consent.\nThe last thing we need to do with the app registration is to create a client secret. We will use this secret from within our PowerShell script and it will allow us to access the API. From the left-side menu, choose \u0026ldquo;Certificates \u0026amp; Secrets\u0026rdquo;. Then click on \u0026ldquo;New Client Secret\u0026rdquo;.\nGive your client secret a description and a time to expire of your choosing. You should now see the client secret and value listed. Make note of these values in a safe place.\nAlso, head to the \u0026ldquo;Overview\u0026rdquo; page for your app registration and note the client ID as well.\nThat\u0026rsquo;s it for the app registration, we can now move on to creating the PowerShell script that will detect installed applications and add devices to an Azure AD group.\nStep 2 - Creating the PowerShell Script The PowerShell script needs to do a few things. First, we need to find out if the piece of software we are looking for is installed on the machine or not. There are many ways to do this but we will just check the registry. In this example, we are detecting if 7-Zip is installed.\n$key = Get-ChildItem \u0026#39;HKLM:\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\Uninstall\u0026#39; | Get-ItemProperty | Where-Object { $_.DisplayName -match \u0026#34;7-Zip\u0026#34; } The code above will look in the Windows Registry for an uninstall key that has a display name of \u0026ldquo;7-Zip\u0026rdquo;. If it finds a match it will be stored in the variable \u0026ldquo;$key\u0026rdquo;.\nWe can now make an if statement that is true if a match is found, inside this if statement we will have the code that adds the device to the group.\nThere are some variables that need to be set for this code to work.\nTenant - This is your tenant ID, found on the Azure AD overview page.\nGroupID - This is the Object ID for the group that you want to add devices to. Found on the Group in Azure AD.\nClientID - This is the App registration client ID that you noted in the last step.\nClientSecret - This is the client secret value. Be sure to use the value and not the secret.\nThe first thing the script does is get the device id from the device by using the \u0026ldquo;dsregcmd /status\u0026rdquo; command. It then stores this device ID to be used later in the script.\nThe next few lines are just setting headers and the body of the API request. This is necessary to get an authorization token to use the API. We then store that token to be used when we make additional API calls.\nLine 38 is going to use the device ID we collected earlier to get the Azure AD object ID of the device, we need this to actually add the device to a group.\nSkipping down to line 41, we get a list of the current members of the Azure AD group. This is so we can make sure that this device isn\u0026rsquo;t already a member of the group.\nThe last few lines set up the body of the API call and then make the API call that will add the device to the group specified.\nIf ($key) { # Define the tenant, group id from azure, graph api address and version $Tenant = \u0026#34;\u0026#34; $GroupID = \u0026#34;\u0026#34; $MSGraphHost = \u0026#34;graph.microsoft.com\u0026#34; $MsGraphVersion = \u0026#34;beta\u0026#34; # App registration values $ClientId = \u0026#34;\u0026#34; $ClientSecret = \u0026#34;\u0026#34; # Get the device Id of the current machine and set to the global DeviceId variable $RegStatus = dsregcmd /status if ($RegStatus -match \u0026#34;DeviceId\u0026#34;) { $global:DeviceId = (($RegStatus -match \u0026#34;DeviceId\u0026#34;).Split(\u0026#34;:\u0026#34;).trim())[1] } else { Write-Host \u0026#34;No device Id Found\u0026#34; exit 1 } # Set request headers $headers = New-Object \u0026#34;System.Collections.Generic.Dictionary[[String],[String]]\u0026#34; $headers.Add(\u0026#34;Content-Type\u0026#34;, \u0026#34;application/x-www-form-urlencoded\u0026#34;) # Set up request body to include app registration details $body = \u0026#34;client_id=$($ClientId)\u0026amp;client_secret=$($ClientSecret)\u0026amp;grant_type=client_credentials\u0026amp;scope=https%3A%2F%2Fgraph.microsoft.com%2F.default\u0026#34; # Authenticate and get the auth token to be stored in the AccessToken variable $response = Invoke-RestMethod \u0026#34;https://login.microsoftonline.com/$($Tenant)/oauth2/v2.0/token\u0026#34; -Method POST -Headers $headers -Body $body $response | ConvertTo-Json | Out-Null $AccessToken = $response.access_token # Add token to request header $headers.Add(\u0026#34;Authorization\u0026#34;, \u0026#34;Bearer $($AccessToken)\u0026#34;) # Get the current members of the group $GroupMembers = Invoke-RestMethod -Method Get -uri \u0026#34;https://$MSGraphHost/$MsGraphVersion/groups/$GroupID/members\u0026#34; -Headers $headers | Select-Object -ExpandProperty Value # Get the Object ID of the device using the Device ID $DeviceObjId = Invoke-RestMethod -Method Get \u0026#34;https://graph.microsoft.com/v1.0/devices?`$filter=(deviceId eq \u0026#39;$($DeviceId)\u0026#39;)\u0026amp;`$select=id\u0026#34; -Headers @{Authorization = \u0026#34;Bearer $AccessToken\u0026#34;; \u0026#39;Content-Type\u0026#39; = \u0026#39;application/json\u0026#39;} # Check if the device is already a member of the group if ($GroupMembers.ID -contains $DeviceObjId.value.id) { Write-Host -ForegroundColor Yellow \u0026#34;($($DeviceObjId.value.id)) is in the Group\u0026#34; } else { # Add device to group Write-Host -ForegroundColor Green \u0026#34;Adding ($($DeviceId)) To The Group\u0026#34; $BodyContent = @{\u0026#34;@odata.id\u0026#34;=\u0026#34;https://graph.microsoft.com/v1.0/devices/$($DeviceObjId.value.id)\u0026#34;} | ConvertTo-Json # Make POST request to add device to the group using the Object ID Invoke-RestMethod -Method POST -uri \u0026#34;https://$MSGraphHost/v1.0/groups/$GroupID/members/`$ref\u0026#34; -Headers @{Authorization = \u0026#34;Bearer $AccessToken\u0026#34;; \u0026#39;Content-Type\u0026#39; = \u0026#39;application/json\u0026#39;} -Body $BodyContent } } Step 3 - Add the PowerShell Script to Intune Now that you have the script created, you need to add it to Intune. This can be done as a Win32 App, Proactive Remediation, or just a normal one-time device script. If you need help with this part, check out our guide on PowerShell scripts in Intune.\nConclusion You should now be able to create Azure groups that have devices dynamically added to them based on installed software. You could extend this script to also remove devices from groups as well. In that case, proactive remediation would probably be your best choice for deploying it. You could also use a scheduled task.\nI hope this guide has helped you overcome some of the limitations of Intune and managing your devices. If you have any questions, please let me know.\n","permalink":"http://localhost:1313/dynamic-azure-intune-groups-based-on-installed-software/","summary":"One of the noticeable drawbacks when moving from Config Manager (SCCM) to Intune is the lack of device collections based on software installed on endpoints. Like many other things in Intune, this can be overcome with a bit of creativity and PowerShell scripts.\nThere are multiple ways you could go about this but the way I am going to show you involves running a PowerShell script on your devices that will check if the software you are looking for is installed and if it is, the script will add the machine to the Azure device group of your choice.","title":"Dynamic Azure Intune Groups Based on Installed Software"},{"content":"If you\u0026rsquo;re like me, prior to using Proxmox you had virtual machines running in something like VirtualBox or Virt Manager. You may have spent a lot of time configuring these VMs and now that you\u0026rsquo;re migrating to Proxmox you really don\u0026rsquo;t want to start from scratch on those existing VMs. Luckily, you can import those into Proxmox and I\u0026rsquo;ll show you how to do that here, so let\u0026rsquo;s get started.\nImport VirtualBox VM to Proxmox Step 1: Launch VirtualBox Once you have VirtualBox open, find the VM that you want to migrate to Proxmox and right-click on it. In the menu, choose \u0026ldquo;Export to OCI\u0026rdquo;\nOn the following screen, you can keep the defaults. Just make sure the \u0026ldquo;Format\u0026rdquo; is set to \u0026ldquo;Open Virtualization Format\u0026rdquo;. Take note of the file location, as we will be copying this file over to our Proxmox server. Go ahead and click \u0026ldquo;Next\u0026rdquo; and then \u0026ldquo;Finish\u0026rdquo;.\nThe export of the VM should now begin and will take a few minutes to complete.\nStep 2: Upload VirtualBox OVA to Proxmox Once the export is finished, you should find the OVA file in the location that you noted above. Now you need to upload this OVA file to your Proxmox server. You can do this using whatever method you want, I typically use SFTP to upload the file.\nStep 3: Prep the OVA File in Proxmox You will need to either SSH to your Proxmox server or use the built-in console/shell for this part.\nNavigate in the shell session to where you uploaded the OVA file and run the following command to extract the OVA. This will give us a vmdk file that represents the hard disk of the VirtualBox VM we are trying to import.\ntar -xvf yourfile.ova After extracting the OVA file, you will have multiple files. The one that we want is the vmdk file which we will use to create the VM in Proxmox.\nStep 4: Create a Base Virtual Machine Now that we have the vmdk file, we need to create a basic VM in Proxmox. Configure the Network, CPU, and RAM however you wish. Once you have created the new VM, we will detach and remove the hard disk that was created with the VM. We will be replacing that hard disk with the one from VirtualBox.\nTo remove the current hard disk of the new VM, go into the hardware for the VM and highlight the Hard Disk. Then in the top menu select detach. After it is detached, it will appear as \u0026ldquo;Unused\u0026rdquo;, highlight it again and choose remove.\nStep 5: Import the VMDK to the New Proxmox VM Before we import the disk, take note of the ID for your new VM in Proxmox and the storage you want the hard disk to live on, you will need this for the import. In my case, the VM ID is 104 and the storage I want is vm-storage1. Your storage and ID will be different.\nBack in your shell prompt, make sure you are still in the folder where you extracted the vmdk file. Then run the following command. Replace the vmid, filename.vmdk, and storage_name with your values.\nqm importdisk vmid filename.vmdk storage_name -format qcow2 You should see the import process begin.\nStep 6: Enable the Disk in Proxmox If you head back to the VM in Proxmox, you should now see your disk listed as \u0026ldquo;Unused\u0026rdquo;. To enable the disk, highlight it and click edit. Customize any options you may need such as \u0026ldquo;Discard\u0026rdquo; and \u0026ldquo;SSD Emulation\u0026rdquo; (Only if the underlying disk is an SSD), then click on Add to make the disk active.\nOne last thing we need to do is change the boot order so that our VM boots to this new disk. From the \u0026ldquo;Options\u0026rdquo; menu of the VM, go into boot order and check the box next to your new hard disk and move it up in the order. In my example, I moved it just below the CD-ROM drive since I don\u0026rsquo;t have an ISO attached to it.\nStep 7: Boot Your VM Now you are ready to boot up your VM for the first time on Proxmox. Once you have confirmed it is working, you can delete the OVA you uploaded and extracted files as they are no longer needed.\nImport Virt Manager VM to Proxmox Step 1: Launch Virt Manager To get started with importing a Virt Manager VM to Proxmox, you need to find out where the VMs disk is currently stored. Go ahead and open up Virt Manager, make sure the VM is powered off, then right-click on the VM you want to use and choose open.\nNext, click the info icon to open the hardware details. Find the disk on the left side and view the file location on the right.\nStep 2: (Optional) Disable Preallocation of the Disk This step is optional but by default, Virt Manager creates full disk-size images. To save some time on uploading the VM disk to Proxmox, we can change the current image to have preallocation turned off, which will reduce the size of the disk image file.\nTo start we will copy the VM disk in case something goes wrong. I\u0026rsquo;m just going to copy it to my home folder. Be sure to replace the image file location below to match the location of your image file.\nNote: You may or may not need to use \u0026ldquo;sudo\u0026rdquo; for this command, depending on where you image file is located.\nsudo cp /path/to/image/file.qcow2 ~/ Now we will disable the pre-allocation feature to shrink the disk image. In the code below, you will need to update current_file and new_file with your values.\nNote: Depending on who owns the image file on the Linux filesystem, you can either change the ownership of the file with \u0026ldquo;chmod\u0026rdquo; or run the command with \u0026ldquo;sudo\u0026rdquo;.\nsudo qemu-img convert -f qcow2 -O qcow2 -o preallocation=off current_file.qcow2 new_file.qcow2 You should now have 2 qcow2 files, the new one should be much smaller than the original depending on how much disk space was actually used in the original image.\nStep 3: Upload QCOW2 file to Proxmox Now we need to upload our qcow2 file to Proxmox. You can do this however you want but I will be uploading it via SFTP.\nStep 4: Create a Base VM Once you have uploaded the qcow2 file, we need to create a basic VM in Proxmox. The options you use for VM creation can be whatever you want, so configure the CPU, RAM, and Network to your requirements or needs. The hard disk created during this process doesn\u0026rsquo;t matter since we will be deleting it.\nAfter your VM is created, the hard disk should be removed. To remove the current hard disk of the new VM, go into the hardware for the VM and highlight the Hard Disk. Then in the top menu select detach. After it is detached, it will show up as \u0026ldquo;Unused\u0026rdquo;, highlight it again and choose remove.\nStep 5: Import QCOW2 Disk to the New VM Before we import the disk, take note of the ID for your new VM in Proxmox and the storage you want the hard disk to live on, you will need this for the import. In my case, the VM ID is 104 and the storage I want is vm-storage1. Your storage and ID will be different.\nBack in your shell prompt, make sure you are still in the folder where you uploaded the qcow2 file. Then run the following command. Replace the vmid, filename.qcow2, and storage_name with your values.\nqm importdisk vmid filename.qcow2 storage_name You should see the import process begin.\nStep 6: Enable the Disk in Proxmox If you head back to the VM in Proxmox, you should now see your disk listed as \u0026ldquo;Unused\u0026rdquo;. To enable the disk, highlight it and click edit. Customize any options you may need such as \u0026ldquo;Discard\u0026rdquo; and \u0026ldquo;SSD Emulation\u0026rdquo; (Only if the underlying disk is an SSD), then click on Add to make the disk active.\nOne last thing we need to do is change the boot order so that our VM boots to this new disk. From the \u0026ldquo;Options\u0026rdquo; menu of the VM, go into boot order and check the box next to your new hard disk and move it up in the order. In my example, I moved it just below the CD-ROM drive since I don\u0026rsquo;t have an ISO attached to it.\nStep 7: Boot Your VM Now you are ready to boot up your VM for the first time on Proxmox. Once you have confirmed it is working, you can delete the qcow2 file you uploaded since it is no longer needed.\nConclusion I hope this guide helps you out on your journey of using Proxmox and virtual machines. If you have any questions let me know below!\n","permalink":"http://localhost:1313/import-virtualbox-and-virt-manager-vms-to-proxmox/","summary":"If you\u0026rsquo;re like me, prior to using Proxmox you had virtual machines running in something like VirtualBox or Virt Manager. You may have spent a lot of time configuring these VMs and now that you\u0026rsquo;re migrating to Proxmox you really don\u0026rsquo;t want to start from scratch on those existing VMs. Luckily, you can import those into Proxmox and I\u0026rsquo;ll show you how to do that here, so let\u0026rsquo;s get started.","title":"Import VirtualBox and Virt Manager VMs to Proxmox"},{"content":"Everyone has heard of Docker by now, it\u0026rsquo;s one of the most popular ways to create and run containerized apps and services. Docker isn\u0026rsquo;t difficult to use and understand but there are tools that exist that make managing, creating, and modifying docker containers even easier and user-friendly. This is exactly what Portainer does, it provides you with a simple-to-use and nice-looking web interface to manage your Docker instances and clusters.\nToday, we will walk through how to install and set up both Docker and Portainer inside a Proxmox VM. I assume for this tutorial you are already familiar with Proxmox and have it installed. If you need help with that, check out my video on installing Proxmox and an overview of its features.\nLXC or VM? There is a lot of debate about whether you should install Docker inside of a VM or an LXC Proxmox container. The official recommendation from Proxmox is to use a VM for better security. This is because an LXC container shares the kernel with the Proxmox host, so there is some concern that if the Docker instance is compromised, this could allow an attacker to breach the Proxmox host as well.\nWhile this may not be very worrisome for a home lab setup, especially if your Docker instance or containers are not exposed to the open internet. It\u0026rsquo;s still a consideration when setting this up.\nFor a production environment, it is highly advisable to run Docker in a full VM rather than an LXC container.\nFor this guide, we will be setting up Docker and Portainer on a full Ubuntu Server 22.04 VM in Proxmox.\nStep 1: Create a Ubuntu Server 22.04 VM We are using the 22.04 version of Ubuntu Server for this guide. You could use a different Linux distribution if you want, you may need to alter parts of this guide to do so.\nFirst, we need to obtain the Ubuntu Server ISO, which you can download from here. You will then want to upload this ISO to your Proxmox server.\nFor my VM I will give it the following resources.\n2 CPU Cores\n8GB of RAM\n32GB HDD Space\nThis is a pretty basic VM setup, nothing special going on here. The same is true for the Ubuntu Server OS installation. Boot up your VM to the ISO that you downloaded and run through the installation. Defaults are fine for most of the options. I did choose the \u0026ldquo;minimal\u0026rdquo; install option though this is up to you.\nStep 2: Update the System Once you have Ubuntu Server installed, you can use the Proxmox console to access the VM or set up SSH if you want. From there, you will want to update the system by running the following commands.\nsudo apt update \u0026amp;\u0026amp; sudo apt upgrade Step 3: Install Docker Now that we have the system update, it\u0026rsquo;s time to install Docker. This is very easy to do on Ubuntu, just run the following commands to grab and install the latest version.\ncurl -fsSL https://get.docker.com -o get-docker.sh sudo sh get-docker.sh Step 4: Install Portainer Once you have Docker installed, you\u0026rsquo;re ready to install Portainer. First, we will create a volume for the Portainer database, then we install Portainer.\ndocker volume create portainer_data sudo docker run -d -p 8000:8000 -p 9443:9443 --name portainer --restart=always -v /var/run/docker.sock:/var/run/docker.sock -v portainer_data:/data portainer/portainer-ce:latest Step 5: Access the Portainer Web Interface To use Portainer, we can access its web interface in a web browser of your choice. Head to https://yourserverip:9443\nThe first time you come to this page, you may need to accept the security risk, since it\u0026rsquo;s a self-signed certificate. You will also need to create a password for your admin user.\nOnce you complete that, you should be at the Portainer interface where you can now manage your Docker instance and containers.\nStep 6: Create Docker Containers in Portainer You installed Portainer to help you set up Docker containers, let us do that then. Portainer comes with some container templates built-in that you can use. You can also add additional templates as well. To view the built-in templates, click on your local environment from the home page. Then in the menu, click on \u0026ldquo;App Templates\u0026rdquo;.\nHere you will find many options like Apache, MySQL, Drupal, WordPress, and more.\nStep 7: Add Additional App Templates to Portainer You can change the \u0026ldquo;template.json\u0026rdquo; file that provides Portainer with the App Templates via the settings. If you search around the web for Portainer App Templates, you will find there are many to choose from.\nHere is a popular choice (not updated often): https://qballjos.github.io/portainer_templates/\nThis Portainer app template list is updated more regularly and is the current one that I\u0026rsquo;m using: https://github.com/Lissy93/portainer-templates/tree/main\nYou can add their templates by going to Settings and updating the JSON file listed under \u0026ldquo;App Templates\u0026rdquo; shown below.\nNow if you go back to your App Templates, you should see many more options available.\nConclusion Docker is powerful and fun to play around with, and Portainer makes it even more enjoyable. Have questions about Portainer? Let me know in the comments. Have a great day!\n","permalink":"http://localhost:1313/install-docker-and-portainer-on-proxmox/","summary":"Everyone has heard of Docker by now, it\u0026rsquo;s one of the most popular ways to create and run containerized apps and services. Docker isn\u0026rsquo;t difficult to use and understand but there are tools that exist that make managing, creating, and modifying docker containers even easier and user-friendly. This is exactly what Portainer does, it provides you with a simple-to-use and nice-looking web interface to manage your Docker instances and clusters.","title":"Install Docker and Portainer on Proxmox"},{"content":"Fedora 37 was released in November of 2022, and since then it has gained a lot of attention. Fedora supports Flatpaks by default and is running the latest Gnome desktop environment which is version 43 at this time. While it does run Gnome by default, you can find Fedora Spins with alternative desktop environments such as KDE Plasma and XFCE.\nFedora is an excellent option for new users and seasoned users as well. Many developers with plenty of experience with Linux choose Fedora for the availability of apps, ease of use, and stability.\nGiven how great Fedora 37 is out of the box, there are still some things you might want to do after getting it installed. You might be asking yourself, what should I do after installing Fedora? Below, you will find 9 things to do after installing Fedora.\n1. DNF Configuration DNF is the package manager used by Fedora, which stands for \u0026ldquo;Dandified YUM\u0026rdquo;. It works great out of the box but there are some tweaks you can make to improve the experience and get faster downloads. You will need to open up the configuration file using \u0026ldquo;sudo\u0026rdquo; to make the necessary edits.\nsudo nano /etc/dnf/dnf.conf At the end of the file, add these lines.\nmax_parallel_downloads=10 fastestmirror=true Max_parallel_downloads will increase the number of file downloads that can be run simultaneously, the default is 3 and the max value is 20. The fastest mirror will set the best mirror based on location.\n2. Update the System One of the first things you should do on any OS after installation is to check for any updates and install those. Packages could have security vulnerabilities that updates have been released for, so it\u0026rsquo;s important to get them installed right away.\nsudo dnf update \u0026amp;\u0026amp; sudo dnf upgrade You can also update the system using the graphical Software Manager.\n3. Add Flathub Repo Fedora has decided to only allow a limited number of packages from the growing Flathub repo by default. This will be changing in Fedora 38 but for now, we need to add the full Flathub repo to get access to all of the great packages there.\nflatpak remote-add --if-not-exists flathub https://flathub.org/repo/flathub.flatpakrepo 4. Enable RPM Fusion Repo There is some software that RedHat cannot include in Fedora but you can get through the RPM Fusion Repo instead. Software like VirtualBox, VLC, and others. The code below will add both the free and non-free repos.\nsudo dnf install https://mirrors.rpmfusion.org/free/fedora/rpmfusion-free-release-$(rpm -E %fedora).noarch.rpm https://mirrors.rpmfusion.org/nonfree/fedora/rpmfusion-nonfree-release-$(rpm -E %fedora).noarch.rpm 5. Install Gnome Tweaks and Gnome Extensions I think that Gnome is somewhat boring and lacking in useful UI features. Luckily, many others feel the same way so we have Gnome Tweaks and the Gnome Extensions app to help us get the UI we want.\nsudo dnf install gnome-tweaks gnome-extensions-app You can find some cool extensions here: https://extensions.gnome.org/\nOne that I always install is Dash to Dock, give it a shot and see if you like it.\n6. File Manager Tweaks By default, the file manager does not list directories first. I find this annoying so I always change that right away. If you open the file manager and go to preferences, you will find the option \u0026ldquo;Sort folders before files\u0026rdquo;, tick that on and you\u0026rsquo;ll be good to go.\n7. Enable Tap to Click If you are on a laptop and using a trackpad, you may want a tap on the trackpad to be registered as a click. If so, you can enable that in the settings under \u0026ldquo;Mouse \u0026amp; Trackpad\u0026rdquo;. There you will find the tap-to-click option, which you can enable.\n8. Install a Different Desktop Environment Fedora comes with Gnome by default, but that doesn\u0026rsquo;t mean that you can\u0026rsquo;t try out different desktop environments like KDE Plasma and XFCE though. Personally, I prefer KDE over XFCE but both are great. If you don\u0026rsquo;t like how Gnome operates, give one of these a try.\nKDE sudo dnf install @kde-desktop-environment XFCE sudo dnf install @xfce-desktop-environment You can get a full list of desktop environments that Fedora has available by running this command.\ndnf group list --available *desktop 9. Install Some Apps You\u0026rsquo;re ready to get started enjoying your new Fedora 37 system, so go ahead and install some apps. You can install software using DNF, Flatpak from the command line, or find your favorite app using the Software Manager interface.\nHere are some apps that I almost always install on every system.\nFlatseal - Manage Flatpak app permissions.\nOB Studio - For recording YouTube videos.\nKdenlive - For editing YouTube videos.\nSpotify\nBoxes - Easily run Virtual Machines.\nRemmina - For remote desktop.\nConclusion What are your favorite apps to run on Fedora? Have any tweaks or modifications that I missed? Let me know!\n","permalink":"http://localhost:1313/9-things-to-do-after-installing-fedora-37/","summary":"Fedora 37 was released in November of 2022, and since then it has gained a lot of attention. Fedora supports Flatpaks by default and is running the latest Gnome desktop environment which is version 43 at this time. While it does run Gnome by default, you can find Fedora Spins with alternative desktop environments such as KDE Plasma and XFCE.\nFedora is an excellent option for new users and seasoned users as well.","title":"9 Things to Do After Installing Fedora 37"},{"content":"Ad and tracking blocker plugins are popular in most web browsers, but what if you could apply ad blocking to your entire network without a need for these plugins? This is where Pi-hole comes in, providing you with whole network ad blocking. In this guide, I will walk you through installing Pi-hole on Proxmox using a Ubuntu container so you don\u0026rsquo;t need many resources to do this.\nWhat is Pi-hole? To put it simply, Pi-hole is a DNS server that uses a blocklist to block ads, trackers, and more. It is customizable, meaning you can add additional blocks manually or via openly available blocklists. You can further customize your DNS by whitelisting domains that you find should not be blocked by Pi-hole.\nWhat is DNS? DNS stands for domain name resolution, but what does this mean? When you open up your web browser, you put in google.com and google comes up. Behind the scenes, a DNS server is being asked, \u0026ldquo;What is the IP for google.com?\u0026rdquo;. The DNS server sends the IP of the website back through your network so that the communication can be successful. Simply put, DNS translates domain names, like google.com, to an IP address.\nInstalling Pi-hole on Proxmox To get started, we are going to create a Ubuntu 20.04 container in Proxmox. Inside the container, we are going to install Pi-hole. Afterward, we will configure pfSense to use Pi-hole as well as show you how to configure individual Linux and Windows machines to use Pi-hole.\nStep 1: Download a Ubuntu 20.04 Container Template In order to set up a container in Proxmox, you will need a template. If you haven\u0026rsquo;t already done so, you can download the Ubuntu 20.04 template that we are going to use from within Proxmox.\nTo do this, navigate to your \u0026ldquo;local\u0026rdquo; storage, then choose \u0026ldquo;CT Templates\u0026rdquo; and click \u0026ldquo;Templates\u0026rdquo; from the top bar as shown below. This will give you a list of templates that can be downloaded. Find the Ubuntu 20.04 one and download it.\nStep 2: Create a Linux Container in Proxmox Now that you have the template downloaded, we can create the container. Right-click on your proxmox node, then choose \u0026ldquo;Create CT\u0026rdquo;.\nIn the \u0026ldquo;create container\u0026rdquo; popup, give your container a name and set up a password. This password will be the root user account password of the Linux container.\nOn the template tab, choose the Ubuntu template you downloaded earlier.\nOn the Disks tab, select the storage volume you want or keep the default and update the disk size to 2-4GB of space. This is all that Pi-hole requires.\nOn the CPU tab, the default is 1 core, I\u0026rsquo;ve changed this to 2. Configure what you want here, 1 or 2 is probably fine and you can change it later if needed.\nOn the Memory tab, the default is 512 MB of RAM, this is the minimum required amount for Pi-hole. You can up this to 1 or 2GB if needed.\nOn the Network tab, it is highly suggested that you configure a static IP. If you set this to DHCP, the IP could change and devices configured to use Pi-hole DNS will fail to resolve domain names. Here I\u0026rsquo;ve configured a static IP of \u0026ldquo;192.168.1.10\u0026rdquo; and the gateway is \u0026ldquo;192.168.1.1\u0026rdquo;. The gateway is my pfSense firewall, yours is likely different.\nOn the DNS screen, keep the defaults and on the confirmation screen review the details and click \u0026ldquo;Finish\u0026rdquo;.\nOnce the container is finished, which should only take a few minutes, power it on and open up the console for it in Proxmox so we can install Pi-hole.\nStep 3: Install Pi-hole Before we start the installation, let\u0026rsquo;s update the container using APT. In the shell console of the container, log in as root and run the following commands.\napt update \u0026amp;\u0026amp; apt upgrade You will need to install \u0026ldquo;curl\u0026rdquo; to install Pi-hole using this method.\napt install curl Once the system has been updated, we can now install Pi-hole. To start the installation, run this command in the terminal.\ncurl -sSL https://install.pi-hole.net | bash A few seconds after running this command you should see a series of questions in the Pi-hole installer. I\u0026rsquo;ll cover the important ones here.\nStatic IP Needed\nThis is a warning that you should have a static IP configured, which we did earlier. Upstream DNS Provider\nThe upstream DNS provider is the service that Pi-hole uses to resolve DNS names that it hasn\u0026rsquo;t cached already. Any choice is fine here, I went with Google DNS. Blocklists\nYou are offered a default blocklist called \u0026ldquo;StevenBlack\u0026rsquo;s Unified Host List\u0026rdquo;, it isn\u0026rsquo;t too aggressive and typically safe to accept this default list. Admin Web Interface\nIf you want to be able to administer Pi-hole from the web interface, you will want this option. Web Server\nIf you chose to install the web interface, you need a web server, Pi-hole will set this up for you. Enable Logging\nThe queries made to Pi-hole can be logged, you will want this in most cases. Privacy Mode\nIf you selected to enable logging, this determines how detailed the logging is. I chose Show Everything. After these menu questions, Pi-hole will complete the installation, then you will be presented with a screen explaining how to access the web interface and the default password. Take note of this information.\nStep 4: Access the Pi-hole Web Interface Open up your browser and head to http://pihole_ip/admin to access the web interface. Use the password that was provided at the end of the installation process to log in.\nFrom here you can add blocklists, manual domain blocks, and whitelists. You can view the query log to see what is being allowed and blocked on your network and much more.\nCheck out this video for a detailed overview of the interface.\nhttps://youtu.be/F2b1SECl-Ek\nStep 5: Update pfSense to Use Pi-hole for DNS If you are using a pfSense firewall like I am and you want your entire network to use Pi-hole for its DNS then you will want to update your DHCP server. To do this, log in to pfSense, in the top menu, go to \u0026ldquo;Services\u0026rdquo; and choose \u0026ldquo;DHCP Server\u0026rdquo;.\nScroll down the page to the \u0026ldquo;Servers\u0026rdquo; section where you will find an option for DNS servers. Put your Pi-hole IP address as the first one and put a backup in the second box.\nThe next time your devices renew their DHCP lease, they will get the updated DNS servers. You can also disconnect and reconnect a device to speed this up.\nIf you have a different firewall or router for your network, look for the DNS or DHCP settings in its interface to make the same changes.\nStep 6: Configure a Linux Device to Use Pi-hole Maybe you just want to configure a few devices and not your whole network to use Pi-hole. You can do that on a Linux device by editing the \u0026ldquo;/etc/resolv.conf\u0026rdquo; file.\nsudo nano /etc/resolv.conf You will want to update the first entry to point to the IP of your Pi-hole server.\nStep 7: Configure a Windows Device to Use Pi-Hole If you have a Windows device that you want to point to Pi-hole for DNS, right-click on the network icon in the system tray and choose \u0026ldquo;Open Network \u0026amp; Internet Settings\u0026rdquo;.\nFrom the network settings, choose \u0026ldquo;Change Adapter Options\u0026rdquo;.\nFind your network adapter, then right-click on it and choose properties. In the properties window, choose \u0026ldquo;Internet Protocol Version 4 (TCP/IPv4)\u0026rdquo; and click on properties.\nHere you will check the box for \u0026ldquo;Use the following DNS server addresses\u0026rdquo;. Then input your Pi-hole IP and a secondary DNS server.\nConclusion That\u0026rsquo;s it, you now have Pi-hole setup in Proxmox to handle all of your DNS queries. If you need any help or have questions, leave a comment below.\n","permalink":"http://localhost:1313/install-pihole-on-a-proxmox-ubuntu-container/","summary":"Ad and tracking blocker plugins are popular in most web browsers, but what if you could apply ad blocking to your entire network without a need for these plugins? This is where Pi-hole comes in, providing you with whole network ad blocking. In this guide, I will walk you through installing Pi-hole on Proxmox using a Ubuntu container so you don\u0026rsquo;t need many resources to do this.\nWhat is Pi-hole? To put it simply, Pi-hole is a DNS server that uses a blocklist to block ads, trackers, and more.","title":"Install Pi-hole on a Proxmox Ubuntu Container"},{"content":"I recently rebuilt my Proxmox server and decided that I wanted to give Fedora 37 with KDE Plasma 5.27 a spin. It\u0026rsquo;s not ideal to always use the console built into Proxmox for remote desktop, as the experience is not the best. To improve the experience, I was going to install and set up XRDP to get the best speed and experience possible while connecting from my main Manjaro laptop.\nHere, I\u0026rsquo;ve documented how to XRDP on the Fedora virtual machine and set up the connection on my Manjaro machine using Remmina.\nStep 1: Install XRDP on the Fedora VM The installation is pretty simple, we just need a couple of commands.\nsudo dnf install xrdp After installing xrdp, we need to set up the service so that it runs after a reboot.\nsudo systemctl enable xrdp To start xrdp now, we use the following command.\nsudo systemctl start xrdp Step 2: Installing Remmina Back on the device we will be connecting from, we need to install a remote desktop client to make the connection to xrdp on Fedora. I really like Reminna for this, it works well with connecting to both Linux and Windows devices.\nManjaro or Arch Linux On Manjaro, we can install Remmina from the command line using pacman or from the GUI software installer pamac. You have multiple options for which repository you install Remmina from, such as Flathub, the official Manjaro repo, or the AUR. Typically I would recommend using the Flatpak version, but in the case of Remmina, I\u0026rsquo;ve had issues with remote sound when connecting to Windows devices.\nBased on my experience, I would recommend installing it from the AUR. The \u0026ldquo;remmina-git\u0026rdquo; version has worked for me.\nyay -S remmina-git # install from the AUR sudo pacman -S remmina # install from the official repo flatpak install flathub org.remmina.Remmina # install from Flathub Ubuntu For Ubuntu, we need to add an additional repo to get Remmina installed.\nsudo apt-add-repository ppa:remmina-ppa-team/remmina-next sudo apt update sudo apt install remmina remmina-plugin-rdp remmina-plugin-secret Alternatively, you can install the Snap package on Ubuntu. I wouldn\u0026rsquo;t recommend this unless you know the snap version has been updated, sometimes they can lag behind the repo listed above.\nsudo snap install remmina Fedora We can use dnf to install Remmina on Fedora.\nsudo dnf install Remmina Step 3: Connecting to Fedora Now that we have the Remmina remote desktop client installed, we can make our XRDP connection to the Fedora virtual machine.\nNote: If you are connecting to the remote machine using Windows, you can use the built-in Remote Desktop Client from Microsoft.\nWhen you open Remmina the first time, it should look similar to this. Click the icon at the top left to add a new connection.\nYou will need the IP address from the Fedora VM, to get this, you can run this command in the terminal on Fedora.\nip addr Now you can fill in the details for the connection in Remmina. Provide the IP address, username, and password for the Fedora user account. Make sure you choose RDP as the connection protocol as well.\nOnce you have configured the details above, you can test the connection.\nIf you have multiple desktop environments installed and it\u0026rsquo;s not defaulting to the one you want, you will need to set that up in a \u0026ldquo;~/.Xclients\u0026rdquo; file.\nStep 4: Set Desktop Environment for XRDP In my example, I installed KDE with Gnome as the default but later installed KDE Plasma. So for my testing, I want KDE to run by default when connecting with XRDP. To do this we run the following commands on the Fedora VM to create the \u0026ldquo;.Xclients\u0026rdquo; file and make it executable.\necho \u0026#34;startplasma-x11\u0026#34; \u0026gt; ~/.Xclients chmod a+x ~/.Xclients After doing this, disconnect from your XRDP session if you had one open, then reconnect again. This time, KDE should run by default.\nStep 5: Customize Your Remmina Session There are many options available in Remmina to enhance your experience. Some that I like to change are the Quality and Remote Sound options.\nNote: Remote sound with XRDP does not work currently if the machine you are connecting to uses Pipewire, such as Fedora. This function works fine with Pulseaudio clients and Windows though. See more: https://github.com/neutrinolabs/xrdp/discussions/2023\nSetting the sound to local will allow the sound from the Fedora VM to be output on my local laptop.\nStep 6: Screen Resolution In order to get the XRDP session to take up the full window, you can use this button in the Remmina connection interface. This button will dynamically adjust the resolution of the remote session.\n","permalink":"http://localhost:1313/setup-xrdp-on-a-fedora-vm-for-remote-desktop/","summary":"I recently rebuilt my Proxmox server and decided that I wanted to give Fedora 37 with KDE Plasma 5.27 a spin. It\u0026rsquo;s not ideal to always use the console built into Proxmox for remote desktop, as the experience is not the best. To improve the experience, I was going to install and set up XRDP to get the best speed and experience possible while connecting from my main Manjaro laptop.","title":"Setup XRDP on a Fedora VM for Remote Desktop"},{"content":"There are times, especially if you are a developer when you really need to create or test something on macOS. Luckily, there is a very easy way to do this on Linux, using Docker. There are many methods out there, such as running macOS in Virtual Box or even dual booting if you have the right hardware combination and a lot of time to fiddle with it.\nRunning macOS in Docker on Linux is really easy thanks to an open-source project from sickcodes called Docker-OSX. This will actually run on most distributions of Linux, assuming you can install Docker and the other dependencies. I will be covering the steps for Manjaro specifically since this is what I run. This exact process should also work on Arch and EndeavourOS flavors of Linux as well.\nNote: Before proceeding, make sure you have Virtualization turned on in your BIOS.\nStep 1: Install Dependencies Before we move on, we need to make sure our machine has all of the necessary software to make running macOS on Linux a success.\nsudo pacman -S qemu libvirt dnsmasq virt-manager bridge-utils flex bison iptables-nft edk2-ovmf Next, we should enable libvirt and load the kvm module.\nsudo systemctl enable --now libvirt sudo systemctl enable --now virtlogd echo 1 | sudo tee /sys/module/kvm/parameters/ignore_msrs sudo modprobe kvm We also need to install and enable Docker.\nsudo pacman -S docker sudo systemctl enable docker sudo systemcrl start docker We also should add our user account to a few groups for docker, libvirt, and kvm.\nsudo usermod -aG docker,libvirt,kvm your_username You may need to restart your machine or log out and back in before proceeding if you run into issues trying to start Docker.\nStep 2: Choose Which macOS Version to Run on Linux Sickcodes offers many different Docker containers, each containing a different OSX version. In the examples below, I have configured 8GB of ram and 4 CPU cores, you can update this for your own needs or remove the two additional \u0026ldquo;-e\u0026rdquo; options to take the defaults.\nCatalina docker run -it \\ --device /dev/kvm \\ -e RAM=8 \\ -e CORES=4 \\ -p 50922:10022 \\ -v /tmp/.X11-unix:/tmp/.X11-unix \\ -e \u0026#34;DISPLAY=${DISPLAY:-:0.0}\u0026#34; \\ sickcodes/docker-osx:latest Big Sur docker run -it \\ --device /dev/kvm \\ -e RAM=8 \\ -e CORES=4 \\ -p 50922:10022 \\ -v /tmp/.X11-unix:/tmp/.X11-unix \\ -e \u0026#34;DISPLAY=${DISPLAY:-:0.0}\u0026#34; \\ sickcodes/docker-osx:big-sur Monterey docker run -it \\ --device /dev/kvm \\ -e RAM=8 \\ -e CORES=4 \\ -p 50922:10022 \\ -v /tmp/.X11-unix:/tmp/.X11-unix \\ -e \u0026#34;DISPLAY=${DISPLAY:-:0.0}\u0026#34; \\ -e GENERATE_UNIQUE=true \\ -e MASTER_PLIST_URL=\u0026#39;https://raw.githubusercontent.com/sickcodes/osx-serial-generator/master/config-custom.plist\u0026#39; \\ sickcodes/docker-osx:monterey Ventura docker run -it \\ --device /dev/kvm \\ -e RAM=8 \\ -e CORES=4 \\ -p 50922:10022 \\ -v /tmp/.X11-unix:/tmp/.X11-unix \\ -e \u0026#34;DISPLAY=${DISPLAY:-:0.0}\u0026#34; \\ -e GENERATE_UNIQUE=true \\ -e MASTER_PLIST_URL=\u0026#39;https://raw.githubusercontent.com/sickcodes/osx-serial-generator/master/config-custom.plist\u0026#39; \\ sickcodes/docker-osx:ventura Step 3: Run the Docker Command Once you pick which version of macOS you want to run, copy the code into your terminal and run it. Depending on your system, this may take a while. It will begin by downloading the required image that you chose, then it will build and launch the Docker container.\nI ran into an error the first time I tried this.\nIf you run into the error gtk initialization failed, you need to install an additional package and run this one additional command, then try launching your container again.\nNote: I would not recommend running \u0026ldquo;xhost +\u0026rdquo; on a shared computer, only a single user personal device. Read more about xhost.\nsudo pacman -S xorg-xhost xhost + If you get the error \u0026ldquo;docker: unknown server OS:\u0026rdquo;, try running the following command and run it again. If it still fails with this error, restart your computer and try again. If you still have this error message, even after a restart, refer to this documentation page for more info.\nsudo systemctl enable --now docker Step 4: Install macOS If you were able to launch the Docker container without any issues, after a while you should come to a screen similar to the one pictured below. There may be some slight differences depending on which version you chose.\nQEMU will pop up once the image is downloaded, and the Docker container is created and started.\nEventually, you should get to this boot menu. You will choose \u0026ldquo;macOS Base System\u0026rdquo; or you can just wait and it will boot this one by default after a few seconds.\nOn the next screen, you will want to open the \u0026ldquo;Disk Utility\u0026rdquo; to wipe the partition so we can install macOS on it.\nOnce you are inside the Disk Utility, choose the first disk, which should be the largest, around 270GB. Then choose to erase from the options at the top. Don\u0026rsquo;t worry, this isn\u0026rsquo;t your hard drive and you are not losing any data on your actual machine. These are just virtual disks inside the container.\nOnce you click erase, give the partition a name and keep the format and scheme as their defaults.\nWhen you are done erasing the partition, you can close the disk utility and you should be back at the menu. Here you will choose to \u0026ldquo;Reinstall macOS\u0026rdquo;.\nOnce you start the installation, it may take a while and there will be a series of reboots. At the disk selection screen, choose the disk that you erased using the disk utility earlier.\nAfter the reboots, make sure to select the macOS installer option.\nAfter multiple reboots, the macOS installer option will disappear from the boot menu. When that happens, you will choose the disk that has the same name you gave it in the Disk Utility earlier in the process.\nEventually, you will end up at the final system and account setup. Once you finish this portion, you will have installed macOS on the Docker container.\nStep 5: Starting Your Docker Container If you shut down your macOS Docker container or reboot your host machine, you will probably want to get back into it at some point in the future.\nIf you were to run the Docker command you used at the start of this process, it will create a whole new Docker container and you will be going through the macOS install all over again. That\u0026rsquo;s likely not what you want.\nTo get back to your container and boot it you need to get the ID of the container. You can do this with the \u0026ldquo;docker ps \u0026ndash;all\u0026rdquo; command.\nWe will copy the container ID and use it with the \u0026ldquo;docker start container_id\u0026rdquo; command to relaunch our existing macOS container. Just replace my container ID with yours.\ndocker start 6b51a8ef8921 It may take a few moments but after running this command you should see the QEMU window popup and macOS start to load.\nFAQ Can you run macOS on Linux? Yes, there are many ways to do this, all involving some form of virtualization technology such as Docker or VirtualBox. This guide walks you step-by-step through setting up macOS on Linux using a Docker container.\nIs it possible to run macOS on a PC? Yes, you can install macOS on a PC depending on the specific hardware. However, running macOS in a virtual machine or container is far easier to get started with.\nCan you put macOS on a Virtual Machine? Yes, you can install macOS on a Virtual Machine using VirtualBox or other virtualization tools. In this article, we cover using Docker, which is another form of virtualization using containers.\nIs it legal to install macOS on a PC? It is a violation of the software license agreement from Apple to install macOS on anything other than genuine Apple hardware.\n","permalink":"http://localhost:1313/mac-osx-on-manjaro-linux-made-easy-with-docker/","summary":"There are times, especially if you are a developer when you really need to create or test something on macOS. Luckily, there is a very easy way to do this on Linux, using Docker. There are many methods out there, such as running macOS in Virtual Box or even dual booting if you have the right hardware combination and a lot of time to fiddle with it.\nRunning macOS in Docker on Linux is really easy thanks to an open-source project from sickcodes called Docker-OSX.","title":"Mac OSX on Manjaro Linux Made Easy With Docker"},{"content":"If you are a .NET developer and coming to Linux, you have a few different options for a development IDE. You may choose any standard text editor if that\u0026rsquo;s your thing, or you may like Vim or VS Code. If you are looking for a Linux alternative that is close to Visual Studio, like you have on Windows, JetBrains Rider is an excellent choice.\nRider is a fully featured .NET IDE for Linux that also supports the cross-platform GUI framework Avalonia UI. This means that you can develop GUI applications that run natively on many different operating systems such as Linux, Windows, MacOS, iOS, etc. by using the Avalonia UI framework. Coupled with JetBrains Rider, your .NET C# development becomes much smoother. While Rider is not a free product, you do get a free 30-day trial to try it out.\nGreat news, Rider is also available in a Flatpak. So installation is a breeze and the application will run great on all Linux distributions. Today, I will be installing Rider on Manjaro Linux and walking you through the process.\nInstall .NET SDK on Linux Before proceeding, make sure you have installed the .NET SDK for Linux on your machine.\nStep 1: Install JetBrains Toolbox for Linux There are many ways to install Rider and other JetBrains products for Linux but using their Toolbox will save you a lot of headaches. Normally I would recommend using the Flatpak but in the case of Rider, it will give you some issues. So use their Toolbox app instead, regardless of Linux distribution such as Ubuntu, Fedora, or Manjaro/Arch.\nHead over to their website to download the latest version. It will be a \u0026ldquo;tar.gz\u0026rdquo; archive which we will install it from.\nOnce you have downloaded the archive file, we need to extract it. Inside will be an AppImage that runs the Toolbox app. Before you can run it, we need to install some dependencies.\nUse your package manager like apt, dnf or pacman to install these.\nlibfuse2 libxi6 libxrender1 libxtst6 mesa-utils libfontconfig libgtk-3-bin If you are on an Arch-based Linux distro like Manjaro or EndeavourOS, the package names will be a bit different.\nsudo pacman -S fuse2 libxi libxrender libxtst mesa-utils fontconfig gtk3 You can extract the JetBrains Toolbox archive with this command.\ntar -zxvf jetbrains-toolbox-1.27.2.13801.tar.gz This will extract the AppImage file to a directory that matches the name of the archive. We will want to cd to that directory and launch the AppImage or you can find it in your File Manager of choice to run it that way.\ncd jetbrains-toolbox-1.27.2.13801 ./jetbrains-toolbox Once it loads, answer a few questions, then you will see a list of JetBrains apps that you can install.\nStep 2: Install JetBrains Rider Using the Toolbox app, find Rider and click install.\nRider will begin to download, you can monitor the progress by scrolling back to the top of the list. Once the download is finished, the installation will start automatically. When finished, you can launch Rider from the Toolbox app by clicking on it, or you can find it in your application menu, typically under the \u0026ldquo;Development\u0026rdquo; category.\nStep 3: Launch Rider After launching Rider on Linux for the first time, you will get a series of prompts to accept the license agreement, configure your color scheme, etc. You will also be given an opportunity to install some additional plugins like the Azure Toolkit or AWS Toolkit. These are optional, install any of these and then you can proceed with using Rider.\nBefore getting to the welcome screen, you must activate Rider using your paid or trial license.\nStep 4: Create a .NET C# Console Project Once you have the Rider IDE loaded, let\u0026rsquo;s test out a simple console app. From the welcome screen, choose \u0026ldquo;New Solution\u0026rdquo;.\nOn the new solution screen, choose \u0026ldquo;console application\u0026rdquo; from the left side menu. You can keep the defaults or customize them as you wish. I will be keeping the defaults for this test.\nDepending on your system, it may take a few moments for the project to prepare and load. Once it does, you will see a simple console print statement for \u0026ldquo;Hello, World!\u0026rdquo;. At the top right, you can click on \u0026ldquo;Run\u0026rdquo; to test everything.\nAfter running the application, you will see the output panel show up at the bottom where the application will build and execute. You should see \u0026ldquo;Hello, World!\u0026rdquo; printed after a moment.\nConclusion Now you have successfully installed JetBrains Rider on Linux for .NET and C# development. You can easily build console applications using .NET on Linux.\nIf you want to build cross-platform GUI applications, I suggest the Avalonia UI framework, which is very similar to WPF apps on Windows. It will make the transition from Visual Studio to Rider on Linux very easy for you.\nYou can get started by installing the Avalonia UI templates with the following command.\ndotnet new install \u0026#34;Avalonia.Templates\u0026#34; The next time you load Rider and choose to create a new solution, you will find the Avalonia Templates at the bottom under \u0026ldquo;Other\u0026rdquo;.\n","permalink":"http://localhost:1313/install-jetbrains-rider-for-c-on-linux/","summary":"If you are a .NET developer and coming to Linux, you have a few different options for a development IDE. You may choose any standard text editor if that\u0026rsquo;s your thing, or you may like Vim or VS Code. If you are looking for a Linux alternative that is close to Visual Studio, like you have on Windows, JetBrains Rider is an excellent choice.\nRider is a fully featured .NET IDE for Linux that also supports the cross-platform GUI framework Avalonia UI.","title":"Install JetBrains Rider for C# on Linux"},{"content":"I said in a recent article that Avalonia UI is a great framework for creating Linux GUI applications using C# and .NET. I also said that it paired well with the JetBrains Rider IDE. So today, we are going to build the basic Linux GUI app using Avalonia UI and Rider.\nThe GUI applications built using this framework will be cross-platform. They will run on Linux, Windows, and MacOS which greatly speeds up development. Also, if you are already familiar with WPF apps in Visual Studio on Windows, Avalonia UI borrows a lot from WPF so you will feel right at home.\nRequirements Have the .NET SDK installed on Linux (guide)\nHave JetBrains Rider Installed (guide)\nStep 1: Install Avalonia UI Templates In order to use Avalonia, we need to first install the templates. We do this by using the command line, so pop open your terminal and run the following:\ndotnet new install \u0026#34;Avalonia.Templates\u0026#34; Step 2: Launch JetBrains Rider on Linux Go ahead and start up Rider and create a new solution. From the new solution menu, choose the \u0026ldquo;Avalonia UI Core App\u0026rdquo; template.\nGive the solution a name, choose C# as the language, and choose the .NET framework you want to build with if needed.\nNow, click \u0026ldquo;Create\u0026rdquo; to build the solution. It will take a moment for the project solution to build\nStep 3: Run the Avalonia UI App Once the project loads fully, you should see the contents of the \u0026ldquo;MainWindow.axaml\u0026rdquo; file displayed in the editor window. This basic app will produce a Linux GUI app that displays \u0026ldquo;Welcome to Avalonia!\u0026rdquo; in a desktop window. You can click run in the top right to test the application.\nAfter running the app, you should see this window.\nCongratulations, you have built and run your first GUI C# .NET application for Linux using Avalonia UI.\nStep 4: Get Familiar With Avalonia UI If we take a look at the solution explorer and the file structure, we will find some similarities of Avalonia with WPF applications on Windows.\nWe see that we are building for .NET 7.0 which is the latest version at this time. We also see that some NuGet packages have been installed for Avalonia.\nFurther down we see some \u0026ldquo;axaml\u0026rdquo; files, these are just normal XAML files, they are prefixed with an \u0026ldquo;a\u0026rdquo; for Avalonia.\nIf you expand the XAML files, you will find the code-behind \u0026ldquo;.cs\u0026rdquo; files, just like a regular WPF application.\nYou can find a full feature comparison between WPF and Avalonia in their documentation.\nProgram.cs This is where the initialization of the program is setup\nApp.axaml.cs Code-behind for \u0026ldquo;App.axaml\u0026rdquo; and the OnFrameworkInitializationCompleted method is called when all parts of the Avalonia Framework are loaded and ready, after which the MainWindow is generated.\nMainWindow.axaml This is the window that will be presented when you run the application, you will want to make additions to the UI here, such as buttons, labels, inputs, etc.\nMainWindow.axaml.cs Code-behind for the MainWindow, unless you are following a strict MVVM pattern, you can put code here to work with UI elements that are in the MainWindow.\nStep 5: Install the Avalonia Rider Plugin In order to see a live preview of what your XAML layout looks like, you will need to install the Avalonia plugin for Rider.\nTo do this, go to the File menu in Rider, then choose Settings. From the settings menu, choose Plugins and search for Avalonia. You should see the plugin listed with the options to install it.\nYou will need to restart Rider for the plugin to be active. After this, you should be able to see the live preview when editing a XAML layout file. If you don\u0026rsquo;t, even after installing the plugin and restarting Rider, make sure you have the \u0026ldquo;Editor and Preview\u0026rdquo; option selected.\nFAQ Does Avalonia use WPF? Avalonia is very similar to WPF but not identical. So you won\u0026rsquo;t be able to just copy your WPF code and run it with Avalonia. Learning Avalonia will be easy if you already know WPF. Avalonia does have a new project, which isn\u0026rsquo;t free, called XPF which allows you to run existing WPF Windows apps on Linux and MacOS.\nIs Avalonia Cross-Platform? Yes, you can build apps that run on Windows, Linux, MacOS, iOS, and Android.\nIs Avalonia UI Free? Yes, Avalonia is free and it\u0026rsquo;s also open source. Check out their GitHub.\nConclusion This was just a simple primer for Avalonia UI to show that building cross-platform .NET C# GUI apps that run on Linux is not difficult or impossible. We will have future posts that build some sample applications using this framework.\nStay Tuned for More! In the meantime, Avalonia has great documentation to get you started.\n","permalink":"http://localhost:1313/linux-c-net-gui-app-using-avalonia-ui/","summary":"I said in a recent article that Avalonia UI is a great framework for creating Linux GUI applications using C# and .NET. I also said that it paired well with the JetBrains Rider IDE. So today, we are going to build the basic Linux GUI app using Avalonia UI and Rider.\nThe GUI applications built using this framework will be cross-platform. They will run on Linux, Windows, and MacOS which greatly speeds up development.","title":"Linux C# .NET GUI App Using Avalonia UI"},{"content":"I assume if you are reading this, then you are familiar with what Active Directory and Linux are. Although, you may be asking yourself, what would be the benefit of joining a Linux device to Active Directory? The answer: Central ID and user management. Especially for large organizations that use both Windows and Linux devices or servers.\nImagine not having to set up local accounts across all of the Linux servers and devices, instead, you just log in with your active directory domain credentials and authenticate with your AD server. Plus you can easily manage who has access to sudo. Another benefit is that you don\u0026rsquo;t have to clean up old local accounts when an employee leaves the company.\nThe following guide will walk you through joining an existing Active Directory domain from your Linux devices such as Fedora, Ubuntu, etc. But first, let\u0026rsquo;s talk briefly about the packages needed to make this possible. We will be using SSSD and Realmd to make this possible on Linux, it\u0026rsquo;s surprisingly easy.\nSSSD\nThe core software package that we need in order to join Linux devices in Active Directory is System Security Services Daemon. This package is called SSSD for short, way easier to say and remember. SSSD is what allows us to communicate with AD, LDP, Kerberos, and other providers. It also handles caching credentials on the client device as well. This way you can log in when network connectivity is not present, assuming you have signed in before and the credentials are cached.\nOne important thing to note is that SSSD does not create local Linux accounts on the client device, it only caches the credentials.\nRealmd\nConfiguring SSSD yourself can be time-consuming, a pain, and error-prone. Thankfully, realmd does all of the heavy lifting for us by doing all of the configurations. You can use realmd to not only discover your AD server but to identify additional packages that are needed to make the connection.\nInstalling SSSD and Realmd Depending on what Linux distribution your client machine is running, this will be different, so I have included a few different types below. In many cases you can use these instructions for other Linux distributions as well, just use the package manager for that specific distro.\nUbuntu 22.04 LTS To install SSSD and Realmd, run the following command in the terminal. This will also work for other Ubuntu/Debian variants such as PopOS and Linux Mint.\nsudo apt install sssd realmd Fedora 37, Rocky Linux 9 Use this command to install SSSD and Realmd on Fedora.\nsudo dnf install sssd realmd Set Hostname Before continuing, make sure you have set a proper hostname and it\u0026rsquo;s not something like \u0026ldquo;localhost\u0026rdquo;. If you don\u0026rsquo;t set a hostname, the domain join using realmd will fail.\nsudo hostnamectl set-hostname newhostname Discovering the Domain Now that you have sssd and realmd installed, let\u0026rsquo;s use realmd to discover our AD domain.\nrealm discover ad1.cdlabs.net The output of this command will give us some information about our AD setup and additional packages that are required for the connection to work properly. It looks like we need to install these additional packages: sssd-tools, libnss-sss, libpam-sss, adcli, samba-common-bin.\nUbuntu 22.04 LTS sudo apt install sssd-tools libnss-sss libpam-sss adcli samba-common-bin Fedora 37, Rocky Linux 9 sudo dnf install oddjob oddjob-mkhomedir adcli samba-common-tools Join the Domain Now we are ready to join the domain. We will use the \u0026ldquo;realm join\u0026rdquo; command to do this and you have some additional options that can be used with it as well. Examples are below, starting with a basic AD join.\nWhen inputting the AD domain admin username, you do not need to specify the domain like \u0026ldquo;domain\\thecd\u0026rdquo;, you can just use the username by itself.\nrealm join -U domain_admin_username domain.fqdn If you want to specify the OU where the computer account is created, you can do that as well with the following variation. By default, new computers will be added to the Computers OU in the root of the domain.\nrealm join --computer-ou=\u0026#34;ou=Computers,ou=HomeLab,dc=cdlabs,dc=net\u0026#34; -U domain_admin_username domain.fqdn We can then check AD to find our Linux device has been created under the OU we chose.\nHandling Errors If your Linux device fails to join AD, you should get a \u0026ldquo;journalctl\u0026rdquo; command output that you can use to see the logs. These logs will help you diagnose the issue.\nCommon issues are the domain account used for joining doesn\u0026rsquo;t have the proper permissions, the encryption type is not supported or an incorrect password was used.\nVerify the Machine Account is Created Login to Linux with AD Account Now that we have our Linux device added to our Windows Active Directory domain, we can log in with an AD account.\nUsername: username@domain.ext\nSo to log in with a test user account we would type in the username like so.\nCreate Home Directories Automatically You may notice that your user doesn\u0026rsquo;t have a home directory upon login. We need to enable it so that when a user logs in with an AD account, their home directory is created.\nNote: If you are on Fedora 37 or Rocky Linux, a home directory will be created by default. You do not need to run this command.\nsudo pam-auth-update --enable mkhomedir Now if you log in with your AD account again, the home directory will be created.\nAdd AD Users to Sudo Group Another common task when integrating Linux devices into Active Directory domains is putting admins into the sudo group so they can run elevated commands.\nTo do this you must add the AD group that you want to have sudo privileges to the sudoers file. We can do this using the \u0026ldquo;visudo\u0026rdquo; command or you can create a new file in the \u0026ldquo;/etc/sudoers.d/\u0026rdquo; directory.\nIf you have a group called \u0026ldquo;linuxadmins\u0026rdquo; in AD, you would add the following line to your sudoers file.\n\u0026#34;%linuxadmins@domain.ext\u0026#34; ALL=(ALL) ALL You should clear the cache and restart sssd before trying to log in with a user that has been added to this group. This will make sure their group memberships are read again and not pulled from the cache.\nsudo sss_cache -E; sudo service sssd stop ; sudo rm -rf /var/lib/sss/db/* ; sudo service sssd start Now, any user that is a member of that group in AD will be able to use sudo on the Linux system.\nFAQ Does Linux Support Active Directory? Linux can support and use Active Directory for user management and authentication. This is done through extra packages like SSSD and Realmd.\nCan I Use Linux as a Domain Controller? Yes, there are specialized Linux distributions made for this, such as Zentayl.\nCan I Control Sudo Access with Active Directory? Yes, once you have connected the Linux system to AD, you can use the sudoers file to grant access to a particular AD group.\n","permalink":"http://localhost:1313/join-a-linux-device-to-active-directory/","summary":"I assume if you are reading this, then you are familiar with what Active Directory and Linux are. Although, you may be asking yourself, what would be the benefit of joining a Linux device to Active Directory? The answer: Central ID and user management. Especially for large organizations that use both Windows and Linux devices or servers.\nImagine not having to set up local accounts across all of the Linux servers and devices, instead, you just log in with your active directory domain credentials and authenticate with your AD server.","title":"Join a Linux Device to Active Directory"},{"content":"Plex has become extremely popular since its humble beginnings back in 2008. Today Plex is used all over the world, serving up streaming content as well as users\u0026rsquo; own content. They have built relationships with many big players in the entertainment industry as well, such as MGM, Lionsgate, and Warner Bros.\nIf you have been looking for a solution to stream your own video content and also access tons of content from the web, Plex has you covered. You can also set up remote access so you can stream from anywhere, not just your home.\nPlex has both a client and a server component, both of which will run on Linux. You can install the Plex server on a VM of your choice or on your desktop, laptop, or server. While this guide covers Linux, you can also install Plex on Windows and MacOS.\nThe following instructions will work for any Arch-based Linux distro such as EndeavourOS.\nStep 1: Install Plex Media Server To get started with the installation on Manjaro you need to make sure you have the AUR enabled.\nIf you do not know how to enable the AUR, our AUR guide will help you with that.\nUnfortunately, the plex-media-server package is not available from Flathub or the Official Manjaro Repo. Once you have the AUR enabled, you can start the installation from the command line or from the GUI using pamac. I\u0026rsquo;m using the yay helper, you can install it with \u0026ldquo;sudo pacman -S yay\u0026rdquo; if you don\u0026rsquo;t already have it.\nyay -S plex-media-server Step 2: Running Plex Media Server Before you can start using the Plex media server on Linux, you will need to enable and start the service. On Manjaro, we do this using systemd and the systemctl command.\nsudo systemctl enable plexmediaserver.service sudo systemctl start plexmediaserver.service You can then verify that it is running with the status command.\nsudo systemctl status plexmediaserver.service Once you have confirmed that the Plex server is running, you can open and browser and head to the following URL to access the interface. http://127.0.0.1:32400/web\nStep 3: Plex Server Folder Permissions In order for the Plex server to access media files on your Linux system, you need to grant the \u0026ldquo;plex\u0026rdquo; user access to them.\nThe best thing to do is to create new directories outside of your home directory to store all of your media files, let\u0026rsquo;s go ahead and do that now.\nsudo mkdir -p /media/movies sudo mkdir -p /media/tvshows Now, let\u0026rsquo;s make the plex user and group the owner of these directories.\nsudo chown -R plex:plex /media We need to be able to access and use these directories as our own user account well, so we will add our user to the plex group.\nsudo gpasswd -a username plex Finally, we make sure the owner (plex) and the group (plex) have write permissions on these folders. This allows both your user account and plex to write to the directories.\nsudo chmod -R 775 /media Note: Your user account may not be able to add/modify files in this directory until you log out and back in again.\nUsing a File Share Instead If you are storing your files on some type of share drive, you should add plex to your users\u0026rsquo; group instead, or whatever group has access to the share. Make sure your user group has read/write permissions on the share drive.\nStep 4: Installing the Plex Client The best and easiest way to install the Plex Client on Linux is through Flatpak using Flathub. Make sure that you have Flathub enabled on Manjaro, if you\u0026rsquo;re not sure, you can use our guide for enabling Flatpak support.\nOnce you have Flatpak enabled, you can use the command line or pamac to install the Plex client. You can also use Flatpak to install it on Ubuntu and other Linux distros as well.\nflatpak install flathub tv.plex.PlexDesktop Step 5: Running the Plex Client To run the Plex client, you can either find it in your Applications menu if you\u0026rsquo;re using KDE, Gnome, XFCE, etc. or you can run it from the command line. You will find it under Multimedia in the Applications menu.\nflatpak run tv.plex.PlexDesktop Accessing Plex Remotely In order to access Plex from outside of your home, you will need to enable port forwarding on your router and open up ports on your firewall. The port you need to open and forward is 32400. On Manjaro you can use ufw or gufw to open this port on the machine itself. You will need to refer to your router\u0026rsquo;s documentation to enable and setup port forwarding.\nFAQ Can I Run Plex Server on Linux? Yes, the Plex server runs great on Linux. It will run on many distros such as Arch-based distros like Manjaro, Ubuntu, and other Debian variants, etc.\nHow do I Watch Plex on Linux? You can use the Plex client or the web interface found at http://serverip:32400/web. I prefer the Plex client, which can be installed on Linux via Flatpak for the best experience.\nHow do I Start the Plex Server on Linux? Assuming that your system uses systemd to manage services you would run \u0026ldquo;sudo systemctl start plexmediaserver.service\u0026rdquo; to start the Plex Media Server.\nIs Jellyfin Better than Plex? Jellyfin and Plex are very similar but Plex supports implementation on more setups, such as some NAS setups. At the core, they are very similar and offer similar performance for media sharing. Jellyfin is free and open source as well, so if that is important to you then you may want to check it out.\n","permalink":"http://localhost:1313/install-plex-media-server-on-manjaro-linux/","summary":"Plex has become extremely popular since its humble beginnings back in 2008. Today Plex is used all over the world, serving up streaming content as well as users\u0026rsquo; own content. They have built relationships with many big players in the entertainment industry as well, such as MGM, Lionsgate, and Warner Bros.\nIf you have been looking for a solution to stream your own video content and also access tons of content from the web, Plex has you covered.","title":"Install Plex Media Server on Manjaro Linux"},{"content":"Manjaro is one of the most popular Linux distributions based on data from DistroWatch and their very active online communities such as Reddit. I personally use Manjaro on my daily laptop PC and I have found it to be not only reliable but easy to use and install the necessary software on. Since Manjaro is derived from Arch Linux, many new users shy away from it, but I think this may be a mistake. Sure, Ubuntu is great for new users but I do not agree that it delivers the best all-around experience.\nIt\u0026rsquo;s true that you can heavily customize Manjaro, but you don\u0026rsquo;t have to. You can start using it, leaving everything at its default, and have a great experience. In that aspect, it\u0026rsquo;s not more difficult to set up, install or use than Ubuntu.\nSo if you decide to give Manjaro Linux a try, I\u0026rsquo;m going to cover some of the first things you should do once the installation is complete. By the way, I would suggest starting with the KDE Plasma or XFCE versions, unless you just love Gnome or prefer something more advanced like the i3 WM.\n1. Update the System In Manjaro you can update the system using Pamac but the one universal way to do it is through the terminal. Pop open a fresh terminal and run the following commands to first update your mirrors so the downloads are fast and then update all of the packages.\nsudo pacman-mirrors --fasttrack sudo pacman -Syu After this, your mirror list will be updated to include the fastest mirrors for you and the system will be up to date. You may be required to reboot, I would suggest doing this even if you\u0026rsquo;re not required.\n2. Install Additional Drivers This is particularly important if you have an AMD or NVIDIA GPU in your system. You may want to install the proprietary drivers for improved performance. To install these drivers, you can use the Manjaro Settings Manager. If you installed KDE or XFCE, you will find the app under Settings. Once you launch the Manjaro Setting Manager, you will then use the Hardware Configuration option to install the drivers.\nInside the Hardware Configuration app, you will find the option to install additional drivers if there are any for your device.\n3. Enable Flatpak Flatpak is an amazing addition to any Linux setup, it allows you to easily install many popular software packages the way the developer intended. This means the app will run on any Linux system without issues like incorrect dependencies or mismatched versions. If it\u0026rsquo;s available as a Flatpak, use that version over one from the AUR or official Manjaro repository.\nTo enable Flatpak on Manjaro, you can use the command line or pamac. In Pamac, you\u0026rsquo;ll find it under Preferences -\u0026gt; Third Party. While you\u0026rsquo;re there, you may want to consider enabling the AUR and Snap support but only install packages from these if you can\u0026rsquo;t find them elsewhere.\nsudo pacman -S flatpak If you install flatpak from the command line, you will want to enable the Flathub repository as this is where you will find most of the popular flatpak packages.\nflatpak remote-add --if-not-exists flathub https://flathub.org/repo/flathub.flatpakrepo 4. Install Software Now you will want to install your favorite software. Try to find the software on Flathub, this will give you the best experience for most applications. You can also use Pamac to install software, try to avoid the applications from the AUR if you can help it. Applications from the AUR may work fine but sometimes they can be problematic and break other applications when new dependencies are installed. The instances are rare but can be totally avoided by using Flatpaks.\nHere are a few examples of software I install on any new Manjaro setup that I do.\nMicrosoft Edge flatpak install flathub com.microsoft.Edge VS Code flatpak install flathub com.visualstudio.code OBS Studio flatpak install flathub com.obsproject.Studio Discord flatpak install flathub com.discordapp.Discord Flatseal Flatseal is a must because it allows you to manage permissions that Flatpack applications have on your system. This allows you to loosen or tighten the restrictions on the application\u0026rsquo;s sandbox.\nflatpak install flathub com.github.tchx84.Flatseal 5. Install Microsoft Fonts You may be opening Microsoft Word documents or applications that are designed for using Microsoft fonts on your Linux machine, these fonts are not included by default. This is one instance where you will want to use the AUR. If you don\u0026rsquo;t already have the AUR helper yay installed, I\u0026rsquo;ve included the command below to install it as well as the Microsoft True Type Fonts as well.\nThe second command which builds and installs the MS Font package will take a while to run as it\u0026rsquo;s compiling everything required. Afterward, if you open something like OnlyOffice or LibreOffice, you will find that you now have these fonts available.\nsudo pacman -S yay yay -S ttf-ms-win10-auto 6. Enable the Firewall By default, Manjaro will come with ufw installed and depending on the ISO and WM, you will have Gufw installed as well. Gufw is the GUI frontend that makes using ufw easier. You will find it under settings as \u0026ldquo;Firewall Configuration\u0026rdquo;. You can also work with ufw and gufw from the command line.\nThe default configuration will be to block all incoming and allow all outgoing which is fine for most setups. You may need to add additional firewall rules if you have services such as MySQL or Apache running on the machine that need to be open to external access.\nsudo ufw enable sudo gufw 7. Configure Backups Last but certainly not the least important is to set up backups. The easiest way to do this is using TimeShift, which can be installed through pamac or the command line from the official Manjaro Repository.\nsudo pacman -S timeshift 8. Install a VPN Everyone should consider using a VPN to protect their device and information. Add a layer of protection between the prying eyes of the government, your ISP, and others by using an encrypted tunnel that a VPN provides. There are many ways to set up a VPN on Manjaro and most large VPN providers have instructions for Installing their VPN on Linux so follow their guides to do so.\nI use ExpressVPN and have a guide for installing it which you can find here.\nWant More App Suggestions? Check out the list of my favorite Manjaro apps.\nConclusion Those are 8 things everyone should do after installing Manjaro on their PC. There are many other things you may want to do after installation, let us know in the comments what you do after a fresh install.\n","permalink":"http://localhost:1313/8-things-to-do-after-installing-manjaro-linux/","summary":"Manjaro is one of the most popular Linux distributions based on data from DistroWatch and their very active online communities such as Reddit. I personally use Manjaro on my daily laptop PC and I have found it to be not only reliable but easy to use and install the necessary software on. Since Manjaro is derived from Arch Linux, many new users shy away from it, but I think this may be a mistake.","title":"8 Things to Do After Installing Manjaro Linux"},{"content":"This guide is part of a series, be sure to check out the other parts as well.\nPart 1 - Introduction to Bash, Variables, Comments, User Input\nPart 2 - If/Else Statements, Looping\nPart 3 - Functions in Bash\nPart 4 - Creating Menus in Bash (This Page)\nIn this part, we will be covering how to create menus in Bash scripting on Linux. We will first cover a basic menu that is really simple to set up and use but also flexible and works for most cases. We will also go over a more advanced menu that offers a very different user experience which is more like a GUI, just in the terminal instead.\nBasic Bash Menu The basic menu will make use of echo, case, and select statements to allow our users to make choices and take action based on that choice. No additional packages are needed to set up this style of menu in your bash script, everything you need is already part of your Linux system.\n#! /usr/bin/bash PS3=\u0026#34;Select an Option: \u0026#34; # Special variable that is a prompt for the select statement # Select a option and put that into the \u0026#34;opt\u0026#34; variable. select opt in Ubuntu Manjaro \u0026#34;Endeavour OS\u0026#34; Fedora Quit do # The opt variable is then used for matching in our case statement case $opt in \u0026#34;Ubuntu\u0026#34;) echo \u0026#34;You chose $opt\u0026#34;;; \u0026#34;Manjaro\u0026#34;) # If the user types 2 at the prompt, the following echo statement is ran echo \u0026#34;You chose $opt\u0026#34;;; \u0026#34;Endeavour OS\u0026#34;) echo \u0026#34;You chose $opt\u0026#34;;; \u0026#34;Fedora\u0026#34;) echo \u0026#34;You chose $opt\u0026#34;;; \u0026#34;Quit\u0026#34;) # If the users types 5, the echo statement runs and then the menu ends # this is because we use \u0026#34;break\u0026#34;, which exits the case block. echo \u0026#34;Exiting....\u0026#34; break;; *) # This is the default option, in the case that the user enters # something that doesn\u0026#39;t match anything above. echo \u0026#34;Sorry, your choice was invalid. Please Try Again.\u0026#34;;; esac done Let\u0026rsquo;s break down what is going on in this script, starting with the \u0026ldquo;PS3\u0026rdquo; variable that we have at the start.\nPS3 Variable PS3 is a special variable in bash that is tied to the select statement. PS3 represents the prompt that we want to use in conjunction with the select statement. This prompt will be displayed to the user after the menu displays on the screen.\nSelect Statement Next, we have the \u0026ldquo;select\u0026rdquo; statement. This statement takes in a list of possible choices. If one of your list items has a space, be sure to wrap it in quotes as you see in the example above. You can also include numbers or variables as items instead of strings. What do we want to do with the selection that the user makes? In this instance, we are feeding it into a case statement.\nCase Statement The case statement, which we saw briefly in the previous lesson, matches on the menu option the user chooses. The script falls through the options until a match is found, if no match is found then it falls to the default represented by the asterisk. When a match is found, the commands after the closing parentheses and before the double semi-colon are executed. The double semi-colon represents the end of the commands that should be executed for that specific option. We end the case statement block with case backward, \u0026ldquo;esac\u0026rdquo; and then we end the entire select block with \u0026ldquo;done\u0026rdquo;.\nUsing an Array If you have a lot of options, the select statement could get pretty long and ugly. An alternative to listing your options in the select statement is to put them into an array. You can then use that array in the select statement.\nCreate a Bash Array We need to create an array with the same menu options as before, then assign it to a variable called \u0026ldquo;options\u0026rdquo;. In bash, you separate each element of the array with a space.\noptions=(\u0026#34;Ubuntu\u0026#34; \u0026#34;Manjaro\u0026#34; \u0026#34;Endeavour OS\u0026#34; \u0026#34;Fedora\u0026#34; \u0026#34;Quit\u0026#34;) To use this array, we need to update the select statement. We will \u0026ldquo;expand\u0026rdquo; the array inside the select statement using \u0026ldquo;[@thecd]\u0026rdquo;.\nselect opt in \u0026#34;${options[@]}\u0026#34; Advanced Bash Menu To give ourselves more options in creating our bash menu, we can use an additional package called \u0026ldquo;dialog\u0026rdquo;. This package is available on most Linux distributions, you can install it using pacman, apt, dnf etc. Be sure to install it before proceeding. Dialog has a large man page that outlines the many options that it provides, be sure to look over that.\nThere are some applications out there that you may have used before that have similar menus to the one we are about to create. Such as part of the MySQL setup for example.\n#! /usr/bin/bash dialog \\ --backtitle \u0026#34;This is our cool dialog menu\u0026#34; \\ --menu \u0026#34;Please select a distro\u0026#34; \\ 10 40 3 \\ 1 \u0026#34;Manjaro\u0026#34; \\ 2 \u0026#34;Other\u0026#34; Go ahead and put this code in your editor and save it. You will need to run this in an actual terminal, not something like the built in terminal in VS Code for example, as it won\u0026rsquo;t work properly there.\nYou\u0026rsquo;ll notice that the \u0026ldquo;\u0026ndash;backtitle\u0026rdquo; is shown at the very top of the window. The next line, \u0026ldquo;\u0026ndash;menu\u0026rdquo; is telling dialog that we want a basic menu and then provides text that will display directly above the menu options. The numbers listed on the next line represent the height, width, etc. which dictate how the menu is sized.\nThe remaining lines are our menu options, one and two. The text next to them for Manjaro and Ubuntu will be listed in the menu as well.\nHow Do We Get Data Back? So, you may be asking yourself how do we get the option the user chose? The easiest way is just to set the dialog itself to a variable and then reference that variable wherever you need, like a case statement we\u0026rsquo;ve used before maybe. The important thing to know about the dialog is that the choice the user makes goes to the standard error output stream. So we need to redirect that in order for this to work.\n#! /usr/bin/bash choice=$(dialog \\ --backtitle \u0026#34;This is our cool dialog menu\u0026#34; \\ --menu \u0026#34;Please select a distro\u0026#34; \\ 10 40 3 \\ 1 \u0026#34;Manjaro\u0026#34; \\ 2 \u0026#34;Other\u0026#34; \\ 3\u0026gt;\u0026amp;1 1\u0026gt;\u0026amp;2 2\u0026gt;\u0026amp;3 3\u0026gt;\u0026amp;-) echo \u0026#34;$choice\u0026#34; Output redirects are common in bash scripts and here we will use 3\u0026gt;\u0026amp;1 1\u0026gt;\u0026amp;2 2\u0026gt;\u0026amp;3 3\u0026gt;\u0026amp;- to essentially redirect standard error (2) to standard output (1) but we need to create a temporary file descriptor (3) to accomplish this. What we are doing is creating the new file descriptor (3) and pointing it to the standard output, then we redirect the standard output (1) to standard error (2) and finally redirect standard error (2) to our temporary file descriptor (3). The last part cleans up the temporary file descriptor we used.\nWhen running this modified version, once you choose a menu option, it is loaded into the \u0026ldquo;choice\u0026rdquo; variable and output to the screen. In a real application, you may want to use this variable in a function or case statement for example. You can do much more with Dialog, such as password boxes, work with files, progress bars, and more.\nConclusion Menus are an essential part of many bash scripts, especially those that require user input such as an installer. Get creative with your installer and be sure to check out the documentation for Dialog to get more ideas on how to use it.\n","permalink":"http://localhost:1313/part-4-beginners-guide-to-bash-scripting/","summary":"This guide is part of a series, be sure to check out the other parts as well.\nPart 1 - Introduction to Bash, Variables, Comments, User Input\nPart 2 - If/Else Statements, Looping\nPart 3 - Functions in Bash\nPart 4 - Creating Menus in Bash (This Page)\nIn this part, we will be covering how to create menus in Bash scripting on Linux. We will first cover a basic menu that is really simple to set up and use but also flexible and works for most cases.","title":"Part 4 - Beginner's Guide to Bash Scripting"},{"content":"Have you been following our Beginner\u0026rsquo;s Guide to Bash Scripting series? If not, check it out.\nI do most of my programming in all languages using Visual Studio Code (VS Code) on Linux. I enjoy how easy it is to use as well as some of the integrations it offers, but also the extensions that are available. For Bash, there are quite a few extensions available that will extend VS Code to make your coding more efficient and error-free. We are going to take a look at 3 of those Bash extensions today.\nIf you don\u0026rsquo;t have VS Code installed on Linux yet, check out our guide to get started.\n1. Bash Debug The first extension that we are going to look at is Bash Debug, which is exactly what it sounds like, a debugger for Bash. It has over 500,000 downloads from the VS Code marketplace to date. First, you need to install it from the marketplace, then restart VS Code. Next, head to the \u0026ldquo;Run\u0026rdquo; option found in the menu and choose \u0026ldquo;Start Debugging\u0026rdquo;. A menu will pop out where you can select \u0026ldquo;Bash Debug\u0026rdquo;. Alternatively, you can press F5 on your keyboard to get the same option.\nOnce you run the Debug Bash, your interface will change to the debugger view. Here you will have options to control the debugging process. You will be able to add standard breakpoints and conditional breakpoints, log messages, and more.\nIf you write complex bash scripts, the Bash Debug extension is a must-have for your toolkit. It also works with Windows if you\u0026rsquo;re using WSL.\n2. Bash Beautify The next extension on our list is Bash Beautify, which is a code formatting helper. This extension has over 400,000 downloads and a 3-star rating. Most of those ratings are over a year old and stated that it wasn\u0026rsquo;t working. I use this extension without any issues so it appears the developer has resolved those problems.\nMaybe you are working on existing code that is poorly formatted or you prefer to let an extension clean up your own code, this extension is for you. Simply install the extension, then use the default formatting keybinding to run it \u0026ldquo;Ctrl+Shift+I\u0026rdquo;, unless you have customized that keybinding.\nMany plugins also suggest an error-checking plugin, which we will discuss next.\n3. ShellCheck ShellCheck is a linter for Bash scripts that works really well in VS Code to provide some helpful error checking and suggestions as you code. It also has over 500,000 downloads from the marketplace and a 5-star rating. The necessary shellcheck binary is included by default in more recent versions, so you can just install it from the marketplace, no restart needed. It offers various configuration options such as excluding certain checks or auto-fixing on save.\nWhat VS Code extensions do you like using for bash shell scripting? Let me know in the comments.\n","permalink":"http://localhost:1313/3-bash-vscode-linux-extensions/","summary":"Have you been following our Beginner\u0026rsquo;s Guide to Bash Scripting series? If not, check it out.\nI do most of my programming in all languages using Visual Studio Code (VS Code) on Linux. I enjoy how easy it is to use as well as some of the integrations it offers, but also the extensions that are available. For Bash, there are quite a few extensions available that will extend VS Code to make your coding more efficient and error-free.","title":"3 Bash VS Code Linux Extensions You Should be Using"},{"content":"If you want to start a fight between Linux users, just ask them what Linux distro is the best, such as Ubuntu and Manjaro. Sure, you will see some commonality in the answers but you\u0026rsquo;ll also see a lot of arguments over rolling release and LTS. So, in this post, we will compare Manjaro, a rolling release, and Ubuntu, an LTS Linux release. Both of which rank highly on DistroWatch. For this comparison, we will use Ubuntu 22.04 LTS and Manjaro 22.0 GNOME Edition. Why not Ubuntu 22.10? Because it isn\u0026rsquo;t LTS and it\u0026rsquo;s also not the version that a typical new Linux user would download.\nManjaro Overview Download Manjaro\nManjaro is based on Arch Linux, which is typically reserved for advanced Linux users. Manjaro has changed that by including a user-friendly installer and multiple choices for desktop environments. Stability typically isn\u0026rsquo;t an issue based on my own 2-3 year experience with it as well as community feedback on their very active subreddit.\nManjaro is a rolling release, which means that software packages are released to end users with very little delay. Unlike Arch, Manjaro holds back packages for a week or so before releasing them in their repository. If you want a package faster, you can use the AUR or compile from source yourself.\nManjaro is not as scary or difficult to use or learn as some would have you believe. If you\u0026rsquo;re scared to make the jump, you can always test it out on a Virtual Machine using VirtualBox.\nChecking out DistroWatch, you will find Manjaro ranked at #4 currently on the 3 and the 6 month trend for popular Linux Distros. This is a good sign of is relevance and adoption among Linux users and Distro Hoppers.\nUbuntu Overview Ubuntu Download\nIf you have read anything or considered Linux in the past, you have definitely heard of Ubuntu. Many would say it is one of the best choices for new Linux users. I beg to differ on this though, I believe there are many other options that are just as good if not better, but that\u0026rsquo;s not the point of this post.\nUbuntu follows a Long Term Support (LTS) release cycle where you get a new release about every 2 years. In between that time, you get security and other important updates but many packages can be quite old. Which means you are missing out on new features but gaining additional stability.\nSimilar to how we checked out DistroWatch for Manjaro\u0026rsquo;s rank, we find Ubuntu ranked in the #7 spot on the 6 month trend of Linux Distros. On the 3 month trend, Ubuntu is found at number 8.\nManjaro and Ubuntu Comparison This chart offers a quick glimpse into the comparison of both distros. They are similar in a few different ways but there are some major differences here. Specifically, the release cycle which we have already discussed but also application availability, latest software, kernel version and the ability to deeply customize.\nFeature Manjaro Ubuntu Parent Distro Arch Debian Package Manager pacman / pamac apt / Ubuntu Software Package Repository Arch User Repository (AUR) \u0026amp; Manjaro Repository Ubuntu Repository Distro Agnostic Packages Flatpak, Snap, AppImage Flatpak, Snap, AppImage Rolling release Yes No (LTS release every 2 years) Latest Software Packages Yes No (Exception for Snap and Flatpack) Default Kernel Version (2/2023) 6.1.9-1 5.15.0-58 Gnome Version (2/2023) 43.2 42.5 UEFI Support Yes Yes Secure Boot Support Possible Yes Available Architecture 64-bit, ARM 64-bit, ARM Support for Bleeding Edge Hardware High Medium/Low Multi-Monitor Support Yes Yes User Community Size Medium Larger Default Desktop Environment KDE Plasma, Gnome, i3, Xfce (Others available) Gnome (Others available) Stability Stable Stable Performance Good Good Customization High Medium User-Friendliness Good Excellent Ubuntu vs Manjaro Feature Comparison\nIs Manjaro Good for New Users? If you are a new Linux user, you can still run Manjaro, especially the Gnome, KDE, and XFCE versions. KDE and XFCE will seem the most familiar to a Windows user, while Gnome feels like a tablet OS in my opinion, even in the latest version 43. Personally, I prefer the XFCE and i3 versions.\nInstallation The install process for Ubuntu and Manjaro is very similar. One you have booted into the live environment from a USB, both distros offer an excellent installer that makes installation a breeze. One issue that Manjaro can run into is when secure boot is enabled on the machine. If you are unable to boot into the live environment, this could be the cause. Ubuntu will not have this issue, which may make the installation seem easier to some users.\nKernel Differences As you can see in the chart above, there is a major difference between the defaul kernals offered with these two distros. This is what makes Manjaro more compatible with newer and bleeding edge hardware. At the same time, some may say that this is part of what gives Ubuntu it\u0026rsquo;s stability. Speaking from personal experience, I haven\u0026rsquo;t experienced any stability issue using the newer kernel on Manjaro, this could be specific to my hardware though.\nWant Old Software? Just to give you an idea of how outdated Ubuntu\u0026rsquo;s software repository can be, here are a few examples of application versions available in both Manjaro\u0026rsquo;s and Ubuntu\u0026rsquo;s default repositories. To be fair, Ubuntu will suggest the Snap versions which are typically much more recent versions of the software packages. Although, Snap packages are a whole other discussion. Please enable and use Flatpak instead. That goes for both Manjaro and Ubuntu.\nWhile you can get new and hard-to-find software packages from the AUR on Manjaro, you should understand the risks involved. Most of the time, Flatpak\u0026rsquo;s are a much better choice in addition to the built-in official Manjaro repository.\nSoftware Title Ubuntu Manjaro Gimp 2.10.30 2.10.32 OBS Studio 27.2.3 29.0.0 LibreOffice 7.3.7 7.4.5 (libreoffice-fresh) Ubuntu vs Manjaro Software Versions\nPackage Management Both APT and pacman are simple to use from the command line. Ubuntu and Manjaro offer GUI package managers as well, sadly Ubuntu Software is a slow experience. Pamac is available on Manjaro and it provides a decent experience for managing your applications.\nDocumentation and Support Ubuntu has been around for a really long time and throughout that time the community and documentation have grown. You won\u0026rsquo;t have any trouble finding information and support for Ubuntu. While Manjaro is not as mature as Ubuntu, it benefits from the Arch Wiki but also has it\u0026rsquo;s own Wiki as well. You will also find the subreddit and forums to be quite helpful. One benefit to Manjaro is that the user base tends to be more technically inclined, so the help can be superior in that aspect. Not to say that Ubuntu users aren\u0026rsquo;t technically inclined at all.\nWhich Distro Should You Choose? That is a tough question to answer in a generic one size fits all way. The decision is based more on what you value, is it stability or having a Linux distro that is compatible with all of the latest hardware and has the latest software? There are some trade-offs there for sure, while Ubuntu is known to be stable, Manjaro has been quite stable for me and many others. If the device you are using is mission-critical, you probably don\u0026rsquo;t want to use Manjaro, but if this is an everyday personal PC or Laptop, I\u0026rsquo;d say give it a shot. This isn\u0026rsquo;t to say that I would go installing Manjaro on my grandmothers computer though LOL.\n","permalink":"http://localhost:1313/manjaro-vs-ubuntu-rolling-better-than-lts/","summary":"If you want to start a fight between Linux users, just ask them what Linux distro is the best, such as Ubuntu and Manjaro. Sure, you will see some commonality in the answers but you\u0026rsquo;ll also see a lot of arguments over rolling release and LTS. So, in this post, we will compare Manjaro, a rolling release, and Ubuntu, an LTS Linux release. Both of which rank highly on DistroWatch. For this comparison, we will use Ubuntu 22.","title":"Manjaro vs Ubuntu - Rolling Better than LTS?"},{"content":"This guide is part of a series, be sure to check out the other parts as well.\nPart 1 - Introduction to Bash, Variables, Comments, User Input\nPart 2 - If/Else Statements, Looping\nPart 3 - Functions in Bash (This Page)\nPart 4 - Creating Menus in Bash\nWelcome back to Part 3 of our Beginners Guide to Bash Scripting. In this guide, we\u0026rsquo;ll be talking about functions in bash scripting.\nFunctions are a very important part of any programming or scripting language. A function can be thought of as a block of code that you give a name to and it can be run multiple times without having to rewrite the code. This allows you to reuse the same code in a clean and efficient manner. So whenever you have repeated code, you should consider using a function instead.\nFunctions can also take parameters or arguments, these parameters are data that you pass into the function. The function can manipulate this data or really whatever you want. Consider a calculator function, you pass in two numbers and what math operation you want it to do, then the function returns the result of the calculation.\nLet\u0026rsquo;s take a closer look at functions in bash scripting.\nSyntax for a Bash Script Function If you have used other programming or scripting languages, then functions in bash scripting will look familiar and work in a similar way. Here is the basic syntax for a bash function.\nWith the Function Keyword # Declare a function using the \u0026#34;function\u0026#34; keyword, then give the function a name function function_name() { # This is the body of the function where we put the code we want to execute some_command } Without the Function Keyword # This example omits the function keyword and just has the function name function_name() { # This is the body of the function where we put the code we want to execute some_command } Single Line Bash Functions You may prefer to declare a short function in bash on a single line, this is valid in bash scripting. When using the single-line function syntax, be sure to include a semi-colon after your function body as shown in the example below.\nfunction_name() { some_command; } How to Call or Execute a Bash Function In order to call or use the bash function shown above, we simply use its name in our script.\nfunction_name # No () or anything are needed, just the name of the function Bash Script Function Example Let\u0026rsquo;s take a look at a real example of a bash script function. This function is the calculator that I referenced earlier in this post.\ncalculator() { case $3 in \u0026#34;+\u0026#34;) result=$(($1 + $2)) ;; \u0026#34;-\u0026#34;) result=$(($1 - $2)) ;; \u0026#34;*\u0026#34;) result=$(($1 * $2)) ;; \u0026#34;/\u0026#34;) result=$(($1 / $2)) ;; *) echo \u0026#34;Invalid operator.\u0026#34; return 1 ;; esac echo \u0026#34;Result: $result\u0026#34; return 0 } This calculator example will take three parameters or arguments. The first argument is the first number, then another number, and the third is the mathematical operator you want to use. There is limited error checking done here, just checking for an invalid operator, we do not verify the first two arguments are actual numbers. How would you call this bash function with arguments?\nUsing Arguments in a Bash Function Bash works a bit differently when it comes to arguments in a function as you can tell from the above example. Typically, when you declare a function you would also include the possible parameters, such as \u0026ldquo;function_name(int x, int y, string z)\u0026rdquo; for example. In bash, you don\u0026rsquo;t declare the arguments in the function definition at all. We simply refer to parameters within the body of the function using a \u0026ldquo;$\u0026rdquo; followed by the number of the argument in order starting with 1.\nIn the example above, you can see that we use arguments $1, $2, and $3. The \u0026ldquo;case\u0026rdquo; statement and usage may be unfamiliar to you and that\u0026rsquo;s ok, we will cover it in a future lesson. For now, just understand that for the case we are looking at the 3rd argument which is our mathematical operator. We compare the 3rd argument with the available options +, -, *, or /.\nCalling a Bash Function with Arguments So, how do we call this function with three arguments? Calling a bash function with arguments is also different than other languages. In other languages, you would call a function like this \u0026ldquo;function_name(1, 2, \u0026ldquo;+\u0026rdquo;)\u0026rdquo; for example. In bash, we don\u0026rsquo;t use parenthesis or commas. To add \u0026ldquo;2+2\u0026rdquo;, this is how the function call would look.\ncalculator 2 2 + # We make sure to put spaces between each argument. If you add that line to the bottom of the script we used above you should see \u0026ldquo;Result: 4\u0026rdquo; output in the terminal. It\u0026rsquo;s important to note that in bash scripts you must declare the function before you use it. If you call a bash function before declaring it, you will get a \u0026ldquo;command not found\u0026rdquo; error message.\nHow to Return Values in Bash Functions Using return values in bash functions is a bit different than in other programming languages too. One of the simplest methods to return something from a function is to set a global variable. By default in bash, all variables declared inside of a function are global. This is another difference when comparing bash with other languages. If you want the variable to be local to the function, you must use the \u0026ldquo;local\u0026rdquo; keyword before the name of the variable.\nReturn Using a Global Variable In the example below, we simply set a global variable and a local variable inside the function body, then reference both variables outside of the function itself. Notice that we fail to get the value of the local variable since it is only valid from within the function body. In order to reference the global variable, we must first call the function.\nreturn_test() { name=thecd # this is a global variable local age=100 # this is a local variable } return_test # here we call the function echo $name # here we echo the global variable echo $age # here we attempt to call the local variable which fails Using the Return Keyword In most programming languages, you can use the \u0026ldquo;return\u0026rdquo; keyword to return some type of data. In bash, you can only return a numeric value such as an exit code. You also must access this return value immediately after running the function. In the example below, you\u0026rsquo;ll see that we return 100 and it shows up in the output the first time. The next time we try to access it, we get 0 instead of 100. This is because we access the return value using the special variable \u0026ldquo;#?\u0026rdquo;. This variable gives us the exit code of the last thing that bash ran. The second time we call \u0026ldquo;#?\u0026rdquo;, the function was no longer the last thing that ran, which is why we don\u0026rsquo;t get 100 as you might expect.\nAssign the Output of a Function to a Variable One last example of getting a return value from a function is to assign the result to a variable. In this bash function example, we echo \u0026ldquo;credibleDEV\u0026rdquo; in the body of the function, then we assign the function to a variable rather than calling it as we have been.\nreturn_test() { echo \u0026#34;credibleDEV\u0026#34; } result=$(return_test) echo $result Conclusion That\u0026rsquo;s it for part 3 of the beginner\u0026rsquo;s guide to bash scripting. Stay tuned for part 4 as we continue learning! Give us a follow on Twitter so you don\u0026rsquo;t miss out and check out our YouTube channel as well for more content!\n","permalink":"http://localhost:1313/part-3-beginners-guide-to-bash-scripting/","summary":"This guide is part of a series, be sure to check out the other parts as well.\nPart 1 - Introduction to Bash, Variables, Comments, User Input\nPart 2 - If/Else Statements, Looping\nPart 3 - Functions in Bash (This Page)\nPart 4 - Creating Menus in Bash\nWelcome back to Part 3 of our Beginners Guide to Bash Scripting. In this guide, we\u0026rsquo;ll be talking about functions in bash scripting.","title":"Part 3 – Beginners Guide to Bash Scripting"},{"content":"GCC which stands for GNU Compiler Collection, is a collection of compilers for many different languages on Linux. For example, GCC can compile source code from C, C++, Fortran, Go, Objective C, and more. GCC is compatible with a long list of architectures, such as i386, ia64, ARM, and more.\nIs GCC Just for Linux? No, GCC is not limited to Linux. GCC stands for GNU Compiler Collection and is developed by the Free Software Foundation as part of the GNU project. GCC supports many different operating systems including Linux but also supports other platforms such as Solaris, Microsoft Windows, macOS, and many others. So, GCC is not just for Linux, but it is also available for a wide range of other operating systems.\nWhat is GCC Used For? It is used to compile the source code of a program written in one of the languages mentioned above into machine-readable binary code that can be executed on a computer. GCC is widely used as the default compiler on many Linux distributions, and it\u0026rsquo;s also used on other platforms like macOS and Windows. GCC is known for its ability to generate efficient code for various computer architectures, its support for multiple languages, and its debugging features. Additionally, GCC provides many features for optimized code generation, making it an important tool for software development.\nIs GCC Installed on Linux? In some cases yes, but not all Linux Distributions include GCC by default. Older versions of Ubuntu, such as 18.04 or 20.04 does not come with GCC installed. The newer versions of Ubuntu do have GCC installed by default though.\nHow Do I Install GCC on Ubuntu? First, check to make sure that GCC is not already installed. You can do a quick check for this in the terminal by running the following command.\nCheck if GCC is Installed gcc -v If you get an error, then GCC is not installed. If you see a version number output in the terminal, then GCC is already installed on your computer.\nInstall GCC Through the Build-Essential Package One of the most common ways to install GCC on Ubuntu is through the \u0026ldquo;build-essential\u0026rdquo; package in APT. This package includes more than just GCC though, below you will find a list of what is included.\ndpkg-dev\ngcc\ngcc++\nlibc6-dev\nmake\nsudo apt install build-essential Install Only GCC on Ubuntu In some cases, you may only want the GCC package. You are not required to install the build-essential package on Ubuntu, instead, you can install GCC by itself using APT.\nsudo apt install gcc How to Compile a C Program with GCC Compiling a simple C program is easy using GCC. Here, we will create a sample C program that you can compile using GCC. Our example is just a simple guessing game but it\u0026rsquo;s a fun way to test that your GCC compiler is working. Open up your favorite editor and paste in the following code for our game.\nExample C Program #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; #include \u0026lt;time.h\u0026gt; int main(int argc, char *argv[]) { int secret, guess; srand(time(NULL)); secret = rand() % 100 + 1; // Generate a random number between 1 and 100 printf(\u0026#34;Guess a number between 1 and 100: \u0026#34;); while (scanf(\u0026#34;%d\u0026#34;, \u0026amp;guess) == 1) { if (guess \u0026lt; secret) { printf(\u0026#34;Too low. Try again: \u0026#34;); } else if (guess \u0026gt; secret) { printf(\u0026#34;Too high. Try again: \u0026#34;); } else { printf(\u0026#34;You got it!\\n\u0026#34;); break; } } return 0; } Assume that we save this code to a file called \u0026ldquo;guessinggame.c\u0026rdquo;. We can compile this into an executable program by using GCC like so. This will output an executable called \u0026ldquo;GG\u0026rdquo;.\nCompiling C with GCC gcc guessinggame.c -o GG When we run the game in the terminal, we will be asked to guess numbers until we get it right. Fun, right?\nRunning the Example C Program Now go have fun writing a new program and use GCC to compile it. If you have questions, let me know in the comments.\n","permalink":"http://localhost:1313/install-gcc-on-ubuntu-linux/","summary":"GCC which stands for GNU Compiler Collection, is a collection of compilers for many different languages on Linux. For example, GCC can compile source code from C, C++, Fortran, Go, Objective C, and more. GCC is compatible with a long list of architectures, such as i386, ia64, ARM, and more.\nIs GCC Just for Linux? No, GCC is not limited to Linux. GCC stands for GNU Compiler Collection and is developed by the Free Software Foundation as part of the GNU project.","title":"Install GCC on Ubuntu Linux"},{"content":"This guide is part of a series, be sure to check out the other parts as well.\nPart 1 - Introduction to Bash, Variables, Comments, User Input\nPart 2 - If/Else Statements, Looping (This Page)\nPart 3 - Functions in Bash\nPart 4 - Creating Menus in Bash\nIn this part, we will be covering the following topics related to Bash scripting on Linux.\nIf/Else Statement\nLoops\nBeing able to control the flow, do comparisons, make decisions and loop are all core parts of any programming or scripting language. Bash offers all of these and if you\u0026rsquo;re already familiar with other programming and scripting languages, you will pick up the syntax pretty easily. Let\u0026rsquo;s jump in with if/else statements, you will find many example bash scripts below to help you.\nIf/Else Statements in Bash An if/else statement is exactly what it sounds like. If this, do that, else do this. It\u0026rsquo;s a way to run some sort of check, like a comparison, and take a certain action based on the result of the comparison. Imagine having the user input and number, then we check if the number entered is higher or lower than our number. That\u0026rsquo;s what we will do here as an example. Crack open your text editor and put in the following code.\nmynum=10 read -p \u0026#34;Enter a number: \u0026#34; usernum if [[ $usernum -lt $mynum ]] then echo \u0026#34;Your number is lower than my number.\u0026#34; else echo \u0026#34;Your number is higher than my number.\u0026#34; fi Syntax for IF Statement You\u0026rsquo;ll notice that we start the if statement with \u0026ldquo;if\u0026rdquo; followed by our comparison. Our comparison is wrapped in double brackets and we use \u0026ldquo;-lt\u0026rdquo; as less than. Out action when this is true comes after the \u0026ldquo;then\u0026rdquo; keyword and our false action comes after the \u0026ldquo;else\u0026rdquo; keyword. We end the if statement block with \u0026ldquo;fi\u0026rdquo;, clever huh?\nBasic IF Statement if SOME CONDITION then DO THIS else DO THIS fi So if we run the example code we had above, this is the output we will see.\nUsing Elif (Else If) in Bash We can take this a bit further, just like in many other languages, using \u0026ldquo;elif\u0026rdquo;. This is an else if condition so we can chain another condition into our if statement. Using our previous example, implementing \u0026ldquo;elif\u0026rdquo; may look something like this. The \u0026ldquo;-eq\u0026rdquo; comparison operator shown here means equal.\nmynum=10 read -p \u0026#34;Enter a number: \u0026#34; usernum if [[ $usernum -eq $mynum ]] then echo \u0026#34;You guessed my number, great job!\u0026#34; elif [[ $usernum -lt $mynum ]] then echo \u0026#34;Your number is lower than my number.\u0026#34; else echo \u0026#34;Your number is higher than my number.\u0026#34; fi Get creative, you are not limited to just comparing numbers, you can do much more.\nBash Comparison Operators In addition to what you have already seen, there are other comparison operators that you can use in your scripts. Note that the operator is different if you are working with strings. This list is not all inclusive, there are many other operators available in bash, such as \u0026ldquo;-d\u0026rdquo; to check if a directory exists or \u0026ldquo;-e\u0026rdquo; to check if a file exists.\nOperator Example Operator Description 1 -eq 1 Equal (numbers) 1 -ne 2 Not Equal (numbers) 1 -lt 2 Less Than (Numbers) 2 -gt 1 Greater Than (Numbers) 1 -le 1 Less Than or Equal To (Numbers) 2 -ge 2 Greater Than or Equal To (Numbers) \u0026ldquo;abc\u0026rdquo; = \u0026ldquo;abc\u0026rdquo; or == (depends on syntax) Equal (strings) \u0026ldquo;abc\u0026rdquo; != \u0026ldquo;def\u0026rdquo; Not Equal (strings) \u0026ldquo;a\u0026rdquo; \u0026lt; \u0026ldquo;b\u0026rdquo; Less Than (strings) \u0026ldquo;b\u0026rdquo; \u0026gt; \u0026ldquo;a\u0026rdquo; Greater Than (strings) -n \u0026ldquo;abc\u0026rdquo; String is not empty -z \u0026quot;\u0026quot; String is empty Bash Comparison Operators\nUsing AND and OR in Bash Like many other languages, you can chain conditional together with AND (\u0026amp;\u0026amp;) and OR (||) for more complex checks. Below is an example of multiple conditionals using AND (\u0026amp;\u0026amp;).\nlower=10 upper=20 read -p \u0026#34;Enter a number: \u0026#34; usernum if [[ $usernum -gt $lower ]] \u0026amp;\u0026amp; [[ $usernum -lt $upper ]] then echo \u0026#34;Your number is between 10 and 20\u0026#34; else echo \u0026#34;Your number is not between 10 and 20\u0026#34; fi For Loop in Bash Scripting Looping is an important function and there are multiple types of loops available. The first one we will look at is the for loop. For loops in bash can be slightly confusing at first if you have experience with another language. The good thing is that there are multiple variations of the for loop, so you can choose the one that best suits you.\nStandard For Loop for n in 1 2 3 4 5 6; do echo $n done The code above is a basic for loop in bash. This code will loop over the numbers 1 through 6, assigning them one at a time to the variable n, which will be printed 1 time on each iteration. The result is the numbers 1 through 6 being printed as shown below.\nFor Loop Over a Range The next type of for loop in bash is to loop over a range. Similar to the last example, we can loop over 1 through 6 again, but in a different way. We put our range between curly braces such as {1..10} to run our loop 10 times. A catch with this method is that you cannot use variables in the defined range. So you can\u0026rsquo;t say something like {$start..$finish} for example. If this is something you need to do, take a look at the more familiar for loop version in the next section.\nfor n in {1..6}; do echo $n done If you run this code, the output will look exactly the same as the last example.\nWe can also define the increment value which is set to 1 as default. So if we want to count by 2\u0026rsquo;s, we can use a range like this, {1..6..2}. Let\u0026rsquo;s look at an example.\nfor n in {1..6..2} do echo $n done As you can see in the output below, we start with 1 and then skip a number before printing the next.\nC Style For Loop in Bash This is my favorite type of for loop in bash, mainly because it\u0026rsquo;s the one that looks the most familiar and readable to me. So if you come from a programming background, it\u0026rsquo;s likely that this format will appeal to you.\nBasic Syntax n=10 for ((i=0; i\u0026lt;$n; i++)); do echo $i done To me, this looks more like a for loop than any other variation in bash scripting. When you read it out loud, it just makes more sense to me as well. For i is equal to 0, and i is less than n(10), do this and then increment by 1.\nContinue Statement Being able to have more control from within the for loop is important and the \u0026ldquo;continue\u0026rdquo; statement is one way we can achieve this. The continue statement is used in other programming languages so you may be familiar with it already. When you use \u0026ldquo;continue\u0026rdquo;, you are not breaking out of the loop completely, you are just jumping to the next iteration of the loop. If you need to break out of the loop altogether, you can use the \u0026ldquo;break\u0026rdquo; statement, which is discussed in the next section.\nn=10 mynum=6 for ((i=0; i\u0026lt;$n; i++)); do if [[ $i -eq $mynum ]] then echo \u0026#34;You found my number, it is $mynum\u0026#34; continue fi echo $i done When you run this script, you will notice that we print each value until we get to the number 6, when our comparison is true. At this point, we don\u0026rsquo;t print the number by itself as we did for the other numbers. This is because the continue statement runs, which jumps to the next iteration, skipping the \u0026ldquo;echo $1\u0026rdquo; statement.\nBreak Statement The break statement is useful when we need to end the loop completely. In our last example, we looped over the numbers 0 through 9 and wrote a special statement when we found the target number, 6. What if we want to just end the loop when we find the number? That\u0026rsquo;s where the break statement comes in, let\u0026rsquo;s do that now. Swap out continue for break instead, then run the script again.\nn=10 mynum=6 for ((i=0; i\u0026lt;$n; i++)); do if [[ $i -eq $mynum ]] then echo \u0026#34;You found my number, it is $mynum\u0026#34; break fi echo $i done Notice how now, the loop completely stops when we reach the number 6. Exactly what we wanted.\nOther Loops in Bash Scripting A for loop is not the only type of loop you can use in bash scripting. Like many other langauges we have the \u0026ldquo;while\u0026rdquo; loop and also the \u0026ldquo;until\u0026rdquo; loop. Let\u0026rsquo;s take a quick look at those.\nBash While Loop The while loop is useful, as it allows us to loop until some condition is no longer true. Careful not to create an infinite loop, you need to make sure that your condition becomes false at some point.\nSyntax for the While Loop n=0 while [[ $n -ne 5 ]]; do echo $n ((n++)) done Our while loop will loop and print the value of n, starting at 0 until the condition is false. The condition becomes false when the variable n is equal to 5 and on each iteration we increment n by 1, at which point the loop stops.\nBash Until Loop Another type of loop is the until loop, which is similar to the while loop. The until loop will run until the condition is true, unlike the while loop which ran until the condition became false. If we use the same example as before, we swap out \u0026ldquo;while\u0026rdquo; with \u0026ldquo;until\u0026rdquo; and flip our conditional check to be equal instead of not equal.\nSyntax for Until Loop n=0 until [[ $n -eq 5 ]]; do echo $n ((n++)) done Conclusion Check out Part 3 of the Beginner\u0026rsquo;s Guide to Bash Scripting where we discuss how to use functions.\nLooping and conditionals are important tools that help us control how our script runs and allow it to make decisions. Explore mixing loops with if statements and see what you can create.\n","permalink":"http://localhost:1313/part-2-beginners-guide-to-bash-scripting/","summary":"This guide is part of a series, be sure to check out the other parts as well.\nPart 1 - Introduction to Bash, Variables, Comments, User Input\nPart 2 - If/Else Statements, Looping (This Page)\nPart 3 - Functions in Bash\nPart 4 - Creating Menus in Bash\nIn this part, we will be covering the following topics related to Bash scripting on Linux.\nIf/Else Statement\nLoops\nBeing able to control the flow, do comparisons, make decisions and loop are all core parts of any programming or scripting language.","title":"Part 2 - Beginners Guide to Bash Scripting"},{"content":"Maybe you came to EndeavourOS from another Linux distro like Ubuntu or Manjaro and you are used to having a graphical software package manager. On Manjaro you have pamac which is a really nice counterpart to pacman and AUR command line package managers like yay. When you install EndeavourOS, you may quickly realize that you don\u0026rsquo;t have a graphical package manager by default. In this post, we will explain step by step, how to install pamac on EndeavourOS.\nFor those interested, you can read some background info on why EndeavourOS doesn\u0026rsquo;t already include a GUI package manager.\nWhat is Pamac? Pamac is a graphical package manager for Arch Linux and its derivatives, like Manjaro and EndeavourOS. It provides a user-friendly interface for installing, updating, and managing packages.\nPamac was created as a graphical package manager for Arch Linux and its derivatives, such as Manjaro. The development of Pamac began in early 2013, with the goal of providing a user-friendly graphical interface for managing packages on Arch Linux. Since then, Pamac has been regularly updated and improved, with new features added and bugs fixed.\nToday, Pamac is one of the most popular graphical package managers for Arch Linux and its derivatives, and is widely used by users who prefer a graphical interface for managing their packages. Pamac has become a key component of the Manjaro Linux distribution and continues to be actively developed and maintained by the Manjaro team.\nPamac Install Steps for EndeavourOS Since EndeavourOS comes with yay pre-installed, the installation of pamac is pretty simple. Run the following command in the terminal to install pamac.\nyay -S pamac-aur Resolving the libpamac-git Conflict Error If you see an error in the terminal output when trying to install pamac that mentions libpamac-git, try removing that package manually. When testing this, it seemed that auto-removing libpamac-git during the installation of pamac-aur was causing problems. Removing the package manually resolved the issue.\nyay -R libpamac-git Running Pamac on EndeavourOS To run pamac on EndeavourOS, you can find it in the app menu, typically found under \u0026ldquo;System\u0026rdquo; or \u0026ldquo;Settings\u0026rdquo; as \u0026ldquo;Add/Remove Software\u0026rdquo;. You can also run pamac from the command line.\npamac-manager Are There Alternatives to Pamac? Sure, one popular alternative to pamac on EndeavourOS and other Arch Linux distros is Octopi. Octopi is similar to pamac but Octopi also features a system upgrade function and the ability to view detailed information about packages, including dependencies and files. You can install Octopi on EndeavourOS with the following command.\nyay -S octopi After installing Octopi, you will find it in the application menu under \u0026ldquo;System\u0026rdquo; or \u0026ldquo;Settings\u0026rdquo; as Octopi.\nConclusion You now have a graphical frontend to your package management on EndeavourOS whenever you need it. You can still use the powerful pacman and yay as well, this is simply just another option for those who love the GUI. If you have any questions or run into issues, let me know in the comments.\n","permalink":"http://localhost:1313/install-pamac-on-endeavouros/","summary":"Maybe you came to EndeavourOS from another Linux distro like Ubuntu or Manjaro and you are used to having a graphical software package manager. On Manjaro you have pamac which is a really nice counterpart to pacman and AUR command line package managers like yay. When you install EndeavourOS, you may quickly realize that you don\u0026rsquo;t have a graphical package manager by default. In this post, we will explain step by step, how to install pamac on EndeavourOS.","title":"Install Pamac on EndeavourOS"},{"content":"Are you tired of manually performing repetitive tasks on the command line? Well, have no fear because bash scripting is here! This beginner\u0026rsquo;s guide to bash scripting will take you from a basic command line user to a bash scripting pro in no time. Say goodbye to manual labor and hello to automation. Whether you\u0026rsquo;re a seasoned developer or just starting out, this guide will provide you with the fundamentals of bash scripting and how to use it to streamline your workflow. So, grab a cup of coffee, get comfortable, and let\u0026rsquo;s dive into the exciting world of bash scripting!\nThis guide is part of a series, be sure to check out the other parts as well.\nPart 1 - Introduction to Bash, Variables, Comments, User Input (This Page)\nPart 2 - If/Else Statements, Looping\nPart 3 - Functions in Bash\nPart 4 - Creating Menus in Bash\nWhat is BASH Scripting? Imagine being able to automate all those tedious, repetitive tasks you do on the command line. No more typing the same commands over and over, no more manual labor! Bash scripting allows you to write a series of commands in a script file and run it as many times as you want, with just one command. It\u0026rsquo;s like having a personal assistant that takes care of the boring stuff for you. With bash scripting, you can turn a 30-minute task into a one-minute task. Trust me, your future self will thank you. It\u0026rsquo;s not just about saving time, though - bash scripts can also help you streamline complex tasks and make them more reliable. Whether you\u0026rsquo;re a sysadmin, a developer, or just a power user, bash scripting is a must-have tool in your toolkit.\nGetting Started with Bash Scripting To follow this beginner\u0026rsquo;s guide to bash scripting, all you need is a Linux computer or virtual machine and a text editor of your choice. Gather your tools and let\u0026rsquo;s get started.\nAt the start of every bash script, you will find something that looks like this \u0026ldquo;#! /bin/bash\u0026rdquo;. This line points to the interpreter that should be used, in this case, bash. This line is commonly referred to as \u0026ldquo;shebang\u0026rdquo;, so if you hear this term, this is likely what they are referring to, or at least the \u0026ldquo;#!\u0026rdquo; portion of the line. The \u0026ldquo;/bin/bash\u0026rdquo; portion is the location on the filesystem where bash is found. This could vary from system to system, you can verify the location by opening a terminal on your machine and running the following command.\nwhich bash This should return the location of bash on your system.\nNow that you know where bash is installed, you can add the first line to your bash script. Your bash script should use the file extension \u0026ldquo;.sh\u0026rdquo;. In your editor of choice, add the shebang line as shown below. Be sure to update the path to match where bash is installed on your system. The editor I\u0026rsquo;m using here is the open-source version of Visual Studio Code, which doesn\u0026rsquo;t include anything proprietary from Microsoft, it\u0026rsquo;s referred to as Code-OSS.\nComments in Bash Let\u0026rsquo;s add a bit more to our first bash script before we try executing it. First, we will add a comment. Comments in bash scripts generally start with the hash symbol, followed by the comment. There are methods for multi-line comments but they are typically avoided as they are difficult to discern from other code. So the single-line comment method is generally preferred by most. Let\u0026rsquo;s add a couple of comments.\nAs you can see, I\u0026rsquo;ve added two comments to the script. The first one is on its own line, while the second is on the same line as an echo statement. Both of these comments are legal in bash scripts. The echo command, if you\u0026rsquo;re not familiar, outputs text to the screen. So in this case, \u0026ldquo;My first bash script\u0026rdquo; will be printed to the terminal screen without the quotes.\nMaking a Bash Script Executable Now that we have our first bash script, we need to make it executable before we can use it. You can make a bash script executable by using the chmod command. The \u0026ldquo;+x\u0026rdquo; option is what is setting our bash script as executable in the command below. Open up your terminal and run this command, replacing the file name with the name you chose for your bash script.\nchmod +x LearnBash.sh Running a Bash Script Now that we have made our bash script executable, we can run it from the terminal. To do so, run the following in your terminal window, remember to replace the name of the file with your file name.\n./LearnBash.sh As you can see, the comments were not printed on the screen, only the text that was echoed. Congrats, you have created and executed your first bash script.\nFundamentals of Bash Script Syntax Now that we have gotten our feet wet with the first bash script, it\u0026rsquo;s time to expand the functionality. Maybe you have been programming in other languages such as Python or Javascript, you\u0026rsquo;ll be happy to know that things such as conditionals, variables, and functions exist in bash scripts as well. So let\u0026rsquo;s go over how to implement them.\nUsing Variables in Bash If you are unfamiliar with variables, to put it in simple terms, they hold data. A variable is made up of a variable name and a value. This value could be a letter, multiple letters, a sentence, numbers, etc. Variables are a handy way to reference this data by a meaningful name. They also make your code easier to understand when used appropriately. Wherever we use the variable, it will be replaced with the data that we stored in it.\nLet\u0026rsquo;s create a couple of variables in our bash script. To properly set a variable, on a new line, you will enter a variable name followed by an \u0026ldquo;=\u0026rdquo; and then the value. You should not have any space between the variable name, the \u0026ldquo;=\u0026rdquo; and the value. If your value has spaces, wrap it in quotes.\n#!/bin/bash # This is a comment echo \u0026#34;My first bash script\u0026#34; # This is also a valid comment # Define a variable called user user=thecd age=99 # Print a sentence using the variables. Prefix the variables with a $ to reference them echo \u0026#34;Hello $user! Wow, you are $age years old!\u0026#34; In the code shown above, we set two variables, one for user and another for age. We then echo those variables out and use them in a sentence.\nMath in Shell Scripts It\u0026rsquo;s common to use calculations of all sorts in programming and you can use the various arithmetic operators in bash to do the same thing. Let\u0026rsquo;s take a look at the available operators and their meanings, then we will look at the usage syntax.\nBash Basic Arithmetic Operators There are a few different ways that you can use these arithmetic operators in a bash script. I find myself using the following method much of the time, mostly because it\u0026rsquo;s the first way that I learned. If you wanted to store the sum of the numbers 2 and 5 into a variable called sum, you could use the following.\nsum=$((2+5)) Another way of doing the same thing is with \u0026ldquo;let\u0026rdquo;.\nlet sum=2+5 We can also use \u0026ldquo;expr\u0026rdquo; for this as well.\nsum=`expr 2 + 5` # Must use a space between the numbers and the operator as shown. #!/bin/bash # This is a comment echo \u0026#34;My first bash script\u0026#34; # This is also a valid comment # Define a variable called user user=thecd age=99 # Print a sentence using the variables. Prefix the variables with a $ to reference them echo \u0026#34;Hello $user! Wow, you are $age years old!\u0026#34; # Exploring Math Operators echo \u0026#34;Let\u0026#39;s do some math\u0026#34; x=2 y=5 echo \u0026#34;$x + $y is $(($x+$y)).\u0026#34; # We can also set the result of a math operation as the value of a variable sum=$(($x+$y)) echo \u0026#34;The sum of x and y is $sum.\u0026#34; # Do the same thing using let let sum2=2+5 echo $sum2 # Same calculation using expr instead sum3=`expr 2 + 5` echo $sum3 Get User Input with Bash A really useful feature of any scripting language is to get input from the user. This is really simple to do with bash scripting so let\u0026rsquo;s add that functionality to our script using the \u0026ldquo;read\u0026rdquo; command. In the below example, we will prompt the user to enter a number, and then store the value they enter into a variable named \u0026ldquo;x\u0026rdquo;. Here you will see the use of \u0026ldquo;-p\u0026rdquo; with the read command which is what tells it to prompt the user.\n# Let\u0026#39;s get some user input read -p \u0026#34;Enter a number: \u0026#34; x read -p \u0026#34;Enter Another Number: \u0026#34; y sum=$(($x+$y)) echo \u0026#34;The sum of x and y is $sum.\u0026#34; Check out Part 2 of the Beginners Guide to Bash Scripting, where we discuss if/else statements and loops.\nThat\u0026rsquo;s it for part 1 of the beginner bash script series. Be sure to check back here soon for part 2, where we will discuss the following topics.\nIf/Else Statements\nLooping\n","permalink":"http://localhost:1313/beginners-guide-to-bash-scripting/","summary":"Are you tired of manually performing repetitive tasks on the command line? Well, have no fear because bash scripting is here! This beginner\u0026rsquo;s guide to bash scripting will take you from a basic command line user to a bash scripting pro in no time. Say goodbye to manual labor and hello to automation. Whether you\u0026rsquo;re a seasoned developer or just starting out, this guide will provide you with the fundamentals of bash scripting and how to use it to streamline your workflow.","title":"Beginners Guide to Bash Scripting"},{"content":"One of the most popular benefits of running an arch-based Linux distribution like Manjaro or EndeavourOS is access to the Arch User Repository, also known as the AUR. Linux distributions typically come with an included software repository which users can easily install software from, and Manjaro is no different. It includes an official software repository that allows access to thousands of software packages. The AUR repository on Manjaro extends this software inventory even further.\nWhat is the AUR Exactly? The AUR is like a big library for Manjaro Linux users. It\u0026rsquo;s made by the community and has tons of software packages that you can install to add new features to your computer. Think of it as a place to find and download new tools and programs for your Manjaro Linux system that aren\u0026rsquo;t available in the regular software store.\nThe AUR differs from the official Manjaro repository in several ways:\nPackage Quality: The AUR packages are not reviewed or tested by Manjaro developers, so the quality of the packages may vary.\nSupport: Official Manjaro repository packages are supported by the Manjaro team, but AUR packages are not.\nPackage Versions: The AUR often has newer versions of software packages than the official Manjaro repository.\nPackage Quantity: The official Manjaro repository has a limited number of packages compared to the AUR, which has many more packages available.\nPackage Availability: Some packages may only be available in the AUR and not in the official Manjaro repository.\nWhat are Some Benefits of Using the AUR? More Packages: The AUR has many more software packages available than the official Manjaro repository.\nNewer Versions: The AUR often has newer versions of software packages than the official Manjaro repository.\nUnique Packages: Some packages may only be available in the AUR, making it a great resource for finding unique and specialized software.\nCommunity-Driven: The AUR is a community-driven repository, so users can contribute and share their own packages with the community.\nEasy to Use: The AUR can be easily accessed and packages can be installed using the Pacman package manager.\nIs the AUR Safe to Use? Using the AUR comes with some risks, as the packages in the AUR are not reviewed or tested by Manjaro developers, and may contain bugs or security vulnerabilities. Here are some steps you can take to reduce the risks of using the AUR:\nRead package descriptions and user comments: This can help you understand what a package does and if there have been any issues with it.\nUse trusted sources: Look for packages that have been frequently downloaded or have positive user comments.\nCheck the code: If you are familiar with programming, you can check the package\u0026rsquo;s source code to see if it contains anything malicious.\nUse a package manager: AUR helpers like yay or pamac can help you manage the installation of AUR packages and also help you keep track of updates.\nHow Do I Enable the AUR on Manajro? The AUR is not enabled by default in Manjaro Linux, but it can be easily enabled by using a package manager such as Pamac or Yay. Here\u0026rsquo;s how you can enable the AUR using Pamac:\nOpen Pamac (Add/Remove Software) from the application launcher.\nGo to the \u0026ldquo;Preferences\u0026rdquo; menu and select the \u0026ldquo;Third Party\u0026rdquo; tab.\nEnable the \u0026ldquo;Enable AUR support\u0026rdquo; option.\nSave the changes.\nThat\u0026rsquo;s it! You can now install packages from the AUR using Pamac. Just search for the package you want to install, select it, and click \u0026ldquo;Install\u0026rdquo;. Pamac will download the package from the AUR and install it for you. If you are on EndeavourOS, the AUR is already enabled and you can install apps by using \u0026ldquo;yay\u0026rdquo; from the command line.\nHow Do I Uninstall an AUR App? To uninstall an AUR app in Manjaro Linux, you will need to use a package manager that supports the AUR, such as Pamac or Yay. Here\u0026rsquo;s how you can uninstall an AUR app using Pamac:\nOpen Pamac from the application launcher.\nGo to the \u0026ldquo;Installed\u0026rdquo; tab.\nFind the AUR app you want to uninstall and click on it.\nClick the \u0026ldquo;Uninstall\u0026rdquo; button which looks like a garbage can.\nConfirm the uninstall by clicking apply.\nThe app and its dependencies will be uninstalled from your system.\nIf you prefer to use the command line, you can use a package manager such as Yay to uninstall an AUR app. For example:\nyay -R app-name Can I Use the AUR From the Command Line? Yes, you can use the AUR from the command line in Manjaro Linux. For this, you will need to install a package manager that supports the AUR, such as Yay, Trizen, or Aurutils. You can use pacman or pamac to install one of these AUR helper tools.\nOnce you have installed a package manager, you can use it to search for packages, install packages, and manage updates from the command line. For example, if you have installed Yay, you can use the following commands to search for and install a package:\nyay -Ss package-name # search for a package yay -S package-name # install a package yay -Syu # update all installed packages, including AUR packages How Do I Add an App to the AUR? To add an app to the AUR, you will need to follow these steps:\nCreate an AUR account: You will need to create an account on the Arch User Repository website to be able to upload packages.\nPackage the app: You will need to create a package for the app, which includes the source code, configuration files, and a PKGBUILD script that defines how the package will be built and installed.\nUpload the package: Once you have created the package, you can upload it to the AUR using the web interface or the AUR command-line tools.\nWait for review: After you upload the package, it will be reviewed by the AUR community to ensure that it complies with the AUR policies and guidelines.\nMake updates: If there are any issues with the package, you will need to make the necessary updates and re-upload the package for review.\nMaintain the package: Once the package is accepted and published on the AUR, you will need to maintain it and make updates as necessary to ensure that it continues to work as expected.\nAdding an app to the AUR can be a complex process, but it is a great way to share your app with the Manjaro community and make it easily accessible to other users. Before you start, make sure you are familiar with the AUR policies and guidelines, and be prepared to invest the time and effort required to package and maintain the app.\nWhat are Some Alternatives to the AUR? Personally, I prefer to install Flatpaks where I can. Apps installed through Flatpaks tend to have fewer dependency related issues and run as the application developer intended. Here are some alternative methods to the AUR for installing software packages.\nOfficial repositories: Manjaro Linux provides a large collection of packages in its official repositories, which are maintained by the Manjaro development team. These packages are tested and supported and are a good place to start if you\u0026rsquo;re looking for a stable and reliable package.\nSnap: Snap is a package manager for Linux that allows you to install and manage applications. It is similar to the AUR in that it provides access to a large repository of packages, but differs in that the packages are pre-packaged and run in a secure sandbox environment.\nFlatpak: Flatpak is another alternative to the AUR, which provides a centralized repository for Linux applications. It allows you to install and manage applications in a similar way to the AUR, but with the added benefit of having more control over the runtime environment.\nAppImages: AppImages are self-contained, portable application packages that can run on most Linux distributions. They are similar to Snap and Flatpak in that they provide a way to install and manage applications, but differ in that they don\u0026rsquo;t require a centralized repository or runtime environment.\nCompiling from source: Another alternative to the AUR is to compile software from source code. This allows you to build the software specifically for your system and gives you complete control over the installation process. However, compiling from source can be more time-consuming and requires a greater understanding of the software and how it is built.\nEach of these alternatives has its own pros and cons, and the best choice for you will depend on your needs and requirements.\nConclusion You are now informed on the AUR, how to use it, and the risks, benefits, and alternatives as well. If you have questions about the AUR or other Manjaro Linux topics, let me know in the comments.\n","permalink":"http://localhost:1313/how-to-enable-the-aur-on-manjaro-linux/","summary":"One of the most popular benefits of running an arch-based Linux distribution like Manjaro or EndeavourOS is access to the Arch User Repository, also known as the AUR. Linux distributions typically come with an included software repository which users can easily install software from, and Manjaro is no different. It includes an official software repository that allows access to thousands of software packages. The AUR repository on Manjaro extends this software inventory even further.","title":"How to Enable the AUR on Manjaro Linux"},{"content":"Many of us remember the Y2K bug, where all computer systems were going to crash and destroy the world. Obviously, that didn\u0026rsquo;t end up happening, thanks to the hard work of programmers and systems admins around the world. The Y2K bug had to do with how dates were used in computer programs. In the early days of computing, storage space was important, so programmers had to write very efficient code in order to not use unnecessary storage space. The difference between 2023 and just using 23 was huge back in that day. By the time the year 2000 rolled around, storage space wasn\u0026rsquo;t as expensive and programmers didn\u0026rsquo;t need to worry about a difference between 2023 and 23 anymore.\nThe 2038 Problem Another issue has the attention of systems admins and programmers, this time it is with how time has been calculated since the 1970s on many computer systems.\nThe UNIX Timestamp which is also referred to as Unix Epoch, considers the start of time to be January 1, 1970. This way of time accounting starts with 0 and counts the seconds since January 1, 1970. This UNIX Timestamp is the basis for time and date calculations on many systems around the world.\nThe issue here is the Unix Timestamp or Epoch is stored as a 32-bit signed number. The maximum value for a 32-bit signed number is 2,147,483,647. That\u0026rsquo;s a pretty big number but in terms of how it is used, this number represents seconds, a relatively small increment of time. Care to guess how many seconds have lapsed since the start of the UNIX Timestamp? At the time of writing this post, that number is currently 1,674,924,554 according to Epoch Converter.\nWe are getting close to the maximum value of a 32-bit signed number, this is the 2038 Problem. Also, known as the Y2K38 bug. So what happens when the seconds try to increment past the maximum value of a 32-bit signed number? Well, the value will start counting up again but this time it will be from its lowest possible value, which is -2,147,483,648.\nSee the problem here? When the Unix Timestamp reaches its maximum value, it will be like going back in time. The lowest value that it will then start counting from would be considered December 13, 1901. So all times and dates that use the Unix Epoch as a basis for calculations will have their value thrown off by this.\nIt\u0026rsquo;s important to note that while we mention Unix here, this doesn\u0026rsquo;t just impact Unix and Linux devices. This form of timestamp has been adopted by many programming languages that run software on all types of devices.\nSo How Do We Fix the 2038 Problem? The solution to this issue, some would say is simpler than the original Y2K bug. The easiest solution is for programmers to switch from 32-bit integers to 64-bit integers for storing this value. Doing so, allows the number to keep counting upward. The Wikipedia page for the problem has a deeper explanation of proposed solutions and some already implemented solutions.\nThe thing to note here is that there is a lot of time left to solve this issue. Awareness of the issue is not an issue, as systems engineers, admins, and programmers are already working on solving the issue. No worries about the Y2K38 problem shutting down your bank or any other core systems.\n","permalink":"http://localhost:1313/the-next-y2k-year-2038-problem/","summary":"Many of us remember the Y2K bug, where all computer systems were going to crash and destroy the world. Obviously, that didn\u0026rsquo;t end up happening, thanks to the hard work of programmers and systems admins around the world. The Y2K bug had to do with how dates were used in computer programs. In the early days of computing, storage space was important, so programmers had to write very efficient code in order to not use unnecessary storage space.","title":"The Next Y2K: Year 2038 Problem"},{"content":"Maybe your school, work, or a client requires you to use OneDrive. What are you to do on Linux, except use the web version of OneDrive? I never realized so many people used OneDrive on Linux but apparently, it\u0026rsquo;s quite common. So today, we will be installing OneDrive on Ubuntu 22.04. We will install both a console version and a GUI version of OneDrive. If you\u0026rsquo;re tired of using the web version or just curious about setting it up, this guide is for you.\nThis guide is made possible by open-source work from two repos, one for the console application and another for the GUI companion app.\nLinux OneDrive Github Repo\nLinux OneDrive GUI Github Repo\nCan I Use OneDrive on Linux? Yes, OneDrive works on Linux through various methods. The method we discuss here will allow you to install the base OneDrive client for Linux but also enables you access to a GUI desktop application as well. There are alternatives, such as using it in the browser but that doesn\u0026rsquo;t let you easily sync files like you can on windows.\nIs OneDrive Supported on Ubuntu? Yes, Microsoft OneDrive is supported on Ubuntu through the use of opensource software.\nIs There a OneDrive Linux GUI? Yes, there is an opensource project called OneDrive-GUI that provides a desktop application. This guide will show you how to install it on Ubuntu.\nInstalling OneDrive on Ubuntu Step 1 - Configure Additional Repo Required for OneDrive The first thing that we need to do is set up the OpenSuSE repo that we will be installing from. According to the documentation for installing OneDrive on Ubuntu, we should NOT use the official Ubuntu repo. Pop open a terminal window and run the following commands to get started.\nThe first command gets the key needed for the repo and the second command adds the repo.\nwget -qO - https://download.opensuse.org/repositories/home:/npreining:/debian-ubuntu-onedrive/Debian_11/Release.key | gpg --dearmor | sudo tee /usr/share/keyrings/obs-onedrive.gpg \u0026gt; /dev/null echo \u0026#34;deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/obs-onedrive.gpg] https://download.opensuse.org/repositories/home:/npreining:/debian-ubuntu-onedrive/Debian_11/ ./\u0026#34; | sudo tee /etc/apt/sources.list.d/onedrive.list Next, you need to do an apt update to sync the new repo that you just added.\nsudo apt update Step 2 - Install OneDrive on Ubuntu To install OneDrive on Ubuntu, we will use APT by running the following command.\nsudo apt install --no-install-recommends --no-install-suggests onedrive Step 3 - Connect OneDrive to our Account Now that we have OneDrive installed, we need to connect the application to our OneDrive account. If you plan to install the GUI application, skip ahead to installing it because it will walk you through this process.\nTo link your OneDrive account, run the following command in the terminal.\nonedrive After you run this command, a link will show up in the terminal. You can hold CTRL and click the link or copy and paste it into your browser. In the browser, you will log in to your OneDrive account and then be sent to a blank page. Once you reach the blank page, you will copy the URL from the address bar and paste it into the terminal.\nYou should then see confirmation that your OneDrive account has been authorized with the OneDrive Linux client.\nStep 4 - Sync OneDrive on Ubuntu We have OneDrive installed and linked to our account, we are ready to sync it now. We can do a test sync first by running the following command.\nonedrive --synchronize --verbose --dry-run When you are ready to do a live sync, you can run the following command.\nonedrive --synchronize When the sync is finished, you will see in the output that the files have been synced to a OneDrive folder inside your Linux home directory.\nStep 5 - Setup Automatic OneDrive Sync Now that you have everything set up and synced, you can continue manually syncing files by running the synchronize command. You can also set up OneDrive as a service on Ubuntu so you don\u0026rsquo;t need to worry about manually syncing. To do this, run the following commands to use systemctl and register OneDrive as a service.\nsystemctl --user enable onedrive systemctl --user start onedrive OneDrive Linux GUI Client Install A separate open-source project offers a GUI front-end for OneDrive on Linux and Ubuntu. It\u0026rsquo;s very easy to get started with because it is a AppImage, which means the install is basically just downloading the AppImage file and making it executable. If you are running Ubuntu 22.04 or higher, there is one package we need to install first.\nsudo apt install libfuse2 Once libfuse2 is installed, we can proceed with downloading the AppImage file. Head over to the projects Github page and download the latest release, currently, that is October 2022.\nAfter the download is complete, navigate to where you downloaded the file in the terminal, then run the following command. You may need to modify the file name if the version has changed since this post was published. This chmod command makes the AppImage file executable so that it will launch properly.\nchmod +x ./OneDriveGUI-1.0.1_fix59-x86_64.AppImage You can now either double-click the file from your file manager to launch it or run it from the command line, \u0026ldquo;./OneDriveGUI-1.0.1_fix59-x86_64.AppImage\u0026rdquo;.\nOnce you launch the application, you will be greeted with a setup wizard. Follow through the wizard and check the option for \u0026ldquo;Create a new OneDrive profile\u0026rdquo;. Fill out the required fields and continue through the process. Once it\u0026rsquo;s complete, click the play button on the main interface which should give you a box explaining how you should click the link, log in to OneDrive and paste the resulting URL back into the program to set up your account.\nOnce the OneDrive client is linked to your OneDrive account, you can once again click the play button on the main interface to start the sync process.\nConclusion That\u0026rsquo;s it, you now have OneDrive installed and set up on an Ubuntu Linux machine. Be sure to check out their official documentation for more options for customized syncing. The GUI app has a lot of advanced sync settings built into its interface as well. If you have any requests or questions, be sure to leave a comment below.\n","permalink":"http://localhost:1313/install-onedrive-gui-on-ubuntu/","summary":"Maybe your school, work, or a client requires you to use OneDrive. What are you to do on Linux, except use the web version of OneDrive? I never realized so many people used OneDrive on Linux but apparently, it\u0026rsquo;s quite common. So today, we will be installing OneDrive on Ubuntu 22.04. We will install both a console version and a GUI version of OneDrive. If you\u0026rsquo;re tired of using the web version or just curious about setting it up, this guide is for you.","title":"Install OneDrive GUI on Ubuntu"},{"content":"Python Flask is a small web development framework written in Python. It allows you to create web applications quickly and easily by providing useful tools and features. You can use it to create a website, a web service, or even a simple web page. It\u0026rsquo;s easy to learn and use, making it a popular choice for beginners and experienced developers alike. Personally, I love Flask. You can quickly spin up a website using the Jinja2 template engine or create a web API to query a backend database or other web API.\nToday, we will set up a Python Flask development environment on Manjaro Linux and then deploy it to a production server running CyberPanel on Ubuntu 22.04 and the OpenLiteSpeed webserver. Let\u0026rsquo;s get started.\nNote: While this guide is written specifically for Manjaro, it will work with other Arch based Linux distributions like EndeavourOS as well.\nStep 1 - Install Python on Manjaro Linux Python should already be installed, as it\u0026rsquo;s typically a default application on Manjaro. Let\u0026rsquo;s double-check by running the following command in the terminal, which should return the specific version of Python installed on your Manjaro machine.\npython3 -V If Python is installed on your system, you should see something similar to the following output in the terminal. The version number may be different for you but that\u0026rsquo;s OK.\nPython 3.10.9 If you don\u0026rsquo;t see Python installed on your Manjaro machine, you can use pacman to get it installed pretty easily. Just run the following command to install the latest available version.\nsudo pacman -S python3 Step 2 - Install Pip for Python 3 The next thing we should do is install \u0026ldquo;pip\u0026rdquo;. Pip is a package manager for Python that we will use to install Flask and other packages that our web app may need. Think of this as the pacman or apt for Python. To install \u0026ldquo;pip\u0026rdquo; on Manjaro, run the following command.\nsudo pacman -S python-pip Step 3 - Set Up a Virtual Environment Virtual environments are important for Python development because you may be working on many Python projects which all share different dependencies. You could have a scenario where you need one version of a package for this app but another version for a different app. A virtual Python environment allows you to separate those projects and their dependencies so that the packages installed are specific to that environment.\nTo set up a new Python virtual environment we will use \u0026ldquo;venv\u0026rdquo; to create an environment called \u0026ldquo;cdflask\u0026rdquo; for example.\npython3 -m venv cdflask Next, we need to activate this new virtual environment. Once activated, the \u0026ldquo;pip install\u0026rdquo; commands will install packages just to that environment. Just swap out \u0026ldquo;cdflask\u0026rdquo; with whatever you named your environment.\nsource cdflask/bin/activate You\u0026rsquo;ll notice that your terminal prompt has changed a bit. It should show (your_environment_name) [username@hostname foldername] or something similar. The important part is that it should show your chosen virtual environment name in parenthesis, this means your virtual environment is now activated.\nStep 4 - Install Flask in the Python Virtual Environment Now that we have the virtual environment set up and activated, we can install the Flask package using pip.\npip install flask Step 5 - Create a Basic Flask App.py File Flask is now installed, so we are ready to create the \u0026ldquo;app.py\u0026rdquo; file which will be our entry point that will display some text as a web page to test everything is working. Open up your favorite editor and create an \u0026ldquo;app.py\u0026rdquo; file inside your virtual environment.\nFirst create a new directory to hold the source files for the app, we will call this folder \u0026ldquo;cdflaskapp\u0026rdquo; for example.\nmkdir cdflaskapp Now go ahead and create your \u0026ldquo;app.py\u0026rdquo; in this new directory with the following Python code as an example and save the file.\napp.py\nfrom flask import Flask app = Flask(__name__) @app.route(\u0026#39;/\u0026#39;) def index(): return \u0026#39;credibleDEV Test\u0026#39; if __name__ == \u0026#39;__main__\u0026#39;: app.run() Step 6 - Start the Flask Development Server To test the flask application, head back to your terminal and run the following command.\nflask run Assuming everything went OK, you should see the output in the terminal similar to the following.\nGreat, this means your Flask app is running. As the output suggests, you can load up a browser and head to http://127.0.0.1:5000 to test your app. You should see something like this if everything worked as expected.\nLet\u0026rsquo;s create a little more fancy using a Jinja2 template and the Bootstrap CSS framework, then we will deploy it to our production OpenLiteSpeed server to show you how that works.\nStep 1 - Creating a Simple Website Using a Jinja2 Template To get started using Jinja templates with our Flask app. Let\u0026rsquo;s create a new directory within our app folder called \u0026ldquo;templates\u0026rdquo;. Then, create an \u0026ldquo;index.html\u0026rdquo; file in the templates directory. Afterward, our directory structure should look like the following.\nInside of our \u0026ldquo;index.html\u0026rdquo; file, let\u0026rsquo;s add the following code as an example.\nindex.html\n\u0026lt;!-- This pulls in the base html file we will create in a moment --\u0026gt; {% extends \u0026#34;base.html\u0026#34; %} \u0026lt;!-- This sets to title variable in the base.html file --\u0026gt; {% block title %}Home{% endblock %} \u0026lt;!-- Everything within this block body will have the base.html applied around it --\u0026gt; {% block body %} \u0026lt;h1\u0026gt;Welcome to {{ sitename }}!\u0026lt;/h1\u0026gt; \u0026lt;p\u0026gt;This is a test Flask app. Be sure to check out the \u0026lt;a href=\u0026#34;https://credibledev.com\u0026#34;\u0026gt;credibleDEV blog\u0026lt;/a\u0026gt;.\u0026lt;/p\u0026gt; {% endblock %} \u0026lt;!-- End the block body tag --\u0026gt; Notice that we don\u0026rsquo;t have the typical open HTML tags or the head tag. We will handle those in separate files so they are uniform across all the pages of our Flask site. This way, each new page we create only needs to have the body or content of the page. The header and footer can be pulled in from the base templates we make for them.\nTo clarify, the content that appears between the {% block body %} and {% endblock %} tags in the index.html file, will be inserted between the {% block body %} and {% endblock %} tags of the base.html file that we are about to create.\nLet\u0026rsquo;s create a \u0026ldquo;base.html\u0026rdquo; file now, so we can put in the standard HTML tags, header, and CSS. This file would include everything that we want to be uniform across the entire site, such as a fancy header for example. We will also have the block body Jinja tag that will pull in the content of other files, like the index.html file for example. Also, the title Jinja variable that is in the index.html file will be inserted into the block title variable of the base.html file.\nThis will all make more sense when you start playing around with it and run a test.\nbase.html\n\u0026lt;!doctype html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;title\u0026gt;{% block title %}{% endblock %} - credibleDEV\u0026lt;/title\u0026gt; \u0026lt;meta name=\u0026#34;viewport\u0026#34; content=\u0026#34;width=device-width, initial-scale=1\u0026#34;\u0026gt; \u0026lt;link rel=\u0026#34;stylesheet\u0026#34; href=\u0026#34;https://cdn.jsdelivr.net/npm/bootstrap@3.4.1/dist/css/bootstrap.min.css\u0026#34; integrity=\u0026#34;sha384-HSMxcRTRxnN+Bdg0JdbxYKrThecOKuH5zCYotlSAcp1+c8xmyTe9GYg1l9a69psu\u0026#34; crossorigin=\u0026#34;anonymous\u0026#34;\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;!-- Start NavBar --\u0026gt; \u0026lt;nav class=\u0026#34;navbar navbar-inverse\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;container\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;navbar-header\u0026#34;\u0026gt; \u0026lt;button type=\u0026#34;button\u0026#34; class=\u0026#34;navbar-toggle collapsed\u0026#34; data-toggle=\u0026#34;collapse\u0026#34; data-target=\u0026#34;#navbar\u0026#34; aria-expanded=\u0026#34;false\u0026#34; aria-controls=\u0026#34;navbar\u0026#34;\u0026gt; \u0026lt;span class=\u0026#34;sr-only\u0026#34;\u0026gt;Toggle navigation\u0026lt;/span\u0026gt; \u0026lt;span class=\u0026#34;icon-bar\u0026#34;\u0026gt;\u0026lt;/span\u0026gt; \u0026lt;span class=\u0026#34;icon-bar\u0026#34;\u0026gt;\u0026lt;/span\u0026gt; \u0026lt;span class=\u0026#34;icon-bar\u0026#34;\u0026gt;\u0026lt;/span\u0026gt; \u0026lt;/button\u0026gt; \u0026lt;a class=\u0026#34;navbar-brand\u0026#34; href=\u0026#34;#\u0026#34;\u0026gt;credibleDEV\u0026lt;/a\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;div id=\u0026#34;navbar\u0026#34; class=\u0026#34;collapse navbar-collapse\u0026#34;\u0026gt; \u0026lt;ul class=\u0026#34;nav navbar-nav\u0026#34;\u0026gt; \u0026lt;li class=\u0026#34;active\u0026#34;\u0026gt;\u0026lt;a href=\u0026#34;#\u0026#34;\u0026gt;Home\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;li\u0026gt;\u0026lt;a href=\u0026#34;#\u0026#34;\u0026gt;About\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;li\u0026gt;\u0026lt;a href=\u0026#34;#\u0026#34;\u0026gt;Contact\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;/ul\u0026gt; \u0026lt;/div\u0026gt;\u0026lt;!--/.nav-collapse --\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/nav\u0026gt; \u0026lt;!-- End NavBar --\u0026gt; \u0026lt;div class=\u0026#34;container\u0026#34;\u0026gt; \u0026lt;div class=\u0026#34;starter-template\u0026#34;\u0026gt; \u0026lt;!-- Page Content Here --\u0026gt; {% block body %} {% endblock %} \u0026lt;!-- End Page Content --\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; To test this out, we need to make a modification to the app.py file that we created earlier. We need to tell the Flask app to use Jinja with the render_template function and pass it in our index.html file so that it displays when users visit our site. We will also pass a variable to the template that will show up in the Welcome to {{ sitename }}! part of our index page. Additionally, we need to add an import at the top for render_template.\napp.py\nfrom flask import Flask, render_template app = Flask(__name__) @app.route(\u0026#39;/\u0026#39;) def index(): sitename = \u0026#34;credibleDEV\u0026#34; return render_template(\u0026#34;index.html\u0026#34;, sitename=sitename) if __name__ == \u0026#39;__main__\u0026#39;: app.run() Step 2 - Testing our Flask App Now that everything is updated, let\u0026rsquo;s test it out. If you still have the \u0026ldquo;flask run\u0026rdquo; command executing in your terminal, press CTRL+C to shut it down. Then launch it again using \u0026ldquo;flask run\u0026rdquo;. You can then refresh the page or open a new tab and go to http://127.0.0.1:5000 once again. You should see that your page looks much nicer now.\nAwesome, what a beautiful start to a site, without much work at all. Now it\u0026rsquo;s time to deploy this Flask website to our production OpenLiteSpeed server.\nStep 3 - Set Up Our Flask App to Run on the Litespeed Server The production server is running on Linode, with Ubuntu 20.04, the CyberPanel management panel, and OpenLiteSpeed. Your setup may be different, such as Apache for example. So the steps may be slightly different for you in that case. The important thing here is that while you could technically just run the Flask app directly on the production server, that\u0026rsquo;s not what you want to do. You want OpenLiteSpeed, Apache, or whatever web server software, to handle the HTTP request and deliver your site to the end user.\nInstall Python and Pip on Ubuntu CyberPanel Server The first thing we need to do is get Python3 and Pip installed on our Ubuntu server. So go ahead and SSH into your server to get a terminal, then run the following command.\nYou need to SSH with a root account or one that has sudo privileges.\nsudo apt install python3 python3-pip Install the wsgi-lsapi Package Next, we need to install the wsgi-lsapi package from LiteSpeed. You can find more information on the official LightSpeed API Downloads page, look for \u0026ldquo;Python Module\u0026rdquo;. Run the following commands to complete the installation for wsgi-lsapi.\ncurl -O https://www.litespeedtech.com/packages/lsapi/wsgi-lsapi-2.1.tgz tar xf wsgi-lsapi-2.1.tgz sudo mv wsgi-lsapi-2.1 /usr/local/lsws cd /usr/local/lsws/wsgi-lsapi-2.1 python3 ./configure make sudo mv lswsgi /usr/local/lsws/fcgi-bin Setup a Python Virtual Environment on our Server Now you need to SSH as the hosting account user instead of root. You may need to enable and set up SSH access for the account from CyberPanel. To do this, use the menu on the left of CyberPanel, click Websites, List Websites, and click on manage for the website you are setting up. At the top, there is a button to set up SSH access.\nAfter getting everything installed above, it\u0026rsquo;s time to set up a new virtual environment on our server. If you\u0026rsquo;re using cyberpanel, your websites are likely listed in the /home directory, so /home/example.com. Use the terminal to CD to that directory.\ncd /home/example.com Now we set up and activate the virtual environment using Python. You can call it whatever you like, I chose cdflask here.\npython3 -m virtualenv venv source venv/bin/activate Install Flask in our Python Virtual Environment We are ready to install the Flask package inside our virtual environment now.\npip3 install flask Create a Directory for our App Files Now we need to create a directory to upload our Flask app.\nmkdir /home/example.com/public_html/cdflask Next, upload the files we created earlier to this directory. You can use the CyberPanel file manager, SFTP, or whatever method you like. Don\u0026rsquo;t get too excited yet, we need to add a new file and edit our app.py file as well before we are finished. Almost there though.\nSetup our wsgi.py File and Edit app.py Create a new file in the public_html directory called \u0026ldquo;wsgi.py\u0026rdquo;. Put the following in that file, swap out the \u0026ldquo;from cdflask\u0026rdquo; part to match your directory though if you chose a different name.\n/home/example.com/public_html/wsgi.py\n#!/usr/bin/env python import sys sys.path.insert(0, \u0026#39;/home/example.com/public_html\u0026#39;) from cdflask import app as application Next, rename your app.py file to __init__.py and remove the if statement and app.run section that was at the bottom so it looks like this.\n/home/example.com/public_html/cdflask/__init__.py\nfrom flask import Flask, render_template app = Flask(__name__) @app.route(\u0026#39;/\u0026#39;) def index(): sitename = \u0026#34;credibleDEV Test Flask Site\u0026#34; return render_template(\u0026#34;index.html\u0026#34;, sitename=sitename) Configure LiteSpeed to Run our Python Flask App We have our app files configured so the next step is to configure the LiteSpeed web server to run our Flask app for us and then serve it to users from the http://example.com/cdflask address. You can also serve it from the root of the domain if you wish, that\u0026rsquo;s up to you. To do that, you will want to change the URI setting in the next section to be just \u0026ldquo;/\u0026rdquo; instead of \u0026ldquo;/cdflask\u0026rdquo;.\nTo get started, head to your LiteSpeed WebAdmin page, typically accessed on port 7080. Once there, choose \u0026ldquo;Virtual Hosts\u0026rdquo; from the left-side menu. In the list of domains, click the magnifying glass next to the domain you want to set up Flask on.\nOn the next page, click the \u0026ldquo;Context\u0026rdquo; tab and then click the Add button found on the right.\nOn the following page, you will select \u0026ldquo;App Server\u0026rdquo; as the type and then click the poorly designed next button.\nNow we will configure the specifics so that LiteSpeed will run and show our Python Flask app to the end user. Remember, if you want users to see your page by going to http://example.com/ then change the URI here to \u0026ldquo;/\u0026rdquo;.\nURI - /cdflask\nLocation - /home/example.com/public_html/cdflask\nBinary Path - /usr/local/lsws/fcgi-bin/lswsgi\nApplication Type - WSGI\nStartup File - wsgi.py\nEnvironment - PYTHONPATH=/home/example.com/venv/lib/python3.8:/home/example.com/public_html/cdflask\nEnvironment - LS_PYTHONBIN=/home/example.com/venv/bin/python3\nOnce you\u0026rsquo;re finished, click the save button at the top right. You will be instructed to gracefully restart the server. You can do this by clicking on your hostname at the top left of the page and choosing \u0026ldquo;Graceful Restart\u0026rdquo; from the popup menu.\nTesting our Python Flask App with LiteSpeed After running the graceful restart, you are ready to test your site.\nTroubleshooting and Changes If you run into issues getting your Python Flask app to run on LiteSpeed and you need to make modifications. Run the following in the terminal to restart the app to test out your changes. You will also do this if you update the website or app.\nsudo killall lswsgi Conclusion Congrats! You now have learned how to set up a Python app to run on LiteSpeed using CyberPanel. If you run into issues or have any questions, let me know in the comments!\n","permalink":"http://localhost:1313/python-flask-dev-environment-on-manjaro-linux/","summary":"Python Flask is a small web development framework written in Python. It allows you to create web applications quickly and easily by providing useful tools and features. You can use it to create a website, a web service, or even a simple web page. It\u0026rsquo;s easy to learn and use, making it a popular choice for beginners and experienced developers alike. Personally, I love Flask. You can quickly spin up a website using the Jinja2 template engine or create a web API to query a backend database or other web API.","title":"Python Flask Dev Environment on Manjaro Linux"},{"content":"You may have seen the term immutable OS thrown around lately and wondered what it is and what is means. While an immutable OS isn\u0026rsquo;t exactly new, they have become more popular in recent months. So let\u0026rsquo;s break down what exactly an immutable OS is, how it can benefit you as well as the potential drawbacks of using one.\nSimple Description of an Immutable OS An immutable operating system is pretty much like an unchangeable one. Imagine a computer system that once it\u0026rsquo;s set up, can\u0026rsquo;t be altered or modified in any way. It\u0026rsquo;s like a locked box that can only be opened with a specific key, and once it\u0026rsquo;s open, you can\u0026rsquo;t change anything inside. This type of operating system is great for security purposes since it prevents any unwanted changes or tampering. Plus, it makes it easy to revert back to a previous state if something goes wrong. So, if you\u0026rsquo;re looking for an ultra-secure operating system, an immutable one might be the way to go.\nWhat are the Benefits of an Immutable OS? Security: Since an immutable OS can\u0026rsquo;t be modified, it eliminates the risk of unwanted changes or malware getting on your system.\nReliability: If something goes wrong, you can easily roll back to a previous state and get the system back up and running quickly.\nEasy Management: Automated tools and scripts can be used to manage everything which saves a lot of time and hassle.\nDowntime Reduction: Updating an immutable OS is typically automated, which minimizes downtime and prevents errors.\nFlexibility: you can run multiple applications in different containers or virtual machines, which allows you to update or roll back an application without affecting the whole system.\nReduced Costs: since the operating system is read-only, it means that there is no need to worry about keeping software up to date or configuring things manually, which can save you a lot of money in the long run.\nBetter Scalability: Immutable infrastructure enables fast and reliable scaling of applications, as new servers can be quickly and easily provisioned with the same configuration as existing servers.\nWhat are the Drawbacks of an Immutable OS? Learning Curve: It may take some time to get used to working with an immutable operating system, especially if you\u0026rsquo;re used to traditional operating systems.\nLimited Customization: Since the operating system is read-only, it can be more difficult to customize and configure it to suit your specific needs.\nRequires Containerization or Virtualization: To install or update software, you need to use containerization or virtualization techniques, which can be more complex than traditional methods. Flatpaks are great for an immutable OS since they already meet this requirement.\nRequires Extra Storage: Since you need to keep multiple copies of the operating system (to roll back to a previous state), it can require more storage space.\nLimited Software Availability: Some software may not be compatible with an immutable operating system, which can limit your options for running certain applications.\nMore Steps to Update: Updating an immutable operating system requires more steps than traditional systems, and requires the creation of a new image of the operating system with updated software and then replacing the old one. This is typically automated in many situations though, so these steps would be transparent to the user.\nWill an Immutable OS Protect Against Ransomware Attacks? An immutable operating system can help keep your computer safe from ransomware, but it\u0026rsquo;s not a magic bullet. Since the operating system can\u0026rsquo;t be changed, malware or ransomware can\u0026rsquo;t make changes to it, which means it can\u0026rsquo;t encrypt your files or cause damage. And if something does happen, you can easily roll back to a previous state and fix the problem. But, keep in mind that ransomware can still target your data, like the files on your shared network drive, so it\u0026rsquo;s important to have a backup plan in place. Also, an immutable operating system can only protect you from ransomware that targets the operating system itself, it can\u0026rsquo;t protect you from phishing scams or other types of attacks. So, while an immutable operating system is a good way to add an extra layer of security, it\u0026rsquo;s not the only solution you should rely on.\nDoes an Immutable OS Mean My Personal Files Are Immutable? An immutable operating system just means that the operating system itself can\u0026rsquo;t be changed, but it doesn\u0026rsquo;t mean your personal files are also immutable. So, in most cases, your personal files can still be changed, deleted, or encrypted by malware or ransomware. That\u0026rsquo;s why it\u0026rsquo;s important to have a backup plan in place to protect your personal files. However, there are some ways to make your personal files immutable too. For example, some file systems allow you to make files immutable, and some backup solutions allow you to create immutable backups of your files. But overall, while an immutable operating system is a good way to add an extra layer of security, it\u0026rsquo;s important to think about how to protect your personal files as well.\nWhat are Some Examples of Immutable Operating Systems? Fedora Silverblue: Provides a similar experience to Fedora Workstation but with an immutable design.\nVanilla OS: Based on Ubuntu and includes Flatpak, Snap, and AppImage support for installing apps.\nOthers are more geared towards IoT and enterprise uses such as Ubuntu Core, Fedora CoreOS, and RancherOS.\nHow do Updates Work in Fedora Silverblue? Updates to the operating system are delivered in the form of new images that replace the existing image. When an update is available, Fedora Silverblue will download the new image in the background and then reboot it into the new image, effectively replacing the old image. This process is known as \u0026ldquo;ostree rollback\u0026rdquo;, and it allows you to easily roll back to a previous version of the operating system if there\u0026rsquo;s a problem with the update.\nThe updates are delivered through \u0026ldquo;rpm-ostree\u0026rdquo; which is a package manager that\u0026rsquo;s specifically designed for use with immutable operating systems. It uses a combination of traditional RPM packages and a git-like branching system to manage updates.\nUsers can also update their system using the command line, using the \u0026ldquo;rpm-ostree upgrade\u0026rdquo; command to update the system, and \u0026ldquo;rpm-ostree rollback\u0026rdquo; command to go back to the previous version.\nShould You Run Fedora Silverblue on a Personal Desktop? Whether or not you should run Fedora Silverblue on a personal desktop depends on your needs and preferences. However, Silverblue is meant to provide a similar experience to Fedora Workstation. So, you can install and use it on personal devices and most likely do so without many or any issues at all. You may need to learn new ways to do things you did before such as install gnome-tweaks which should be done using the \u0026ldquo;toolbox\u0026rdquo;. If you already use a lot of Flatpaks, those are perfect and actually preferred in Silverblue since the /var directory is mutable and those apps will install there.\n","permalink":"http://localhost:1313/what-is-an-immutable-os/","summary":"You may have seen the term immutable OS thrown around lately and wondered what it is and what is means. While an immutable OS isn\u0026rsquo;t exactly new, they have become more popular in recent months. So let\u0026rsquo;s break down what exactly an immutable OS is, how it can benefit you as well as the potential drawbacks of using one.\nSimple Description of an Immutable OS An immutable operating system is pretty much like an unchangeable one.","title":"What is an Immutable OS?"},{"content":"Let\u0026rsquo;s be honest, there are tons of web hosting providers out there who all claim to be the best, the fastest, or offer the most extras. Trying to weed through all of the providers and all of the opinions of folks on YouTube and blogs isn\u0026rsquo;t easy either. It will likely leave you feeling cheated or confused. So I\u0026rsquo;m going to throw my hat into the ring of who is the best web hosting provider for WordPress using my own experience with 3 different providers. The option I\u0026rsquo;m going to give you isn\u0026rsquo;t just the best hosting provider for WordPress sites though, you can host all sorts of sites or servers. Maybe you have a guess of where I\u0026rsquo;m going here.\nhttps://www.youtube.com/watch?v=Ulm3ardtm7A\nThe Backstory of My Web Hosting Journey For a little background, I originally hosted my sites with Vultr, which is a cloud service provider much like AWS, Azure, and others, just on a smaller scale I would say. Vultr allowed you to set up a Linux or Windows virtual private server, also known as a VPS. Vultr was OK, but I found myself running into issues with the IP being blacklisted or on spam lists, which hurts email delivery and SEO.\nAfter some time, I decided to try out Linode for hosting my websites and other projects. My decision was based on the many YouTubers who recommended them on basically every channel I watched. I was able to give them a try using a new customer credit at the time so I wasn\u0026rsquo;t losing much.\nLong story short, I have stuck with Linode for years now. Not just for typical web hosting, like a WordPress site, but also for many personal projects that ran on Node JS or Python Flask. You can really do almost anything with a cloud VPS because the server is in your full control. Unlike many shared hosting providers who limit you on the types of services or apps that you can host on their service. Shared hosting is getting better, I\u0026rsquo;ll give them credit for that, you can now host other types of web apps on many shared hosts, but it\u0026rsquo;s still limited in comparison.\nI said long story short, but here I am, still going on. Let\u0026rsquo;s cut to the chase here. I\u0026rsquo;ve been hosting this website on Linode since I started it. Using a Linux VPS that I set up from scratch, running on Apache. I had grown dissatisfied with the speed of my site, so I set out to try one of the most commonly recommended WordPress hosts, Bluehost. I didn\u0026rsquo;t go for the cheapest plan, I picked a middle-of-the-road plan, so I expected decent results. Sadly I didn\u0026rsquo;t get the results I would have expected and my WordPress site performance was even worse than on my Linode VPS.\nSo here I am, upset with my decision but also not satisfied with the old solution either, what do I do? All I want is reliable, secure, and fast web hosting for my WordPress site. After some research, I discovered a website panel called CyberPanel. My last server on Linode was set up completely by hand so there were probably some optimizations missing that could have made it better. I read plenty of great reviews about CyberPanel, especially since it uses OpenLiteSpeed as the web server back-end.\nSo back to Linode I go, to set up a brand new server and I wasn\u0026rsquo;t surprised to find that Linode has CyberPanel in the marketplace. This means, I don\u0026rsquo;t have to manually set up this server and I also don\u0026rsquo;t have to worry about the install steps and requirements of CyberPanel. Linode took care of everything and the setup was simple. Within about 20 minutes, my new Linode was ready to be the new web host for my WordPress site.\nNot only was the setup fast and easy, but my website is also blazing fast thanks to OpenLiteSpeed and the LS-Cache plugin. Couple that with Cloudflare, and you can\u0026rsquo;t beat it in my opinion.\nLet\u0026rsquo;s go over the steps to get CyberPanel set up on Linode so you can be your very own, and fast WordPress web host.\nSetup a New CyberPanel Server on Linode The first step here is going to be getting a Linode account if you don\u0026rsquo;t already have one. I have an offer listed here that will get you a free $100 credit to use within 60 days. You can use it if you wish, I will get a little money in my pocket if you stick with them and spend a little of your own money. You can also just head straight to Linode.com as well if you wish, I don\u0026rsquo;t mind.\nTake advantage of the free $100 60-day credit using this link. Plus, you’re helping me to keep creating content.\nOnce you have your Linode account set up, you should see a green button in the middle of the screen that allows you to create a new Linode. If you already have a Linode, the button to create a new Linode will be at the top right of the page and the top left.\nOnce you\u0026rsquo;re on the screen to create a new Linode, you want to choose the Marketplace tab and find CyberPanel. You can find it under popular apps or type \u0026ldquo;cyberpanel\u0026rdquo; into the search box. Go ahead and click on it once you find it.\nAfter you have selected CyberPanel, scroll down the page and choose your image. I recommend choosing the Ubuntu 20.04 LTS option for your VPS OS. Pick a region that is close to where your customers will be. Next, you will pick the plan for your Linode. Based on my experience, you should choose at least the $10 2GB plan for good performance.\nGo ahead and give your server a label, this can be whatever you wish. After this, set a secure root password and the rest of the options can be left as they are. When you are finished, go to the bottom of the page and click on the \u0026ldquo;Create Linode\u0026rdquo; button.\nNow we wait, go get a cup of Coffee, or maybe even check out the credibleDEV YouTube or Twitter. This process will probably take 20 minutes or so, depending on the plan you chose. The $5 1GB Linode plan is quite slow in getting set up, I wouldn\u0026rsquo;t recommend it for CyberPanel.\nHow will you know when it\u0026rsquo;s done? Easy, just open a web browser to the IP of your Linode on port 8090 like this, http://ipaddress:8090. If the CyberPanel page opens, things are ready. If not, just wait a little longer and try again.\nLogging into CyberPanel for the First Time Great, so now, how do you login? We need to get the admin password, this will be different than the root password you created earlier. To get this, you need to SSH to the server. If you are not familiar with how to use SSH, I have a guide that will help you which was part of a Linode VPS setup series I did.\nOnce you are connected with SSH, login as root and you should see the following output in the terminal.\nIn this output, it is telling you that you need to run a command in the SSH session to get the admin account password for CyberPanel. Go ahead and do that and then head back to your browser to login as the admin user.\nCreating a New Website in CyberPanel Now that you are logged in, go ahead and click on the \u0026ldquo;Websites\u0026rdquo; button, then click on \u0026ldquo;Create a Website\u0026rdquo; on the following page. Here you will fill out the required details to get the website created.\nPackage - It\u0026rsquo;s ok to select the default here.\nOwner - You can select admin here unless you want to create a new user first.\nTest Domain - This is an add-on feature that comes at a cost, uncheck this for now.\nDomain Name - Put in your website domain name here.\nEmail - Your email address.\nPHP - Select the version of PHP you wish to use for this site. 7.4 or 8.1 should be OK for WordPress.\nSSL - You want to check this so your site is protected by SSL.\nDKIM Support - This is related to email, if you plan to use email on your domain, check this box.\nopen_basedir Protection - This is for security, you will want to check this box.\nCreate Mail Domain - If you plan to use email, check this box.\nAfter all of the details are filled in, click the button to create the website. This should only take a minute or so.\nPoint Your Domain Name to CyberPanel Now that the website is set up on the CyberPanel side, we need to point our domain name to the Linode server. This isn\u0026rsquo;t too difficult but the process is going to be different depending on which domain registrar your domain is with. My domain is with NameCheap so I can show you how this works there. If you have GoDaddy, this page may help you out.\nThe goal here is the create host entries for NS1.YOURDOMAIN.COM and NS2.YOURDOMAIN.com, both of which will point to the IP address of your Linode server.\nOn NameCheap, head to the domain, then choose \u0026ldquo;Advanced DNS\u0026rdquo;. At the bottom of the page, you will see an option for \u0026ldquo;Add Nameserver\u0026rdquo;. Choose that option and add an entry for ns1, pointing to your Linode server IP, then do the same thing for ns2.\nAfter you have these added, head back to the \u0026ldquo;Domain\u0026rdquo; tab, and update your name servers to NS1.YOURDOMAIN.COM and NS2.YOURDOMAIN.COM.\nNow that you have this updated, it may take some time for DNS propagation to take place. Sometimes it\u0026rsquo;s quick, other times it can take a couple of hours. One way to check is to use a website like https://dnschecker.org/. Go there, put in your domain name, and check if the IP\u0026rsquo;s listed are pointing to your Linode IP address. If all of them are, there is a good chance things are ready to go.\nAdd an SSL Certificate to Your CyberPanel Website Now that our domain is pointed to our Linode Website on CyberPanel, we can issue a free SSL certificate to the site. Head back to your CyberPanel page. From the menu on the left, choose \u0026ldquo;Websites\u0026rdquo;, then choose \u0026ldquo;List Websites\u0026rdquo;. You see your domain listed here, along with an \u0026ldquo;Issue SSL\u0026rdquo; button. Go ahead and click that, then wait for the confirmation, which should take a minute or so.\nGreat, now we can set up our WordPress site.\nInstall and Setup WordPress on CyberPanel Click the \u0026ldquo;Manage\u0026rdquo; link on the list websites page for your website from within CyberPanel. At the bottom of the page, you will find a link for \u0026ldquo;WP + LSCache\u0026rdquo;. This link will automatically install and set up WordPress and the LiteSpeed Cache plugin for you.\nHow easy was that? You now have a Linode setup, which is hosting CyberPanel and your WordPress site. Let me know if you think this is the best web hosting for a WordPress site once you\u0026rsquo;ve given it some time.\nConclusion I hope this guide helped you, if it did, let me know in the comments. I will probably make some future posts about CyberPanel on Linode, such as adding additional security to the server. You definitely will want to install and enable the Firewall. You will also want to create a new CyberPanel user, change the admin account password, and setup a new SSH user with a keypair. Some of my other Linode guides can help you with some of that so be sure to check them out.\n","permalink":"http://localhost:1313/best-web-hosting-for-wordpress/","summary":"Let\u0026rsquo;s be honest, there are tons of web hosting providers out there who all claim to be the best, the fastest, or offer the most extras. Trying to weed through all of the providers and all of the opinions of folks on YouTube and blogs isn\u0026rsquo;t easy either. It will likely leave you feeling cheated or confused. So I\u0026rsquo;m going to throw my hat into the ring of who is the best web hosting provider for WordPress using my own experience with 3 different providers.","title":"Best Web Hosting for WordPress 2023"},{"content":"\rIf you have been using redirected desktops or some form of mandatory profile in your on-prem Active Directory environment using GPO, you may ask yourself how you will manage desktop icons and shortcuts in Intune? This was a question I faced myself, how can we easily control what icons and shortcuts a user see\u0026rsquo;s on their desktop of fully Intune managed devices? It\u0026rsquo;s actually not that hard thanks to the work of Florian, who runs the scloud blog. Let\u0026rsquo;s go over the implementation and how you can use this to manage the desktops of your Intune devices.\nDownload the Desktop Icon Script Package To start, we need to download the script package that we will use to deploy desktop shortcuts to our Intune devices. Head over the the scloud GitHub page to download this.\nThe important parts of this package are broken down here.\ninstall.ps1 - This script is what does the heavy lifting of copying the icons, cleaning up old icons etc. When you package this as a Win32 app in Intune, you will use this file as your setup and install file.\ncheck.ps1 - This is the detection script that will be used by the Win32 app to verify that the device has the latest desktop icon package.\nLink-list.csv - In this file you can put website links and also a custom .ico file that will go in the Icons Folder. Web links put in this CSV file will be added to the users desktop. You don\u0026rsquo;t need to add these to the Desktop folder. This file has one already added as an example.\nuninstall.ps1 - Removes the icon package and icons, obviously.\nDesktop Folder - You will drop the shortcuts you want the user to see into this folder.\nIcons Folder - Here you can drop custom .ico files to assign to web links, in case you want them to look different than the default browser icon. There is an example icon file in this directory that is used for the example web link in the link-list.csv file.\nUsing the Script to Configure the Intune Desktop Icons Now that you have the script package, let\u0026rsquo;s go ahead and use it to create a set of managed desktop icons for Intune.\nExtract the downloaded package somewhere on your system\nLocate the application shortcuts that you want to appear on the users desktop and copy them to the Desktop folder of the package. You can also copy website shortcuts here if you are good with the icon being the default browser icon.\nConsider an web links you may want to customize the icon for. If you have some, you will want to edit the link-list.csv file to include them and also put the .ico file into the icons folder.\nOpen up the install.ps1 file for editing.\nEdit the $packagename variable to be something unique.\nEdit the version number if needed.\nOpen up the check.ps1 file for editing.\nEdit the $packagename variable to match what you put in the install.ps1 file.\nEdit the version number to match what you put in the install.ps1 file as well.\nOpen up the uninstall.ps1 file for editing.\nEdit the $packagename variable to match what you put in the install.ps1 file. Package Desktop Icons In a Win32 Intune App Now that you have your shortcuts configured and ready, we need to package it all up into a Win32 Intune app for deployment. You are likely already familiar with this process, in case you\u0026rsquo;re not, check out our post on deploying PowerShell scripts for Intune. Specifically the section about packaging them into Win32 apps. You will want to use the \u0026ldquo;install.ps1\u0026rdquo; file as the setup file when using the Win32 Content Prep Tool. You will use the \u0026ldquo;check.ps1\u0026rdquo; file as your detection method when creating the app in the Intune console.\nImportant Notes How do you update these shortcuts if you need to make changes once you have deployed them in Intune? You just need to update the shortcuts in the desktop folder, the version number found in the \u0026ldquo;install.ps1\u0026rdquo; and \u0026ldquo;check.ps1\u0026rdquo; scripts, while making sure the package name stays the same. Then repackage the Win32 app and deploy along with the updated \u0026ldquo;check.ps1\u0026rdquo; file as the detection method.\nConclusion That\u0026rsquo;s it, you have migrated from the old on-prem Active Directory method of using redirected desktop to the fully Intune managed way of deploying shortcuts to your end users. You also have a path forward for keeping the shortcuts updated when you need to make future changes.\nIf you have any questions about this method or other Intune topics, let me know in the comments.\n","permalink":"http://localhost:1313/managed-desktop-icons-and-shortcuts-in-intune/","summary":"If you have been using redirected desktops or some form of mandatory profile in your on-prem Active Directory environment using GPO, you may ask yourself how you will manage desktop icons and shortcuts in Intune? This was a question I faced myself, how can we easily control what icons and shortcuts a user see\u0026rsquo;s on their desktop of fully Intune managed devices? It\u0026rsquo;s actually not that hard thanks to the work of Florian, who runs the scloud blog.","title":"Managed Desktop Icons and Shortcuts in Intune"},{"content":"https://youtu.be/-F1IF9kybbU\nMany organizations could import the hardware hash of their existing endpoints using SCCM or other automated means because the endpoints were already running Windows. However, in some cases, this wasn\u0026rsquo;t possible because the devices were not running Windows at the time, which was the case for my organization. We wanted to use Autopilot when converting from the old Linux solution to the new Windows Azure AD/Intune solution. To do this, we needed an automated solution for collecting the hardware hash and importing it into Intune. So this was the start of a journey to find a good solution.\nWe already have SCCM in our environment, which was used heavily pre-pandemic. So we started looking at ways we could use SCCM to our advantage to complete the following steps.\nConvert Linux or Other OS Devices to Windows\nCollect the Hardware Hash and Import it into Intune\nEnd Goal Being a Fully Intune Managed Windows 10 PC\nResearching online, it wasn\u0026rsquo;t easy to find solid information for this scenario. I guess what we were trying to do just wasn\u0026rsquo;t that common. Luckily, we stumbled upon the Intune Training YouTube channel, which had a video on the topic of collecting the hardware hash and uploading it to Intune via an SCCM task sequence.\nAfter some trial and error and a couple of changes to their provided solution using a few PowerShell scripts at the end of the task sequence, we had a working product. Windows 10 would be deployed using SCCM, after this, the task sequence would collect the hardware hash and import it to Intune. The device then reboots and starts the Autopilot process. Sweet! So let\u0026rsquo;s dive into how this is set up.\nTask Sequence PowerShell Scripts to Collect and Upload the Hardware Hash First, we need to obtain the PowerShell scripts we will use during the task sequence to obtain and import the hardware hash to Intune. The original files are available from the Windows Admins Github Repo. As I\u0026rsquo;ve mentioned, we made some slight modifications that you may want to consider as well, so we\u0026rsquo;ve forked the repo and made the modified version available on the credibleDEV Github repo. If you download the files from our repo you will have these modifications already.\nThe two modifications made are as follows.\nChange the grouptag variable to be a parameter instead of hardcoded. This allows us to customize the group tag without editing the script. We can now use the same package for all of the task sequences and just change the parameter used for the grouptag.\nAdd the -Assign flag to the call of Get-WindowsAutoPilotInfo. This will cause the script to wait for the assignment of the autopilot profile in Intune to complete before continuing to the OOBE. We ran into issue where the assignment took a while on the Intune side which caused issue when the device kicked out to the OOBE.\nThe scripts being used in this package will perform the following functions.\nScript1 - Sets up the directory and copies the needed files to the target machine\nScript2 - Sets variables for your tenant, app registration, grouptag, and optional Teams integration. This script also calls GetWindowsAutoPilotInfo to do the work of uploading the hardware hash and grouptag to Intune.\nScript3 - Cleanup, remove the config manager client from the machine and kick it out to the OOBE.\nRequired App Registration We need to allow these scripts to talk to the tenant and upload the hardware hash from the task sequence. For this to work, you will need to create an app registration from your Azure tenant. Let\u0026rsquo;s do that now.\nFrom Azure AD, choose App Registrations from the left sidebar menu.\nOn the next screen, you will click on \u0026ldquo;New Registration\u0026rdquo; at the top. You will then be taken to page to name your new app registration. Give it an appropriate name and configure any other options you may need to customize. When finished, click on \u0026ldquo;Register\u0026rdquo; at the bottom.\nOnce your app registration is created, click on \u0026ldquo;API Permissions\u0026rdquo; from the left sidebar menu. Then click on \u0026ldquo;Add a Permission\u0026rdquo;.\nOn the Add Permission popout window, do the following.\nSelect Microsoft Graph\nSelect Application Permissions\nIn the search box, type \u0026ldquo;device\u0026rdquo; to narrow down the list.\nFind and expand \u0026ldquo;DeviceManagementServiceConfig\u0026rdquo;\nSelect the checkbox next to \u0026ldquo;DeviceManagementServiceConfig.ReadWrite.All\u0026rdquo;\nClick Add Permissions at the bottom\nBefore leaving the API page, we need to give admin consent as well. You do this by clicking on the link that says \u0026ldquo;Grant Admin Consent\u0026rdquo;.\nNext, you click on \u0026ldquo;Certificates \u0026amp; Secrets\u0026rdquo; from the left sidebar menu, then choose \u0026ldquo;New Client Secret\u0026rdquo;. Give it a name, then select the expiration time you would like.\nAfter creating your new client secret, you will want to take note of the value highlighted in the image below. You will be adding this to Script2 in the next step.\nLink the Task Sequence Script to Azure AD In this step, we will be linking variables in Script2 from the repo to our Azure AD tenant and the app registration we just created. Open up Script2.ps1 and edit the following variables accordingly.\n$tenant = \u0026ldquo;whatever.onmicrosoft.com\u0026rdquo;\n$clientid = \u0026ldquo;Application ID from your app registration\u0026rdquo;\n$clientSecret = \u0026ldquo;The value you copied from the client secret you created in the previous step\u0026rdquo;\nCreate an SCCM Package Once you have downloaded the files from the Github repo. You want to create an SCCM package for them and push it out to your distribution points. I assume you already know how to do this process and won\u0026rsquo;t go into detail here.\nCreate an SCCM Task Sequence to Get the Hardware Hash and Upload to Intune Now that we have an SCCM package created with the PowerShell scripts, we will create a task sequence. Again, I won\u0026rsquo;t go into the basics of creating a task sequence, as I assume you already know how.\nAt the end of the task sequence, you will want to add three steps, one for each of the PowerShell scripts that need to run from the package we just created. When creating the task sequence steps, choose the step type of \u0026ldquo;Run PowerShell Script\u0026rdquo;, then select the package you created.\nFor the first one, you will put \u0026ldquo;Script1.ps1\u0026rdquo; as the script name and set the execution policy to bypass.\nFor the second step, you will set the script name as \u0026ldquo;Script2.ps1\u0026rdquo;. In the parameters field, you will put your chosen grouptag, and then set the execution policy to bypass as well.\nThe third script will be set up like the first, except for using \u0026ldquo;Script3.ps1\u0026rdquo; as the script name.\nConclusion You\u0026rsquo;re now ready to assign the task sequence to a collection and test. If set up properly, and your devices have a physical TPM 2.0 chip, you should not have any issues getting this to work.\n","permalink":"http://localhost:1313/intune-hardware-hash-import-during-task-sequence/","summary":"https://youtu.be/-F1IF9kybbU\nMany organizations could import the hardware hash of their existing endpoints using SCCM or other automated means because the endpoints were already running Windows. However, in some cases, this wasn\u0026rsquo;t possible because the devices were not running Windows at the time, which was the case for my organization. We wanted to use Autopilot when converting from the old Linux solution to the new Windows Azure AD/Intune solution. To do this, we needed an automated solution for collecting the hardware hash and importing it into Intune.","title":"Intune Hardware Hash Import During Task Sequence"},{"content":"Intune makes a lot of things really easy, but some things are just easier with GPO. Adding or changing registry keys for the current user in the HKEY_CURRENT_USER hive is one of the things that was far easier with GPO than it is in Intune. I\u0026rsquo;m really going to miss the days of OnPrem AD, OU\u0026rsquo;s, and GPO\u0026rsquo;s. Sad times we live in, or maybe I\u0026rsquo;m just old and frustrated with Microsoft.\nSadly, there are some configurations that we need to do as engineers or admins that require us to dive into the HKCU hive to make modifications.\nNever fear, there is a way to deploy registry keys to HKCU using Intune though. You can package this as a Win32 app or you could use a Proactive Remediation. I\u0026rsquo;ve covered those methods in this post: Deploy PowerShell Scripts in Intune\nYou will want to create a new PowerShell script similar to the one below. In our example, we are creating a new value in HKCU:\\Software called Test and setting the value equal to 1.\nNew-ItemProperty -LiteralPath \u0026#39;HKCU:\\Software\u0026#39; -Name \u0026#34;Test\u0026#34; -Value 1 -PropertyType \u0026#34;Dword\u0026#34; -Force -ea SilentlyContinue Simple enough, right? The important part is during the Win32 app creation or Proactive Remediation, whichever you choose. We want to make sure that this runs in the user context, otherwise, it won\u0026rsquo;t work properly.\nWin32 App Config For a Win32 app, you must make sure to change the Install Behaviour to \u0026ldquo;User\u0026rdquo; instead of system.\nProactive Remediation Config If you choose a Proactive Remediation deployment for this, you want to make sure that the option to Run this script using the logged-on credentials is set to \u0026ldquo;Yes\u0026rdquo;.\nOther Options Another option is to make your script load the registry key for all new users who sign in. This will not impact users who already have profiles on the device, only new users.\nTo do this, we use PowerShell again to enable access to the HKEY_USERS hive, and then you can create your key there.\nNew-PSDrive -PSProvider Registry -Name HKU -Root HKEY_USERS New-ItemProperty -LiteralPath \u0026#39;HKU:\\.DEFAULT\\Software\u0026#39; -Name \u0026#34;Test\u0026#34; -Value 1 -PropertyType \u0026#34;Dword\u0026#34; -Force -ea SilentlyContinue Conclusion Oh, the good old days of GPO are quickly going away and Microsoft doesn\u0026rsquo;t seem to want to make our lives easy. No worries, we found a workaround and now you know how to deploy registry keys using Intune to the current user registry hive.\nHave Intune questions? Let me know in the comments.\n","permalink":"http://localhost:1313/deploy-hkcu-registry-keys-using-intune/","summary":"Intune makes a lot of things really easy, but some things are just easier with GPO. Adding or changing registry keys for the current user in the HKEY_CURRENT_USER hive is one of the things that was far easier with GPO than it is in Intune. I\u0026rsquo;m really going to miss the days of OnPrem AD, OU\u0026rsquo;s, and GPO\u0026rsquo;s. Sad times we live in, or maybe I\u0026rsquo;m just old and frustrated with Microsoft.","title":"Deploy HKCU Registry Keys Using Intune"},{"content":"What is Docker? Docker is a platform and tool for building, shipping, and running distributed applications. It allows developers to package their applications and dependencies into a portable container, which can be run on any machine that has Docker installed. This makes it easy to create, deploy, and run applications in a consistent environment, regardless of the host operating system or infrastructure.\nDocker vs Virtual Machines ocker and virtual machines (VMs) are both technologies for running multiple isolated environments on a single host, but they work in different ways.\nA virtual machine is a software implementation of a physical machine, which runs on a host operating system and emulates all the hardware resources of a physical computer. Each VM runs its own operating system, and applications running inside the VM are isolated from the host and from other VMs.\nDocker, on the other hand, uses the host operating system\u0026rsquo;s kernel and does not run a separate operating system for each container. Instead, it uses a feature of the Linux kernel called namespaces to create isolated environments for applications. This means that Docker containers are much more lightweight than VMs, and require fewer resources to run.\nAnother difference is that VMs are typically used to run different operating systems while a Docker container is used to package an application and its dependencies in a portable container, allowing it to run consistently across different environments.\nStep 1 - Install Docker To install Docker on Manjaro Linux or other Arch based distros, you can use pacman. Open a terminal and run the following command to install Docker.\nsudo pacman -S docker Step 2 - Start the Docker Service The next step is to start the Docker service. We can also use \u0026ldquo;systemctl enable\u0026rdquo; to make Docker run as a system startup service, this means that Docker will start itself after a reboot. Run the following commands in the terminal.\nsudo systemctl start docker.service sudo systemctl enable docker.service Step 3 - Add User to Docker Group (Optional) This step is optional but by default, the Docker commands need to be run as root. If you don\u0026rsquo;t wish to run them as root, you can add yourself to the docker group.\nThis change will not take effect until your log out and back in again.\nsudo usermod -aG docker $USER Step 4 - Search for a Docker Image You may already know the name of the Docker image you want, or maybe you\u0026rsquo;re creating your own. If not, there are plenty of available Docker images and you can search through them using the command below. In our example, we will search for Manjaro Docker images.\nsudo docker search manjaro This search will return a list of available Docker images.\nStep 5 - Install a Docker Image To install a Docker image, you will need to know the name of the image. In our example, we will use \u0026ldquo;marjarolinux/base\u0026rdquo; from the search we just did. To install this Docker image, we run the following command.\nsudo docker pull manjarolinux/base Wait patiently while the image is downloaded. If it is successful you will see output similar to the following.\nStep 6 - Run a Docker Image Now that we have a Docker image selected and downloaded, we are ready to launch it. Simply run the following in the terminal to spin it up. We use \u0026ldquo;-it\u0026rdquo; here to run the Docker container in interactive mode. If we don\u0026rsquo;t use \u0026ldquo;-it\u0026rdquo;, the Docker container would just exit immediately and nothing would happen. Since we use \u0026ldquo;-it\u0026rdquo;, we will be dropped into the shell prompt of the Docker container.\nsudo docker run -it manjarolinux/base Once you\u0026rsquo;re at the terminal, you can run any Linux commands you want. You might install Apache to host a website. Maybe you want to set up NodeJS so you can host an API? The choice is yours and so is the container.\nYou could also just send a command to the Manjaro Docker container instead. If you wanted the container to check for updates you could do the following.\nsudo docker run -it manjarolinux/base pacman -Syu Step 7 - Check the Status of Running Docker Containers Now that we have our Manjaro Linux container up and running, we can check its status a few different ways.\nFirst, to get a quick status of all running containers run the following in a new terminal.\nsudo docker container ls You can also get live stats of your Docker containers by running the following command.\nsudo docker stats BONUS: How to Copy Files to and From a Docker Container It\u0026rsquo;s a pretty common scenario that you might want to copy files from your local machine to the Docker container. To do that, imagine you have a file called test.js on your local machine and you want to copy it to the Docker container. First, you need to get that container id, which you can get using the \u0026ldquo;sudo docker ps\u0026rdquo; command. This will list all of your containers, and grab the id of the one you want, it will be in the first column of the output.\nsudo docker ps Now that you have the container id, use the following command to copy the file to the container. Replace \u0026ldquo;fc40117da262\u0026rdquo; with your container id and \u0026ldquo;foldername\u0026rdquo; with the folder to which you want to copy the file.\ndocker cp test.js fc40117da262:/foldername/test.js You can read more about the \u0026ldquo;docker cp\u0026rdquo; command and the more advanced options by checking out the official documentation.\nConclusion You have now successfully set up Docker on Manjaro Linux. Time to get developing your next app!\nHave questions? Let me know in the comments.\n","permalink":"http://localhost:1313/setup-docker-on-manjaro-linux/","summary":"What is Docker? Docker is a platform and tool for building, shipping, and running distributed applications. It allows developers to package their applications and dependencies into a portable container, which can be run on any machine that has Docker installed. This makes it easy to create, deploy, and run applications in a consistent environment, regardless of the host operating system or infrastructure.\nDocker vs Virtual Machines ocker and virtual machines (VMs) are both technologies for running multiple isolated environments on a single host, but they work in different ways.","title":"Setup Docker on Manjaro Linux"},{"content":"There comes a time in every Window\u0026rsquo;s engineers life when they need to deploy a scheduled task to hundreds or even thousands of endpoints. Unfortunately, if your company has moved to Intune for endpoint management, this deployment isn\u0026rsquo;t as obvious and straightforward as it could be.\nLuckily, it isn\u0026rsquo;t terribly hard to do and it certainly isn\u0026rsquo;t impossible. So today, we will break down the steps to deploy a scheduled task with Microsoft Intune. I have used this same method on multiple occasions and it has worked every time.\nStep 1 - Creating a Schedule Task in Windows The first step in the process is to mock up the scheduled task that you want to create from within the Windows task scheduler. You want to create all aspects of the task the way you want them, be sure to include the event and action. Consider if you want this running in the user or system context as well.\nOnce you have the scheduled task created, you will want to export it. You can do this by right-clicking on your scheduled task and choosing export.\nThis will export an XML file that has the details of your scheduled task. This is what we will use to deploy via a Win32 Intune app, along with a little bit of PowerShell.\nStep 2 - Create an Install Script in PowerShell Now that we have our scheduled task exported as an XML file. We will create a PowerShell script that will install the task via Intune on the target endpoint device.\nThis PowerShell script will copy the XML file to the machine, then generate the scheduled task using the Register-ScheduledTask command.\nThe part at the end \u0026ldquo;-User system\u0026rdquo; will be the user account the task will run in. In our example, the scheduled task that we deploy will run in the system context.\ninstall.ps1\n# Copy the XML file Copy-Item \u0026#34;.\\test.xml\u0026#34; \u0026#34;C:\\\u0026#34; # Register a new Scheduled Task using the XML Register-ScheduledTask -xml (Get-Content C:\\test.xml | Out-String) -TaskName \u0026#34;test\u0026#34; -TaskPath \u0026#34;\\\u0026#34; -User system If you need your task to run in the user context for all users. Be sure your task is set up to run as BUILTIN\\Users in the task you created. Also, in the PowerShell script above, remove the \u0026ldquo;-User system\u0026rdquo;.\nStep 3 - Create a Detection Script Now that we have the install script created, we need to also create a detection script. This script will be run on endpoints to detect if the scheduled task exists on the machine or not. If it doesn\u0026rsquo;t, then the install script we just created will be executed on the endpoint.\ndetection.ps1\n$taskExists = Get-ScheduledTask | Where-Object {$_.TaskName -like \u0026#34;test\u0026#34;} if($taskExists) { Write-Host \u0026#34;Success\u0026#34; Exit 0 } else { Exit 1 } Step 4 - Create an Uninstall Script Our Win32 app package for Intune wouldn\u0026rsquo;t be complete with a proper way to uninstall the scheduled task in case the need arises. This script will simply remove the scheduled task and ignore the confirmation prompt. Since this will run silently, we don\u0026rsquo;t need a confirmation prompt preventing it from running properly.\nuninstall.ps1\nUnregister-ScheduledTask -TaskName \u0026#34;test\u0026#34; -Confirm:$false Step 5 - Create a Win32 App Package for Intune Now we have our XML, install, detection, and uninstall scripts for our scheduled task, we are now ready to package them as a Win32 app that we can upload it into Intune.\nPut all four files in their own directory, for our example, we\u0026rsquo;ll use C:\\scripts\\ST as the directory.\nNow we need to run Microsoft Win32 Content Prep Tool, to package these files into a Win32 app. This tool will generate an \u0026ldquo;intunewin\u0026rdquo; file, which we will upload to Intune. Visit the GitHub page linked above and download the repo as a zip. Extract the zip file to your system so you can use the tool. Either double-click the \u0026ldquo;IntuneWinAppUtil.exe\u0026rdquo; file or run it from the terminal.\nThe source folder is where you have the 4 files we created. The next prompt will be for the setup file, this will be \u0026ldquo;install.ps1\u0026rdquo;. The next prompt will be the output directory, this can be the same as the source folder. You will then be asked about creating a catalog folder, you can put \u0026ldquo;n\u0026rdquo; for no. Then your package will be generated.\nWhen it is finished, you should now have an \u0026ldquo;intunewin\u0026rdquo; file in your directory.\nStep 6 - Upload the Win32 App Package to Intune Login to Intune and start creating a new Win32 app. I assume that you know how to start this process so I will only cover the relevant parts here that make it unique. Proceed with choosing Win32 as the app type and when prompted, navigate to the location of the \u0026ldquo;intunewin\u0026rdquo; file to upload it.\nFor the install and uninstall command of the Win32 app use the following as shown in the screenshot above.\nPowershell.exe -ExecutionPolicy ByPass -File .\\install.ps1 Powershell.exe -ExecutionPolicy ByPass -File .\\uninstall.ps1 For the detection rule, you will choose to use a custom detection script. Then browse to the script that we created earlier.\nConclusion You have now successfully created a Win32 app in Intune that will deploy a custom scheduled task to your Windows endpoints.\nWant to know how to do other things in Intune? Leave a comment below. Also, be sure to check out my other post on the different ways you can Deploy PowerShell Scripts in Intune.\n","permalink":"http://localhost:1313/how-to-deploy-a-scheduled-task-in-intune/","summary":"There comes a time in every Window\u0026rsquo;s engineers life when they need to deploy a scheduled task to hundreds or even thousands of endpoints. Unfortunately, if your company has moved to Intune for endpoint management, this deployment isn\u0026rsquo;t as obvious and straightforward as it could be.\nLuckily, it isn\u0026rsquo;t terribly hard to do and it certainly isn\u0026rsquo;t impossible. So today, we will break down the steps to deploy a scheduled task with Microsoft Intune.","title":"How to Deploy a Scheduled Task in Intune"},{"content":"Flatpak\u0026rsquo;s are great, they make installation of applications and their dependencies on Linux easy. Flatpak is already a part of some Linux distributions but EndeavourOS, Manjaro, and Arch do not have them enabled by default, so today we will walk through how to get up and running with Flatpak on these distros.\nWhy are Flatpak\u0026rsquo;s Great? I will keep it simple here and give a better explanation in the next section. Simply put, Flatpak\u0026rsquo;s are great because of compatibility, ease of use and security. They also make a developer\u0026rsquo;s life easier too.\nWhat is Flatpak? A Flatpak is a software package that is bundled with the required dependencies such as frameworks, libraries, and other software to make the application work as intended by the developer. All are included in a Linux distro agnostic installer.\nBundled Dependencies Packaging applications in this way makes it so that everyone who uses a given app is on the same page in terms of installed dependency versions, which makes it much easier for the developer and the user. The user doesn\u0026rsquo;t have to worry about making sure all dependencies are installed and that they are the right version. This isn\u0026rsquo;t just a Linux problem, this issue exists for some Windows applications as well.\nDistro Agnostic If you\u0026rsquo;ve been using Linux for some time, you are familiar with DEB and RPM packages for example. The days of Linux distro specific packages such as these are no more with Flatpak. The same Flatpak package will install on over 30 different Linux distros!\nSecurity Another important feature is sandboxing. Not only do you not need root privileges to install a Flatpak, but they also run in a sandbox that protects the OS. The sandbox that a Flatpak application runs in, is an environment that is isolated from the rest of the OS. This means the application has no access by default to your user files, devices, or the OS itself. This is huge for system security and another big selling point for Flatpak.\nPortals and Flatseal Obviously, applications will need access to files and other parts of the system. This functionality is provided through what they call portals. These portals are what make it possible for the sandboxed Flatpak software to touch parts of the OS, filesystem and devices.\nFlatseal is a separate application install that is almost a must for those running Flatpak\u0026rsquo;s. Flatseal exposes the permissions on a per app basis so you can easily give a Flatpak access to specific parts of your system.\nEnough background, let\u0026rsquo;s get started using Flatpak\u0026rsquo;s on EndeavourOS, Manjaro and Arch Linux.\nInstall Flatpak on EndeavourOS, Manjaro and Arch Linux To get started with Flatpak on EndeavourOS, it\u0026rsquo;s quite simple. We will use either pacman or yay (insert favorite AUR helper here) to install Flatpak. Pop open your terminal and use one of the following commands to install from the Arch or AUR repository.\nStep 1 - Install Install Flatpak from the Arch Repository\nsudo pacman -S flatpak Install Flatpak from the AUR Repository\nyay -S flatpak Step 2 - Add Flathub Repo You may need to add the Flathub repository as well, you can do this by running the following command in the terminal.\nflatpak remote-add --if-not-exists flathub https://flathub.org/repo/flathub.flatpakrepo You now have Flatpak installed and you can begin installing Flatpak software packages on EndeavourOS.\nGUI Flatpak Install Using Pamac in Manjaro The pamac GUI software installer that is provided by default in Manjaro Linux comes with support for Flatpak\u0026rsquo;s, it just needs to be enabled. You will find the option to enable Flatpak under the preferences of Pamac.\nOnce you have Flatpak support enabled, you will be able to search for Flatpak applications from within pamac, rather than using the terminal. You can use the terminal as well though.\nInstalling Flatpak Packages on EndeavourOS, Manjaro and Arch You may already know the name of the package you want to install, in case you don\u0026rsquo;t, you can check our the Flathub page to find packages and their install commands. For example, if you wanted to install Spotify, you can run the following command in the terminal.\nflatpak install flathub com.spotify.Client Once the command finishes, you should find Spotify in your application menu. If you prefer to run the application from the terminal, you can run the following command to launch Spotify.\nflatpak run com.spotify.Client Install Flatseal for Flatpak Permission Management I would highly suggest that you install Flatseal, so that you can easily manage the permissions of your Flatpak installs. Flatseal gives you granular control over each apps individual permissions. So you can give file system and device access to whatever apps you wish.\nflatpak install flathub com.github.tchx84.Flatseal To run Flatseal, find it in your application menu or run the following command in the terminal.\nflatpak run com.github.tchx84.Flatseal Upon launching Flatseal, you should see all of your Flatpak applications listed on the left. When selecting one of the applications, you will see a list of permissions on the right side. Here you can make changes to the individual app to give it access to various parts of your file system, user files and devices.\nConclusion You now have Flatpak installed and set up on EndeavourOS, Manjaro and Arch. You also have learned how to install Flatpak packages and manage them using Flatseal.\nIf you have any questions about Flatpak, let me know in the comments.\n","permalink":"http://localhost:1313/install-flatpak-endeavouros-manjaro-arch-linux/","summary":"Flatpak\u0026rsquo;s are great, they make installation of applications and their dependencies on Linux easy. Flatpak is already a part of some Linux distributions but EndeavourOS, Manjaro, and Arch do not have them enabled by default, so today we will walk through how to get up and running with Flatpak on these distros.\nWhy are Flatpak\u0026rsquo;s Great? I will keep it simple here and give a better explanation in the next section.","title":"How to Install Flatpak on EndeavourOS, Manjaro and Arch Linux"},{"content":"Maybe you have a headless Windows or Linux OS running on a Proxmox server or even running on bare metal. In either case, it\u0026rsquo;s necessary to be able to remote into the desktop of the machine, whether that be Linux or Windows. Typically this is done via the remote desktop protocol on Windows or VNC on Linux. However, an open-source implementation of RDP exists as well, and it\u0026rsquo;s called XRDP.\nToday, we will compare both of these remote desktop protocols in terms of performance, security, and setup.\nWhat are XRDP and VNC? XRDP and VNC are both popular remote desktop protocols that allow users to remotely connect to and control a computer from a different device. Both protocols have their own unique features and benefits, but how do they compare in terms of performance, security, and setup?\nWhat is XRDP? First, let\u0026rsquo;s define each protocol. XRDP is an open-source Remote Desktop Protocol (RDP) server that allows users to connect to a remote computer using RDP client software. XRDP is one option for setting up a remote desktop on a Linux workstation and packages are available for most distributions.\nXRDP offers important features you would expect from RDP.\nRemote Desktop Viewing and Control\nRedirection audio output and input redirection\nBi-directional clipboard\nFilesystem redirection, make local drives available on the remote machine\nWhat is VNC? On the other hand, VNC (Virtual Network Computing) is a cross-platform remote desktop protocol that allows users to remotely access and control a computer from another device. It is also open-source and can be used on a variety of operating systems.\nXRDP and VNC Performance Comparison Now, let\u0026rsquo;s compare the performance of these two protocols. In terms of speed, XRDP tends to be faster than VNC. This is because XRDP uses RDP, which is a native Windows protocol and is therefore optimized for Windows environments. On the other hand, VNC uses a custom protocol, which can sometimes result in slower performance.\nHowever, VNC has a few advantages over XRDP in terms of performance. First, VNC is more flexible and can be used on a wider variety of operating systems and devices. This makes it a good choice for users who need to access computers running different operating systems. Second, VNC has better support for high-resolution displays and can handle multiple monitors more effectively than XRDP.\nXRDP and VNC Security Comparison In terms of security, both XRDP and specifically TigerVNC operate over TLS for their connections by default. This makes it more secure in terms of man-in-the-middle attacks but doesn\u0026rsquo;t protect it from brute force attacks. For this reason, it is not advisable to have XRDP or VNC available openly on the internet. At the very least it should be behind a firewall that only allows connections from IP addresses that need it.\nSSH Tunnel For better security, if the connection must be available over the internet, you should consider using an SSH tunnel for the connection. This process will be described in a later article but for now, if you are planning to connect via XRDP or VNC over the internet, you should research SSH tunnels before making it available.\nXRDP Setup Now, let\u0026rsquo;s talk about the setup process for each protocol. Setting up XRDP is relatively straightforward, especially on Windows. To set up XRDP on Windows, users simply need to install the XRDP software on the remote computer and then connect to it using an RDP client on the local computer. On Linux, the setup process is slightly more complex, but there are detailed instructions available online that make it easy to follow.\nXRDP Setup on Linux The installation of XRDP is far easier than VNC, we just need to install and set up the service. Described below is the installation process for various distributions of Linux.\nInstall XRDP on Manjaro and Arch To get started installing XRDP on Manjaro or Arch Linux distributions, you will need to enable the AUR repository. You can do this in the preferences of pamac, the GUI package manager.\nOnce the AUR is enabled, you have a few options. You can use the GUI package manager in Manjaro/Arch to install XRDP and xorgxrdp. Alternatively, you can use the yay AUR helper to install XRDP. If you don\u0026rsquo;t have yay or some other AUR helper installed, you can install it with the following command.\nsudo pacman -S yay Once yay is installed, you can install XRDP and xorgxrdp with the following command.\nyay -S xrdp xorgxrdp After XRDP is installed, you will need to enable and start the service before you can successfully use RDP to connect.\nsudo systemctl enable xrdp sudo systemctl start xrdp We need to edit the ~/.xinitrc file in order for KDE to launch properly in an XRDP session. Open up this file for editing and replace the line \u0026ldquo;exec $(get_session \u0026ldquo;$1\u0026rdquo;)\u0026rdquo; with the following:\n/usr/lib/plasma-dbus-run-session-if-needed startplasma-x11 Save the edits to the file. Next, we need to create the file /etc/X11/Xwrapper.config if it doesn\u0026rsquo;t already exist. Put the following contents in the file.\nallowed_users=anybody That\u0026rsquo;s it, you now have XRDP setup on Manjaro or Arch Linux.\nInstall XRDP on Ubuntu 22.10 Installing and setting up XRDP on Ubuntu 22.10 is far easier than on Manjaro or Arch. Use apt to install the XRDP package.\nsudo apt install xrdp Now we just need to enable and start the XRDP service.\nsudo systemctl enable xrdp sudo systemctl start xrdp That\u0026rsquo;s all you need to do to get XRDP running on Ubuntu. You can now connect to your Ubuntu machine remotely using RDP.\nInstall XRDP on Fedora 37 and CentOS To get started installing XRDP on Fedora 37, we need to install XRDP using the dnf package manager in the terminal.\nsudo dnf install xrdp Once installed, we need to enable and start the XRDP service so that it runs after each reboot of the system.\nsudo systemctl enable xrdp sudo systemctl start xrdp You should now be able to connect using an RDP client. Some guides will mention SELinux changes, these are not necessary for connection within your local network. If you plan to connect over the internet, consider an SSH tunnel to decrease your security risk.\nVNC Setup Setting up VNC can be a bit more complex, depending on the operating system being used. Check out our guide on setting up VNC for Manjaro Linux.\nConnecting to XRDP To connect to XRDP from Linux, you can use Rimmina, which makes the connection pretty easy. There are other RDP clients for Linux that you could check out as well.\nRemmina\nVinagre\nIf you are connecting to XRDP from a Windows device, you can use the built-in RDP application found in your start menu.\nAlternatives to XRDP and VNC If you\u0026rsquo;re not a techie or you don\u0026rsquo;t want to do any command line work or configuration, you can check out these popular alternatives to XRDP and VNC. These solutions rely on third-party services and could expose your system to external risks. These applications are far easier to set up and configure though, which makes them a perfect solution for newer users of remote desktop functionality.\nTeamViewer\nAnyDesk\nConclusion Overall, both XRDP and VNC are reliable and effective remote desktop protocols, and the choice between the two will depend on the specific needs and preferences of the user.\nIn conclusion, XRDP is generally faster and more secure, but VNC is more flexible and has better support for high-resolution displays. Both protocols have their own unique features and benefits, and the choice between the two will depend on the specific needs and preferences of the user.\n","permalink":"http://localhost:1313/xrdp-and-vnc-which-is-the-better-remote-desktop/","summary":"Maybe you have a headless Windows or Linux OS running on a Proxmox server or even running on bare metal. In either case, it\u0026rsquo;s necessary to be able to remote into the desktop of the machine, whether that be Linux or Windows. Typically this is done via the remote desktop protocol on Windows or VNC on Linux. However, an open-source implementation of RDP exists as well, and it\u0026rsquo;s called XRDP.","title":"XRDP and VNC: Which is the Better Remote Desktop"},{"content":"Need to downgrade a Linode server? No longer need a large Linode plan? Not using all of that storage, RAM, or CPU like you thought you would? Maybe the workload of your Linode server has changed. In any case, you can easily downgrade the plan that you use on Linode.\nIf you are thinking about using Linode but don\u0026rsquo;t have an account yet. Take advantage of the free $100 60-day credit using this link. Plus, you’re helping me to keep creating content.\nUpgrading on Linode is even easier since Linode handles resizing the disk for you. However, when downgrading, there is just a small amount of manual work required.\nCheck how much storage you currently use.\nAre you using less storage than the plan you want to downgrade to allows?\nIf you are, resize the disk.\nNow you can downgrade the Linode plan you are on.\nIt\u0026rsquo;s not too bad and I\u0026rsquo;ll walk you through resizing your Linode step by step and then how to downgrade a Linode plan. Let\u0026rsquo;s get started.\nCheck Linode Storage Usage We first need to check that we are not using more space than the small Linode we want to downgrade to allows. In this case, we are downgrading from the 2GB Linode, which offers 50GB of storage space, to the smaller 1GB Linode which offers 25GB of storage.\nWe can check the current amount of storage that we are using by connecting to the Linode server via SSH and running the following command.\ndf -h The \u0026ldquo;-h\u0026rdquo; option will print the drive space in gigabytes so it\u0026rsquo;s easier to read. After running this command, a disk usage summary will be printed out. We are interested in this one: \u0026ldquo;/dev/sda\u0026rdquo;.\nWe can see that in our case, we are only using 7.6 gigabytes of space. So we are under the 25GB limit of the Linode plan we want to downgrade to. This means we can proceed with downgrading. If you are over the limit of the smaller plan, you will want to delete data that may no longer be needed or consider that a downgrade is not an option.\nResize Linode Storage The next step in the process is to resize the disk to match the plan we are downgrading to. In our case, this will be 25GB. Head over to the Linode dashboard for your server.\nYou will have to power off your server in order to resize the current disk. So go ahead and power it down.\nOnce your server is powered down, click the Storage link in the Linode dashboard. You should then see your disk listed along with a resize button.\nGo ahead and click on resize, then type in the new disk size, for our example this will be 25GB.\nOnce this is done, you will see a bar that will update you with the progress of the resize. Once this is finished, you can proceed with the downgrade in the Linode Dashboard.\nDowngrade a Linode Plan Now you are finally ready to downgrade or change the Linode plan that your server uses. From the Linode dashboard, click the 3 dots at the top right to drop down the menu. Make sure you are on the Linode instance that you want to change the plan for. Choose to resize from the menu.\nYou will get a popup that lists the available Linode plans, choose the one you wish to downgrade to.\nAfter starting the resize of your Linode, it may take a minute or two before you see anything happen, but soon you will see the status change to resizing.\nOnce the resizing is finished, your Linode server will be returned to the last state it was in, so it may be powered off. Go ahead and power the server on and confirm everything is working as expected, such as SSH and whatever services you were running.\nConclusion That wasn\u0026rsquo;t too bad, right? You have successfully downgraded and resized your Linode server. Upgrading is much easier, as Linode will dynamically resize the disk to be larger for you.\nHave questions about Linode? Let me know in the comments. Don\u0026rsquo;t forget to check out the Linode series if you\u0026rsquo;re interested in setting up your own Linode Linux VPS.\n","permalink":"http://localhost:1313/3-easy-steps-to-downgrade-a-linode-server/","summary":"Need to downgrade a Linode server? No longer need a large Linode plan? Not using all of that storage, RAM, or CPU like you thought you would? Maybe the workload of your Linode server has changed. In any case, you can easily downgrade the plan that you use on Linode.\nIf you are thinking about using Linode but don\u0026rsquo;t have an account yet. Take advantage of the free $100 60-day credit using this link.","title":"3 Easy Steps to Downgrade a Linode Server"},{"content":"I planned on creating a VM with the latest version of Ubuntu on it, which currently is 22.10. This VM is going to be used in a future post about Flatpaks. Since I\u0026rsquo;m creating this VM, I decided to document the process on Proxmox as well as how to access the VM through an app like Remina for example.\nLet\u0026rsquo;s go ahead and jump into setting up this Ubuntu VM on Proxmox.\nDownload the Ubuntu 22.10 ISO To obtain the proper ISO, we will need to head over to the Ubuntu Desktop Download page. Scroll down to the 22.10 version and download the iso to your machine.\nOnce you have the ISO downloaded, we need to upload that iso to Proxmox so we can then create a VM.\nUpload ISO to Proxmox Go ahead and log in to your Promox servers web interface, and locate the local storage or whichever storage you use for ISO files. Click on ISO Images and then Upload. From there, you can navigate to where you downloaded the Ubuntu ISO file and start the upload process.\nOnce you have the ISO file uploaded, we can move on to creating the actual VM.\nCreating a Ubuntu 22.10 VM Back in Proxmox, we will right-click on our node, then choose \u0026ldquo;Create VM\u0026rdquo;.\nNext, we will go through a series of VM configurations provided by Proxmox, such as device name, OS, CPU, RAM, etc. I will include the screenshots below, feel free to copy the settings or make changes where needed for your specific setup.\nVM Naming Proxmox VM Name Setup\nVM ISO and OS Settings Proxmox VM OS Setup and ISO Selection\nVM System Setup - GPU and BIOS Proxmox VM System Setup\nVM Disk and Storage Setup Proxmox VM Disk Setup - SCSI is preferred for performance. Enable discard if the underlying storage is an SSD.\nVM CPU Setup Proxmox VM CPU Setup\nVM RAM Setup Proxmox VM RAM Setup\nVM Network Setup Proxmox VM Network Setup\nVM Review and Confirmation Confirm all of your settings look good, you can select \u0026ldquo;start after created\u0026rdquo; if you wish. Otherwise, you will need to manually startup the VM after it finishes building.\nAccess the VM Console After your VM finishes building, you can click on the VM, then choose console from the menu. The VM should be booting into Ubuntu and the installer.\nInstall Ubuntu 22.10 on the Proxmox VM Now we are ready to start the actual installation of Ubuntu on our VM. So you should be at the console of the VM in Proxmox. You will see an option for \u0026ldquo;Install Ubuntu\u0026rdquo; which is what we want to do.\nYou will go through a series of standard setup items such as the keyboard layout, timezone, etc. I will only show the important ones here.\nSince this is a VM, we will choose \u0026ldquo;Erase disk and install Ubuntu\u0026rdquo; on the installation type screen.\nContinue through the other prompts to create your account and password. When the installation is finished you should see this screen, from which you can reboot the VM.\nIf you see a message about removing the installation media and pressing enter, you can either ignore this and press enter or you can remove the CD/DVD drive from the VM on the Hardware tab.\nAfter the VM restarts, you should be at the Ubuntu login screen. You can use the Ubuntu VM from the console as you have been, or you can proceed with remoting to it using a tool like Remina.\nUpdate Your Ubuntu VM Before you proceed with anything else, you should update the Ubuntu OS. There are many ways to do this. You could use the terminal and run the following command.\nsudo apt update \u0026amp;\u0026amp; sudo apt upgrade You can also update the OS using the GUI Software Updater. This application can be found in the app menu.\nOnce you have finished updating, restart the VM.\nEnable Remote Desktop on Ubuntu 22.10 VM Now that we have our Ubuntu VM updated, let\u0026rsquo;s turn on the remote desktop feature so we can connect to our VM from outside of Proxmox.\nOn the Ubuntu VM, go to Settings and find the \u0026ldquo;Sharing\u0026rdquo; menu.\nYou will then want to enable Sharing at the top of the page, followed by turning remote desktop on.\nInside the remote desktop settings, make sure it is set to on. Also, check or set the password, this will be different from the password you sign into the VM with. This password is specific to the remote desktop session.\nNow, to connect to this VM, we need to know its IP address. It is easy to get from the terminal, just run the following command and look for the IP. 127.0.0.1 is not the correct IP, we will want the other one, usually 192.168.x.x depending on your network setup.\nip a Connecting via RDP to Ubuntu VM Now that you have the IP, we can now RDP to the Ubuntu VM from outside of Proxmox. If your machine is a Linux machine, Remmina is a great choice for this. If you\u0026rsquo;re on Windows, the built-in remote desktop utility will work just fine as well.\nNote: For this to work, you must be logged into the Ubuntu VM. Otherwise, the connection will fail. If the Ubuntu VM is in sleep mode, screen locked or you are not logged in, the connection will fail.\nRDP from Linux to Ubuntu VM As I mentioned, Remmina is probably the best tool for remotely connecting from a Linux machine to the Ubuntu VM. I would highly suggest the flatpak version of Remmina, especially if you are running an arch-based Linux distro like Manjaro. I can into issue connecting via RDP using the Remmina install from the official repo for Manjaro. After installing the flatpak version, it worked like a charm.\nIn Reminna, add a new connection, choose RDP for the protocol, enter the IP of the Ubuntu VM, the username and password that you configured for RDP inside of Ubuntu and you\u0026rsquo;re good to go.\nRDP from Windows to the Ubuntu VM As I mentioned earlier, the built-in remote desktop utility in windows works just fine for this purpose. Launch RDP, and enter the Ubuntu VM IP address. You will be prompted to enter the username and password you set up for RDP on Ubuntu.\nConclusion That\u0026rsquo;s it, you have set up a Ubuntu 22.10 VM inside of Proxmox, connected via console in Proxmox as well as set up RDP using Reminna or Windows remote desktop. If RDP doesn\u0026rsquo;t work well for you, try setting up a VNC server on the Ubuntu VM and connecting via VNC rather than RDP.\n","permalink":"http://localhost:1313/creating-a-ubuntu-vm-on-proxmox/","summary":"I planned on creating a VM with the latest version of Ubuntu on it, which currently is 22.10. This VM is going to be used in a future post about Flatpaks. Since I\u0026rsquo;m creating this VM, I decided to document the process on Proxmox as well as how to access the VM through an app like Remina for example.\nLet\u0026rsquo;s go ahead and jump into setting up this Ubuntu VM on Proxmox.","title":"How to Create a Ubuntu 22.10 VM on Proxmox"},{"content":"Hopefully, you have been following along with Part 1 and Part 2 of the Creating a Linode Linux VPS series. If not, be sure to go back and check out the previous 2 parts of the guide to get up to speed.\nIn part 3 we will be installing a package called fail2ban on our Linode Linux VPS, which will help to protect our VPS from unauthorized access attempts. Particularly brute force attacks. We will also be installing Apache, MySQL, and PHP, this will set up our VPS with the LAMP stack. Which stands for Linux, Apache, MySQL, and PHP.\nIn the end, we will point a domain name from Namecheap to the Linode server as well.\nOur Linode Linux VPS So Far At this point, you should have your Linux VPS setup, a new Linux user account created, secure SSH access with a private key, and firewalls in place.\nDon\u0026rsquo;t forget, if you haven\u0026rsquo;t set up your Linode account yet. Take advantage of the free $100 60-day credit using the link below. Plus, you\u0026rsquo;re helping me to keep creating content.\nLinode Coupon Code – $100 in Free Credit for 60 Days\nLet\u0026rsquo;s go ahead and get started with installing fail2ban.\nInstall fail2ban What is fail2ban? Fail3ban is a software package that monitors connection attempts to services like SSH. When continuous failed attempts are made, fail2ban jumps into action to configure our firewall for us to ban the IP addresses making those connections. This will stop a brute force attack in its tracks, which protects our server.\nTo install fail2ban on your Linode Linux server, run the following command in the terminal.\nsudo apt install fail2ban That\u0026rsquo;s all it takes to get fail2ban installed, but we also need to enable it. Before we do that, let\u0026rsquo;s check out some of the configurations we can do to fail2ban.\nConfigure fail2ban The default configurations for fail2ban exist in the /etc/fail2ban/jail.conf file. However, we do not want to edit this file directly, we will want to create our own copy and do our modifications there. So let\u0026rsquo;s create a new \u0026ldquo;jail.local\u0026rdquo; file that is a copy of the default configurations.\nsudo cp /etc/fail2ban/jail.conf /etc/fail2ban/jail.local Now we can use our favorite editor like nano, to open this config file and start exploring options.\nsudo nano /etc/fail2ban/jail.local The default configuration may be fine for you but you might also consider changing the number of tries that would trigger a ban and how long the ban is for. For these settings, find the following lines and configure them as you wish.\nbantime = 10m findtime = 10m maxretry = 5 For most setups, the defaults will be fine though, which protects SSH out of the box. Once you are finished with the configuration, you can start and enable the fail2ban service using the following command.\nsudo systemctl enable fail2ban sudo systemctl start fail2ban You can then check the status to ensure that fail2ban is running.\nsudo systemctl status fail2ban That\u0026rsquo;s it, you now have additional protection on the SSH service of your Linode Linux VPS. Let\u0026rsquo;s move on with installing Apache, MySQL, and PHP.\nInstalling Apache on a Linode Linux VPS Apache is one of the world\u0026rsquo;s most popular web servers, it is production ready and dependable with many configurations. As complex as it can be, Apache is really simple to install and start using.\nsudo apt install apache2 No need to start or enable the service, it is done for you automatically. However, you won\u0026rsquo;t be able to access it due to the UFW firewall and the Linode firewall. We need to allow Apache to communicate on ports 80 and 443 (HTTPS).\nFor UFW, run the following command to allow both HTTP and HTTPS traffic for Apache.\nsudo ufw allow \u0026#39;Apache Full\u0026#39; You will need to head over to the Linode website and add a rule to allow the preset HTTP and HTTPS traffic to our Linux VPS. If you don\u0026rsquo;t remember how to do this, check out part 2 of the guide for some guidance.\nOnce you have the firewalls configured, you should be able to open up your browser, put in your Linode server IP, and get the following default Apache page.\nThe default location for this page is /var/www/html - so if you would like to put your own page here, this is the default location to do so. In a future post, we will discuss virtual hosts so you can host multiple domains. Let\u0026rsquo;s move on to installing PHP and MySQL for now, then we will configure a domain name for Apache and our Linux VPS on Linode.\nInstall PHP on a Linux VPS with Apache Installing PHP is about as simple as installing Apache, we will also install some common modules for MySQL for example. May save you some headaches down the road of installing these later. Feel free to remove the ones you know you won\u0026rsquo;t need. the only required ones will be \u0026ldquo;php libapache2-mod-php and php-mysql\u0026rdquo;.\nsudo apt install php libapache2-mod-php php-mysql php-curl php-json php-cgi php-gd php-mbstring php-xml php-xmlrpc We will also need to restart Apache after installing these packages.\nsudo systemctl restart apache2 Test PHP Installation We can run a simple test of PHP and ensure it\u0026rsquo;s working properly with Apache. In the /var/www/html directory, we will create a test.php file with the following content in it.\n\u0026lt;?php phpinfo(); ?\u0026gt; You can now open a browser to HTTP://ipaddress/test.php, if the installation of PHP was successful, you should see a page like the one below.\nNote: If you get a blank page, reboot the server and try loading the page again.\nOnce you have confirmed PHP is working, it is highly suggested that you delete the test.php file.\nInstall MySQL Server on Linode VPS Our last piece of software to install is MySQL, which will serve as a database for websites and apps such as WordPress.\nsudo apt install mysql-server After running this command, the MySQL server should automatically be started but you can verify this by checking the status.\nDue to some recent changes to the Ubuntu MySQL package and some of its default settings, we need to modify a few things so the mysql_secure_installation script can run properly.\nsudo mysql You should now be at a MySQL\u0026gt; prompt. Here we will run a command that changes the default authentication method of the root account. This will be set to mysql_native_password and a default password of \u0026ldquo;password\u0026rdquo;. This is needed so the script can run, afterwards, we will change the default authentication method back to auth_socket.\nmysql\u0026gt; ALTER USER \u0026#39;root\u0026#39;@\u0026#39;localhost\u0026#39; IDENTIFIED WITH mysql_native_password BY \u0026#39;ThisIsN0tAStr0NGP4ssw0rd!\u0026#39;; Next, we will exit the MySQL console.\nmysql\u0026gt; exit Next, we will use the secure MySQL install helper application to finish the setup.\nsudo mysql_secure_installation You will be asked a series of security questions such as password strength, disallowing remote root login to MySQL, removing test databases, etc. I suggest you answer yes to each question for the best security.\nOnce this is finished, you can log back into the MySQL console as root to change the default authentication method to auth_socket.\nmysql -u root -p mysql\u0026gt; ALTER USER \u0026#39;root\u0026#39;@\u0026#39;localhost\u0026#39; IDENTIFIED WITH auth_socket; You can also go ahead and create a new MySQL user that isn\u0026rsquo;t root with the following command. This command will create the user with the authentication method of mysql_native_password. This is for compatibility reasons with some PHP apps, you can try the suggested caching_sha2_password method instead to see if it works for your use.\nmysql\u0026gt; CREATE USER \u0026#39;thecd\u0026#39;@\u0026#39;localhost\u0026#39; IDENTIFIED WITH mysql_native_password BY \u0026#39;credibleDEV_2023!\u0026#39;; You will want to grant the new user privileges on tables, otherwise, they can\u0026rsquo;t really do anything useful. You can check out this blog post for more information on granting privileges.\nPoint a Domain Name to our Linode Linux VPS For your specific use case, accessing the Linux VPS with the IP address may be just fine. For those who have a domain name that they would like to point to their Linode Linux VPS, I will walk you through how to do this. My domain name is registered with Namecheap, you have a different provider but the setup is generally the same.\nBy far, the easiest way to go about doing this is to use Linode to handle your domain\u0026rsquo;s DNS. You can do this by adding your domain to Linode, then from your registrar like Namecheap, point the domain to Linode\u0026rsquo;s name servers.\nTo start, log in to Linode, the choose domains from the menu. On the domains page, you will see an option for \u0026ldquo;Create Domain\u0026rdquo;. Click that button which will take you to this screen.\nHere, you will fill out the domain name, email address and under the \u0026ldquo;insert default records\u0026rdquo; dropdown, you can choose your Linode Linux VPS. This will create necessary A records for you to make this much easier.\nAfter you have added your domain, select it from the list of domains which will take you to the page listing all the DNS records. Here you will find a section titled \u0026ldquo;NS Record\u0026rdquo;. These are the name servers you want to add to your domain in the registrar like Namecheap.\nOver on Namecheap, this is what it looks like when the nameservers have been added. This will vary by registrar though.\nOnce you have added the nameservers, it can take some time before they have propagated, sometimes up to 24 hours.\nYou should be able to ping your domain and get the IP for your Linode VPS once this is complete. You should also be able to access the domain in a browser and see the default Ubuntu Apache page.\nI would suggest editing the default index.html file found in /var/www/html to whatever you want to just making it a blank page. No need to expose to the internet that we run Apache on Ubuntu and that we are too lazy to change the default page, lol.\nPart 3 Conclusion Stay tuned for part 4, where we will further configure Apache, set up SSL with Let\u0026rsquo;s Encrypt, and more.\nTo recap, at this point, you have a secure VPS setup with SSH, firewalls, and fail2ban. We have set up Apache, PHP, and MySQL. Now we have pointed a domain name to our Linode and let Linode manage the DNS for the domain name.\n","permalink":"http://localhost:1313/create-a-linode-linux-vps-part-3/","summary":"Hopefully, you have been following along with Part 1 and Part 2 of the Creating a Linode Linux VPS series. If not, be sure to go back and check out the previous 2 parts of the guide to get up to speed.\nIn part 3 we will be installing a package called fail2ban on our Linode Linux VPS, which will help to protect our VPS from unauthorized access attempts. Particularly brute force attacks.","title":"Create a Linode Linux VPS Part 3 – 2022 Quickstart Guide"},{"content":"Installing software is a core function of any operating system, pacman, the package manager built into most arch based Linux distributions such as Manjaro Linux serves this purpose well. It is a powerful command-line utility that everyone who uses an Arch based Linux distro should be familiar with.\nIf you prefer a GUI over using the command line, you can also use pamac, which comes pre-installed typically. Pamac also allows you to handle Flatpaks and packages from the AUR repository, which is a nice bonus.\nPacman is the main utility you will find yourself using on Manjaro to install, update and maintain most of the software on your machine. So, it is essential to understand how to use pacman effectively to install, search, update and inventory the software installed.\nToday, we are going to break down 11 of the most common command line functions that will help you make better use of the pacman package manager on Manjaro. Let\u0026rsquo;s get into it.\nUse Pacman to Install a Software Package The most common and vital function of them all is simply to install a new software package using pacman. If we want to install Firefox, for example, this is the command we would use.\nsudo pacman -S firefox Sync Package Database in Pacman Packages are updated constantly, so the database needs to be refreshed to ensure you are getting the most up-to-date software from pacman and its repositories. Running this command will sync the databases.\nsudo pacman -Syy Sync the Pacman Database and Update Installed Packages Most likely, you are not wanting to just sync the database like with the previous command, you also want to update any out-of-date packages that you have installed. The following pacman command will do just that, it will sync the databases and check for any out-of-date packages on your system.\nsudo pacman -Syu Use Pacman to Search for Available Software Sometimes you may not know the exact package name of the software you want to install. Pacman offers the ability to search for available packages and you can also use regular expressions if that\u0026rsquo;s your thing. If we want to search for Gimp, we can use the following command.\nThis will search package names and descriptions for the keyword or expression that you enter.\nNote: You can also use the Arch website to search for packages as well.\nsudo pacman -Ss gimp You\u0026rsquo;ll notice in the output from searching for the package called Gimp, the version number is listed but to install Gimp or the XSane plugin for Gimp, we would not use the version number to install it necessarily. We would simply run \u0026ldquo;sudo pacman -S gimp\u0026rdquo; or \u0026ldquo;sudo pacman -S xsane-gimp\u0026rdquo;.\nUse Pacman to Search for Installed Packages You can also use pacman to search your Manjaro or Arch based Linux system for packages that are already installed. If we wanted to search our system to see if Gimp is installed, we can use the following command.\nsudo pacman -Qs gimp Use Pacman to Uninstall Software and Packages If you have unneeded software on your system, pacman makes it easy to uninstall and also clean up dependencies that are no longer needed as well. If we wanted to uninstall Gimp and all of the dependencies that are no longer needed we can use the following command.\nNote: Any dependencies still needed by other applications will not be removed. If you want to remove a package without cleaning up dependencies, remove the \u0026ldquo;ns\u0026rdquo; option from the command and just use \u0026ldquo;-R\u0026rdquo; instead.\nsudo pacman -Rns gimp Listing All Installed Apps with Pacman If you want to spit out a list of all of the packages installed on your system, pacman can help with that. We can also break it down further by apps you installed as opposed to packages that were installed by Manjaro for example. We can also break out just a list of packages installed from the AUR repository.\nsudo pacman -Q List User Installed Apps This command will list all of the apps you installed yourself.\nsudo pacman -Qe List Apps Installed from the AUR Repository This command will list only the software packages that were installed from the AUR repository.\nsudo pacman -Qm Use Pacman to List Orphan Packages If you want to list out all packages that are considered orphaned or no longer needed. Run the following pacman command. You could then uninstall these packages since they are no longer needed and waste hard disk space.\nsudo pacman -Qdf Clear Pacman Cache Pacman can use quite a bit of disk space from cached packages and database cache. You can easily clean this up to free up additional disk space by running the following command.\nsudo pacman -Sc Pacman Config File Options Did you know that you can customize some features of pacman? Check out the pacman config file, typically found here: /etc/pacman.conf\nIn this config file, you can configure the behavior of pacman, such as checking for available space before installing a package, color terminal output from pacman and more.\nYou can read about the full pacman config file options here in their documentation.\nGUI Frontend Package Manager Manjaro Linux and other Arch distros also come with pamac, which is the GUI frontend for package management. For those who are not comfortable with the command line yet, or simply prefer a user interface, pamac is perfect for managing packages on Linux.\nConclusion The provided examples on how to manage, update and install packages should get you started and cover most of the common uses and needs. Did I miss anything? Let me know in the comments. Meanwhile, check out a recent post about how to install Onedrive on Manjaro Linux.\n","permalink":"http://localhost:1313/how-to-use-pacman-on-manjaro-linux/","summary":"Installing software is a core function of any operating system, pacman, the package manager built into most arch based Linux distributions such as Manjaro Linux serves this purpose well. It is a powerful command-line utility that everyone who uses an Arch based Linux distro should be familiar with.\nIf you prefer a GUI over using the command line, you can also use pamac, which comes pre-installed typically. Pamac also allows you to handle Flatpaks and packages from the AUR repository, which is a nice bonus.","title":"11 Ways to Use Pacman on Manjaro Linux"},{"content":"For someone who writes documentation all the time, screenshots play a big role in the documentation process. In my humble opinion, for Manjaro and other Linux distributions, Spectacle takes the cake when it comes to screenshot utilities.\nSpectacle is actually part of KDE, which is how I was first introduced to it on the Manjaro Linux KDE edition. However, Spectacle can run outside of the KDE desktop environment. I still use Spectacle for every screenshot, even on my i3 window manager setup of Manjaro.\nDon\u0026rsquo;t just take my word for it, Spectacle offers a lot of features that make it a complete and easy-to-use screenshot utility for Linux. Let\u0026rsquo;s break down some features and why I believe they are important and useful.\nSpectacle Capture Mode In Spectacle, you can capture the screen or portions of the screen in all of the standard modes. If you want to capture all monitors at once, one screen, the current window, or a selection, Spectacle has you covered.\nYou also have additional options such as hiding or including the cursor in the screenshot or removing the window and title bars.\nTimer Delay on Screenshot One would think that having a timer delay option would exist on all screenshot utilities, but it doesn\u0026rsquo;t. I was surprised by this fact when exploring other tools for screenshots on my Manjaro Linux machine.\nTimers and on-click options are very handy when you need to get a screenshot of a dropdown menu for example. This is a common task when writing documentation, Spectacle makes this a breeze.\nEasy Annotations for Screenshots When taking screenshots for documentation, it is basically required that you annotate the image. Some examples of this are drawing arrows, highlighting, adding text, etc.\nSpectacle has all of this built-in, so there is no need to export the screenshot to another image manipulation program (although you can, right from Spectacle).\nSpectacle has a ton of built-in annotations. These save you a ton of time and frustration.\nHighlighting\nArrows and Lines\nBlur and Pixelating (to hide information such as names, email, IP address, etc.)\nText\nNumbers inside circles (for numbering steps for example)\nShapes\nEmoji Stickers\nInstalling Spectacle You should be able to find Spectacle in the software manager for any Linux distro, just search for spectacle or use the following command line installs for your flavor of Linux.\nManjaro or Arch Install sudo pacman -S spectacle Debian or Ubuntu Install sudo apt install spectacle Fedora Install sudo dnf -y install spectacle Spectacle SNAP Package Install sudo snap install spectacle Conclusion Hopefully, you can see why Spectacle is my favorite Manjaro Linux screenshot utility and it works great on any flavor of Linux. Check out this post on my other favorite Manjaro Linux apps.\nDo you use a different screenshot utility? Let me know what it is in the comments!\n","permalink":"http://localhost:1313/spectacle-the-best-manjaro-screenshot-utility/","summary":"For someone who writes documentation all the time, screenshots play a big role in the documentation process. In my humble opinion, for Manjaro and other Linux distributions, Spectacle takes the cake when it comes to screenshot utilities.\nSpectacle is actually part of KDE, which is how I was first introduced to it on the Manjaro Linux KDE edition. However, Spectacle can run outside of the KDE desktop environment. I still use Spectacle for every screenshot, even on my i3 window manager setup of Manjaro.","title":"Spectacle: The Best Manjaro Screenshot Utility"},{"content":"I\u0026rsquo;ve heard the Linux elite talk about tiling window managers, like Manjaro i3 edition, for some time. So I decided to dive into the i3 tiling window manager on my Manjaro desktop, and these are some things I learned.\nThis isn\u0026rsquo;t really my first dive into a tiling window manager, I\u0026rsquo;ve run across some before, likely by accident as I recall. I believe it was an early adventure into Arch that led me to an unpleasant experience with a tiling window manager that I don\u0026rsquo;t remember the name of. Being brought to a desktop where there wasn\u0026rsquo;t really anything to click on and no menu to be found, or so I thought.\nI didn\u0026rsquo;t really give this window manager a fair shake, in frustration of not knowing what to do, I installed something more familiar like KDE or Gnome. Ah, finally, a menu and a clickable interface.\nFast forward to last week, I decided to dive straight into the Manjaro i3 version of the window manager by installing the i3 community install of Manjaro. At this point, I had watched a few YouTube videos about i3, which explained how to navigate, use dmenu and show off their fancy customized bars, backgrounds, and transparency. I love how many of the Linux YouTube folks show htop, even when system performance is not even being discussed, it makes me giggle.\nAnyways, let\u0026rsquo;s jump into a few things I\u0026rsquo;ve learned so far during my time with the i3 window manager on Manjaro.\nMultiple Display Setup on i3 One of the first things I wanted to tackle before I customized anything was my display setup. I use a laptop, which is connected to an external display. So, sometimes I\u0026rsquo;m using just the laptop screen, and others I\u0026rsquo;m using a dual display setup with the external monitor above the laptop.\nAfter searching around online, I found that I could run commands to adjust the display using xrandr. This wasn\u0026rsquo;t too difficult, and plugging the commands in my i3 config file in Manjaro was pretty simple. The issue was switching from one monitor to two monitors, then back to one monitor.\nSo I continued searching and found some information about the applications arandr and autorandr. Wow, after setting this up, it did exactly what I wanted. In i3, when 2 monitors were connected, the displays were extended and my external display was recognized as being above my laptop\u0026rsquo;s built-in display. When I disconnected my external monitor, it recognized this and adjusted it appropriately for one monitor.\nEasy Setup for Multiple Displays on i3 To get started the easy way and save yourself some frustration, install the arandr and autorandr packages.\nsudo pacman -S arandr autorandr Once you have these packages installed, use dmenu (mod+d) or whatever menu you may have installed, to launch arandr.\nIn arandr, you can drag your displays around, change their resolution, etc. Go ahead and play around with the settings, once you have things the way you want, click apply and confirm the displays work the way you expect.\nNow that you have your displays the way you want them, we will head back to the command line and use autorandr to save this config so it can be automatically restored later.\nautorandr --save dualdisplay If you\u0026rsquo;re like me, you want another config for when the external display is disconnected, so only the laptop screen is in use. To do this, run arandr again, this time only configure one screen. My external display still showed up in arandr even though it was disconnected. If this happens to you, right-click on the external display in arandr and uncheck the active box to disable it. Then click apply to confirm everything works as expected.\nOnce you are satisfied with the second config, we will use the autorandr application in the command line again to save the single monitor config.\nautorandr --save singledisplay Add autorandr to i3 Config If you haven\u0026rsquo;t already made your own i3 config in Manjaro, you will want to create a copy of the default config, found here: /etc/skel/.i3/conifg\nCopy that default config to this file ~/.config/i3/config\nNow that we have our display profiles set up, we can add an autorandr line to our i3 config file. By adding this line, each time we log in, depending on the displays connected, autorandr will adjust accordingly.\nexec autorandr -c After adding this line and saving the config, you should be all set. Upon reboot, if you have 2 monitors connected, i3 should adjust to extend and position the screens the way that you saved them in arandr. If you have 2 monitors connected, then disconnect one of them, i3 should adjust again.\nAdjust i3 Wallpaper on Screen Change Something else annoying happened when I set my dual displays. I change the resolution of one of my monitors and when autorandr runs to change it, the wallpaper isn\u0026rsquo;t sized properly.\nManjaro i3 uses nitrogen for wallpaper selection and configuration, which is a nice tool. We just need to make a minor change to our i3 config to fix this issue though. First, you want to configure your wallpaper, which you can do by running nitrogen from the command line or from your chosen menu such as dmenu.\nOnce you have the wallpaper set up how you like, adjust the autorandr line we added to the i3 config to look like this.\nexec autorandr -c \u0026amp;\u0026amp; exec nitrogen --restore Now, when you reboot the wallpaper will be refreshed after autorandr makes adjustments to your displays.\nAutorandr Display Change Trigger If you have an issue with the wallpaper whenever a display is connected or disconnected, autorandr has the ability to trigger actions based on this change. This can be done by creating a postswitch script in the ~/.config/autorandr directory.\nCreate a new file in that directory called postswitch. An example of how I used this to trigger nitrogen to restore the wallpaper is shown below. I added a 3-second sleep because I had issues without it. Feel free to remove this and test it on your own machine.\n#! /bin/sh sleep 3 nitrogen --restore After you have created the script, you need to make it executable. This can be done using chmod in the following way.\nchmod +x ~/.config/autorandr/postswitch Now, whenever you connect to disconnect a display, nitrogen \u0026ndash;restore will be launched.\nBluetooth in Manjaro i3 I have a bluetooth mouse and I use Apple Airpods on my Manjaro laptop, so making bluetooth available in the i3 status bar was necessary for me and I didn\u0026rsquo;t want to manually launch a bluetooth manager every time I started my system.\nManjaro i3 comes with blueman installed, so I only needed to add a call to the applet in my i3 config file. This provided me with the bluetooth status bar icon where I could easily manage my bluetooth devices.\nAdd this line to the i3 config file.\nexec blueman-applet Now, on each reboot, the status bar icon for bluetooth is there and my mouse automatically connects after login.\nConclusion For those interested, my current i3 config can be found here (warning: it\u0026rsquo;s nothing fancy): i3 config Github repo.\nMy adventure with Manjaro i3 edition has been short so far but I plan to continue using it, so stay tuned for future tips, configs, etc. as I continue this journey. If you have any questions or suggestions, please drop a comment below and let me know! In the meantime, check our recent guide on Setting up a Yubikey for Manjaro Linux.\n","permalink":"http://localhost:1313/manjaro-i3-window-manager-tips/","summary":"I\u0026rsquo;ve heard the Linux elite talk about tiling window managers, like Manjaro i3 edition, for some time. So I decided to dive into the i3 tiling window manager on my Manjaro desktop, and these are some things I learned.\nThis isn\u0026rsquo;t really my first dive into a tiling window manager, I\u0026rsquo;ve run across some before, likely by accident as I recall. I believe it was an early adventure into Arch that led me to an unpleasant experience with a tiling window manager that I don\u0026rsquo;t remember the name of.","title":"Manjaro i3 Window Manager Tips"},{"content":"Using Ubuntu? Check our Guide to Install OneDrive on Ubuntu\nOneDrive for Linux is a thing? Yes, yes\u0026hellip; I know. Why would you want to install a Microsoft product on Linux? Well, if you’re like me, work and school are both heavily in the Microsoft ecosystem. So, I don’t mind and it makes my life easier if I can have access to OneDrive on my Linux machine.\nIf you really want to make other Linux users\u0026rsquo; blood boil, check out our guide on installing Microsoft Edge on Manjaro Linux.\nIf you fit into this box too, I will show you how to install and set up OneDrive on Manjaro Linux. We will explore both the command line tool and an optional GUI tool for managing OneDrive as well. Both of these projects are open source, so if you want to help make them better, you can!\nLet’s go ahead and get started.\nInstall OneDrive on Manjaro Linux The first thing we need is the core OneDrive for Linux component, which is provided by a user called abraunegg. This tool is really all you need to set up and run OneDrive on your Linux machine. It can be installed from the AUR repository in the GUI software manager or from the command line. Make sure you have AUR repository enabled in the preferences of the software manager before proceeding.\nIt’s important that you install version 2.4.15 or higher if you plan to use the optional GUI component. Current version as of this writing is 2.4.22\nCommand Line Install To install the core component of OneDrive for Linux, open up your terminal and run the following command. If you don\u0026rsquo;t already have it installed, you will need an AUR helper like yay installed.\nyay -S onedrive-abraunegg Software Manager Install In order to install the OneDrive for Linux core component using the graphical software manager, search for onedrive and make sure you have the AUR repository enabled in the preferences.\nConfiguring OneDrive from the Command Line If you plan on installing the OneDrive GUI, skip ahead to the next section, as the rest of the setup is simpler via the GUI.\nTo get started, open up a terminal and run the following command below. This will give you a URL that you need to open in your browser. When you open the link, you may be prompted to log in to your OneDrive account. Log in if prompted, then you will be redirected to a blank page. Here, you want to copy the URL in the address bar, then paste it back into the terminal where it’s asking for a response URI.\nIf everything is good, you should receive a message in the terminal saying that the OneDrive for Linux application is now authorized. We can now proceed with syncing. First, we can do a test sync, which is called a dry run, by running the following command.\nonedrive --synchronize --verbose --dry-run If no errors were observed and everything looks ok, we can proceed with a real sync of OneDrive on Linux. By running the following command, everything in your OneDrive will be downloaded to your local machine in a OneDrive folder within your home directory.\nIf you only want to sync a single directory, check out the other command listed in the section below.\nonedrive --synchronize Other Command Line Options If you would like to only sync one directory you can run the following command.\nonedrive --synchronize --single-directory \u0026#39;directoryname\u0026#39; There are many configurations that you can do to customize how OneDrive syncs on Linux, these are outside of the scope of this simple introduction. I would suggest you head over to this documentation page on the official GitHub repo for the project.\nInstall OneDrive for Linux GUI App This part is optional, the GUI app is nice to have and if you wish to install it you can grab the AppImage from the official GitHub repo.\nOnce you have the AppImage downloaded, you will need to make it executable by running the following command in the terminal where you downloaded the file.\nchmod +x OneDriveGUI-1.0.1_fix59-x86_64.AppImage Now you can simply run the GUI app by double-clicking the file or running the following command. Once you run it, you will be taken through a setup wizard that will get you started.\nThis wizard will walk you through initial profile creation, then you will have a chance to configure any sync options for OneDrive prior to the first sync. The GUI application offers many advanced options such as select file/directory sync, rate limit, file permissions, download only, upload only, and many more.\nWhen you\u0026rsquo;re ready, you can begin a sync through the GUI interface by clicking the play icon.\nAfter starting the first sync, you will be prompted to link your OneDrive account. This is done by opening the link provided in the app, logging into your OneDrive account, and then you are taken to a blank page where you will need to copy the URL in the address bar and paste it into the app.\nAfter you complete this step, your OneDrive account is now linked to the app and the sync can begin. You will be shown a status of the number of files being downloaded and a list of those files. This provides a familiar look and feel to the Windows version of the OneDrive GUI client.\nConclusion That\u0026rsquo;s it, you broke the Linux code of ethics and installed a Microsoft product on your Linux machine. Some of us just like to live by our own rules and that\u0026rsquo;s ok. If you have questions about installing or using OneDrive on Linux, let me know in the comments!\n","permalink":"http://localhost:1313/onedrive-for-linux/","summary":"Using Ubuntu? Check our Guide to Install OneDrive on Ubuntu\nOneDrive for Linux is a thing? Yes, yes\u0026hellip; I know. Why would you want to install a Microsoft product on Linux? Well, if you’re like me, work and school are both heavily in the Microsoft ecosystem. So, I don’t mind and it makes my life easier if I can have access to OneDrive on my Linux machine.\nIf you really want to make other Linux users\u0026rsquo; blood boil, check out our guide on installing Microsoft Edge on Manjaro Linux.","title":"Install OneDrive for Linux - Manjaro Edition"},{"content":"I\u0026rsquo;ve been using Linux off and on for years, and more recently Manjaro Linux has become my main Operating System of choice. I figured this would be a good time to cover some of my favorite Manjaro apps that I use often. Many of these Manjaro apps are available for other operating systems and distros as well, so be sure to check them out.\nThese apps are not in any particular order. Let\u0026rsquo;s go ahead and jump into my list of favorite Manjaro apps!\nSpectacle Spectacle is a screenshot utility that is packaged with KDE, which will be included by default if you installed the KDE version of Manjaro.\nSpectacle is not just a basic screenshot utility, it offers many other features such as cropping, obfuscating, annotating, and more. This is why I enjoy it so much, it makes creating images and screenshots for my website very easy.\nKdenlive Kdenlive is a must-have for me since I also create YouTube videos. While it may not be quite as feature-rich as something like Adobe Premiere, it has everything you need for basic video editing. There are some additional features such as transitions, effects, annotations, titles, animations, etc.\nKdenlive is also available on Windows and Mac in addition to Linux. Try it out, it\u0026rsquo;s free and open source!\nBitwarden Bitwarden is one of the Manjaro apps that I couldn\u0026rsquo;t live without. Security should be important to everyone, and using unique and strong passwords is imperative. Bitwarden makes this task easy and enjoyable. Bitwarden not only generates and stores complex passwords for you but also handles MFA codes, stores notes, and provides the ability to share account information with the family.\nThe browser plug-in can also make it more convenient to log in to websites by entering credentials automatically. With Bitwarden\u0026rsquo;s zero knowledge system, I trust this service to manage and secure passwords.\nBitwarden is available for pretty much every OS, either through the browser extension or the desktop app. There is no reason not to be using a password manager and Bitwarden is the one I would recommend.\nMailspring Maybe you enjoy heading to a website to receive, send and manage your email, but I do not. After using Thunderbird for many years, I finally switched over to Mailspring once they removed the requirement to create an account with them.\nI can manage multiple email accounts using Mailspring and their easy-to-use interface makes it a simple and enjoyable task. Thunderbird feels archaic in comparison, to be honest. If you\u0026rsquo;re looking for a new email client with a modern feel and lots of features, check out Mailspring. It\u0026rsquo;s open source and it\u0026rsquo;s available for Linux, Windows, and Mac.\nVirt Manager (Virtual Machine Manager) After using Virtual Box for virtual machines, I kept hearing recommendations for virt manager on Linux. Once I finally decided to try it, I haven\u0026rsquo;t looked back. So, if you\u0026rsquo;re still using Virtual Box, be sure to check our virt manager. It may not be as easy to get started, I wouldn\u0026rsquo;t say it\u0026rsquo;s difficult though. I\u0026rsquo;ve found that the performance of my VMs is far better in virt manager over other tools I\u0026rsquo;ve used as well.\nVirt manager is only available for Linux but it is available for basically any distro, including Arch-based distributions like Manjaro, which is why it is one of my favorite Manjaro apps.\nOneDrive for Linux Check out our Guide on Installing OneDrive for Linux, including a GUI client.\nI know, I know! Why would you want to install a Microsoft product on Linux? The truth is, many of us are forced into the Microsoft ecosystem through work or school, and our files are managed through OneDrive. Sure, you could use the web client, but sometimes that isn\u0026rsquo;t feasible for your scenario or it\u0026rsquo;s just cumbersome.\nThere are 2 open-source projects to assist with OneDrive. One of which is a base for handling the setup and syncing, and the other offers a GUI interface, which is very nice. The GUI app is not required, but it does make managing OneDrive and viewing the status nicer.\nYou can find the app here: https://abraunegg.github.io/ and the GUI Client here: https://github.com/bpozdena/OneDriveGUI\nOther Manjaro Apps The apps listed here are quite common but I figured I would mention them for those curious about apps available on Manjaro Linux. These are all apps I use today, many of these are cross-platform as well, so be sure to check them out.\nFTP Client - FileZilla\nVPN - ExpressVPN (Manjaro ExpressVPN Install Guide)\nCode Editor - Visual Studio Code (Visual Studio Code Install Guide)\nC# .NET IDE - Rider\nScreen Recording - OBS\nImage Editing - Gimp\nBrowser - Firefox or Edge (Edge Install Guide for Manjaro)\nNetwork Traffic Analyzer - Wireshark\nSystem Backup - Timeshift\nOffice - OnlyOffice\nWhat Manjaro Apps Do You Use? This is a list of my favorite Manjaro Apps, but what are your favorites? What apps could you not live without? Which apps make Linux more enjoyable for you? Let me know in the comments!\n","permalink":"http://localhost:1313/favorite-manjaro-apps/","summary":"I\u0026rsquo;ve been using Linux off and on for years, and more recently Manjaro Linux has become my main Operating System of choice. I figured this would be a good time to cover some of my favorite Manjaro apps that I use often. Many of these Manjaro apps are available for other operating systems and distros as well, so be sure to check them out.\nThese apps are not in any particular order.","title":"My 6 Favorite Manjaro Apps"},{"content":"Welcome to part 2 of our guide on Creating a Linode Linux VPS. You can check out part 1 of the guide here. Part 3 is now live as well, going over how to set up Apache, PHP, MySQL, and a domain name.\nLinode Coupon Code – $100 in Free Credit for 60 Days\nA big part of running your own Virtual Private Server (VPS), is securing the server. One of the first steps that you should take is creating a new user and securing SSH. These are very basic steps that go a long way in protecting your VPS. Not long after bringing a VPS online, there will be bots and other automated attacks attempting to connect via SSH. By simply disabling root access via SSH, having a new user and only allowing SSH connections with a private key, your server will be much more secure against the attacks.\nIn this guide we will walk through creating a new user, giving them administrator access through sudo, disabling root SSH access, and setting up private key authentication. Let’s get started.\nAdd a New User to our Linode Linux VPS First, we need to access our VPS via SSH as we did in part 1 of this guide.\nssh@serverip Now that we are connected to our server, let’s create a new user. We will create a new user with the name thecd by running the following command in the terminal. Name your account whatever you’d like.\nadduser thecd You will then be asked to create a password, be sure to choose something secure. You will also be asked for information such as name, phone number, etc. you can leave these blank.\nGive Our User Sudo Privileges Now that we have a new user account created, we need to add this user to the sudo group so that the user can maintain and administer the server with elevated privileges when needed. We add user account thecd to the sudo group by running the following command.\nusermod –aG sudo thecd Now we have a new user and they can do admin tasks through sudo, we can log out of the root again and reconnect with our new account. Simply type logout in the terminal and press enter to disconnect. Now reconnect as your new user and log in with the following command.\nssh thecd@serverip Go ahead and run a command using sudo, then enter your password when prompted to confirm the permissions are correct. You can simply check for updates using APT for example.\nsudo apt update Once you have confirmed that you can connect, we can start configuring the SSH keys so that our server is better protected. This process will be different depending on the OS you are connecting with, such as Linux or Windows. We will go through the process on both.\nConfiguring SSH Keys Once you have confirmed that you can connect, we can start configuring the SSH keys so that our server is better protected. This process will be different depending on the OS you are connecting with, such as Linux or Windows. We will go through the process on both.\nGenerate SSH Keys from a Linux Host To generate the key pair needed for this setup, you will run the following command from your Linux machine, not the server. This will generate a private/public key in your home directory under the .ssh folder. Be careful, if you already have a key there, this will overwrite it.\nssh-keygen –b 4096 You will be asked where to save, it is fine to keep the default. You will also be asked for a passphrase, which is optional. The passphrase is an additional layer of security since an attacker would need both the private key and the passphrase used.\nNow that we have a keypair, we need to put the public key on our VPS, which is very easy to do from a Linux machine. We run the following command to complete this step.\nssh-copy-id thecd@serverip Now that our public key has been copied to the server, we can switch back to the terminal where we are connected to the server with the new user and log out. Simply run the logout command from the server terminal window.\nOnce you are disconnected, reconnect to the server as the new user, this time you won’t be prompted for the password. If you chose to set up a passphrase during the previous step, you will be asked for that instead of the password.\nYour setup for private key authentication is complete. Keep your private key safe and be sure not to lose it.\nGenerate SSH Keys from a Windows Host If you are on a Windows device, you will use a utility that comes with PuTTY to generate your keys. If you followed part 1 of this guide, you already have PuTTY installed. Otherwise, you can download PuTTY here.\nFirst, we want to launch the PuTTYgen, which you can find in your Windows start menu under PuTTY.\nIn PuTTYgen, you will want to change the number of bits to 4096, which is located in the bottom right corner. Also make sure RSA is selected, then click the generate button. You will keep moving your mouse as instructed to randomize the key generation. When complete you will be presented with the public key and the option to configure a passphrase if you wish.\nOnce this is complete, open up notepad, copy and paste the public key into notepad. Keep this notepad open, you’ll need it later. Do not use the save public key button, as this will mess up the formatting. Next, click the save private key to save it, and keep the default format which should be a .ppk file.\nNow that we have generated and saved the keys, we need to include our private key in PuTTY and copy our public key onto the server. Go ahead and fire up PuTTY. If you followed part 1 of this guide, you saved the connection to your server in PuTTY, so you can select it from the list and click on load.\nNext, you will want to expand SSH on the left side and select Auth, then select Credentials. Here you will find a box to input your private key. Go ahead and click on browse and navigate to where you saved the private key file. After you input your key, on the left menu, scroll to the top and click session, then click on save. Otherwise, the key file won\u0026rsquo;t be saved for future sessions.\nOnce complete, click Open at the bottom to launch the terminal sessions. Input your username and password to log in.\nNow that we are connected to the server, we need to run a few commands to create the directory and file used to store our public key. We also need to protect the folder and file using Linux file permissions with the chmod command. After this is complete, we need to open the file using your favorite editor, such as nano, to input the public key and save it.\nmkdir –p ~/.ssh touch ~/.ssh/authorized_keys chmod 700 ~/.ssh chmod 600 ~/.ssh/authorized_keys nano ~/.ssh/authorized_keys Once you have the authorized_keys file open, paste in the public key from notepad. It should look something like this. You can press Ctrl+O to save the changes to the file and Ctrl+X to exit the editor.\nYou can now test that your key works. Once you’re back at the terminal run the logout command to disconnect, then reconnect using PuTTY. If everything was successful you should not be prompted for your password. If you set up a passphrase, you will be prompted for that though.\nSSH Security Config So far we have set up and confirmed that we can connect via SSH to our Linode Linux VPS with our keypair, so we are good to start securing SSH a bit more. We will do this by preventing root login via SSH and disabling password authentication for SSH. This means you will not be able to connect to SSH with the root account and you will only be able to connect with a private key for the new user you created previously.\nIn your server terminal session, we want to edit the SSH config file to complete these changes. Run the following command to open the SSH config file.\nsudo nano /etc/ssh/sshd_config In this file, find the line that says PermitRootLogin and change it from yes to no. Next, find the line that says PasswordAuthentication, and change it to no as well. So these lines should look like the following.\nPermitRootLogin no PasswordAuthentication no Make sure you save the changes (Ctrl+O) and then exit nano (Ctrl+x). Now we need to restart the SSH service by running the following command.\nsudo systemctl reload sshd.service After running this command, do not log out of the server, instead, open a new PuTTY window and connect in a new session to ensure you can still connect.\nUbuntu Firewall Configuration Using UFW The next step we need to take in securing our Linode VPS is to enable the firewall on the server. This is an easy task that we will use UFW for. Since we only have one service that we are using, SSH, we only need to allow the SSH port which is 22.\nWe will add a rule to allow SSH using the following command.\nsudo ufw allow OpenSSH We can then run the following command to confirm that SSH is allowed. After running this command you should see OpenSSH listed under available applications.\nOnce confirmed, we will enable the firewall using the following command.\nsudo ufw enable After you have enabled the firewall, open a new terminal and confirm you can still connect to your server via ssh.\nYou can confirm the firewall is active by running the following command, which should show the status is active and list the OpenSSH rule we added.\nsudo ufw status Configure Firewall on Linode As an extra layer of protection, in case of an issue with the UFW firewall, we will set up the firewall directly from Linode as well. Head to your Linode dashboard and choose firewalls from the menu on the left.\nOn the firewalls page, click on create a firewall. You will then name the firewall and select the server to apply the firewall to. Once you’re finished, click on create firewall.\nAfter creating your firewall in Linode, you will see it listed. Go ahead and click on the name of the firewall you just created to open its rules page.\nHere, we want to add an inbound rule that allows SSH connections to our server.\nAfter adding the SSH rule, change the default inbound policy to deny. This will deny all inbound traffic except for SSH traffic. Since we are not currently hosting other services like a website, this is fine. After making all of your changes, click on save changes to apply the firewall to our Linode server.\nGo back to your PC, and launch a new SSH session to make sure you can still connect.\nConclusion In this guide, you have successfully completed the following tasks on your Linode Linux VPS.\nAdd a new user\nAdded your user to the sudo group\nCreated and configured SSH keys from Linux or Windows\nSetup and configured the Ubuntu and Linode Firewall\nCheck out Part 3 of this guide to set up Apache, PHP, MySQL, and point a domain name to your Linode VPS.\n","permalink":"http://localhost:1313/create-a-linode-linux-vps-part-2/","summary":"Welcome to part 2 of our guide on Creating a Linode Linux VPS. You can check out part 1 of the guide here. Part 3 is now live as well, going over how to set up Apache, PHP, MySQL, and a domain name.\nLinode Coupon Code – $100 in Free Credit for 60 Days\nA big part of running your own Virtual Private Server (VPS), is securing the server. One of the first steps that you should take is creating a new user and securing SSH.","title":"Create a Linode Linux VPS Part 2 – 2022 Quickstart Guide"},{"content":"This is a multi-part series. Part 1 (this guide) is the basics of setting up the VPS on Linode. Part 2 covers SSH and Firewalls, and Part 3 covers installing Apache, PHP, MySQL, and setting up a domain name for our Linode VPS.\nPersonally, I use Linode Linux VPS\u0026rsquo;s (virtual private servers) to run multiple app projects, and websites and for testing certain technologies. Linode is one of the easiest platforms to get started with Linux servers in my opinion and a great place to learn about and deploy your projects. Their interface is well laid out, easy to understand, and they offer many ready-to-go options in their marketplace if you don’t want to start from scratch.\nIn this post, we will cover how to set up a Linux VPS and then secure it so that your shiny new server is protected and ready for the internet and your next project or website.\nWhat is a VPS? A virtual private server, also known as a VPS, is a server instance that you lease in a remote data center. This could be a Windows or Linux server for example. Typically, a VPS will be a virtual server running alongside many other servers on a single physical server. You decide how much CPU, RAM, and storage you need as well as the geographical location and the cloud provider like Linode will select the best physical server to place your instance in. You could purchase a dedicated server instance, but these are typically not necessary for a small or medium-sized website or project.\nhttps://www.youtube.com/watch?v=zY-UGVHSHPU\nSetup a Linode Linux VPS There are only a few quick steps that need to be completed to get up and running with a VPS on Linode. You will need an account and I have a referral code with them that will give you $100 to start out with, so you can test Linode out for free. We will then create our VPS, configure it and finally, connect to the VPS from our Windows or Linux PC. Let\u0026rsquo;s get started!\nCreate Your Linode Account The first step is to create an account with Linode. If you use this link to join Linode, you will receive a free $100 credit to use during your first 60 days. So, essentially you can get a free Linode server for 2 months to test out their services.\nLinode Coupon Code - $100 in Free Credit for 60 Days\nCreate a VPS on Linode To get started you will want to click on Create Node from your main dashboard after logging in to Linode.\nOn the following screen, we will select from various options to customize our VPS.\nAlthough we are not doing this for our guide. You will notice a Marketplace tab on this page, this is where you can install pre-configured images for popular apps and tech stacks. Here are a few examples of what you can choose from the Linode Marketplace for quick setup.\nLinode Marketplace LAMP Stack – Linux, Apache, MySQL, PHP\nMERN Stack – MongoDB, Express, React, NodeJS\nNextcloud\nOpenVPN\nWordpress\nDocker\nCloudron\nMinecraft Server\nDjango\nJoomla\nCS:GO Server\ncPanel\nAnd Over 80 more\nBack to our setup, let’s go back to the distributions tab and continue our VPS setup.\nImage – This is the OS image we want to install on our VPS (I chose Ubuntu 22.04)\nRegion – Which Linode data center our VPS will be located in.\nSize – The amount of RAM, CPU, Storage and Transfer that our VPS will have. (This can be changed later if needed)\nFurther down the page, we have additional options to configure our Linux VPS on Linode.\nLabel – Give your Linode VPS a descriptive and appropriate label.\nTags – This is a way to categorize your Linode VPS in case you have many servers in your account. Most users won’t have a need for this.\nRoot Password – This is the root password for your Linux server. You want to create a complex and unique password. Later we will configure a public/private key pair to better protect access to our VPS.\nSSH Key – If you are new to Linode, you won’t have anything here yet, so you can skip this for now.\nVLANs – VLANs are an advanced networking option, and most users will not have a need for this.\nJust a few more options and we’ll be finished with the initial setup of our VPS.\nBackups – For an additional cost, you can enable managed backups. Linode will take care of creating automated backups for you.\nPrivate IP – This will not be needed for most users but if you have networking set up between multiple Linode instances, you may have a need for this.\nOnce you have finished the last few options, you can click on Create Linode to start building the VPS.\nNow Linode will start provisioning your new Linux VPS, this process will only take a few minutes and this page will update automatically. Once it says that your VPS is running, you will be able to SSH to your shiny new VPS using the root account and password you created in the previous steps.\nConnecting to Your Linux VPS via SSH\nNow we are ready to connect to our VPS. SSH is the most common method of connecting to a Linux VPS. SSH connections can be initiated from your Linux, Windows or Mac PC and we will cover how to make this connection from the various Operating Systems.\nSteps to Connect via SSH Get the Linux Server IP Address\nObtain an SSH Client\nConnect to the Linode Linux VPS Using the root Account and Password\nConnect to Linode from Linux To get started, open a terminal and check if SSH is already installed, it likely is. Type ssh into the terminal and press enter to see if it is installed. You should see output similar to the below image if it is installed.\nIf it is not installed, you should use your package manager like APT, pacman, etc. to install it. The package name is different depending on the Linux distribution, such as Ubuntu or Arch/Manjaro Linux for example. The package may be called openssh-client or simply openssh.\nOnce you have installed SSH or confirmed that it is installed. You can connect by running the following command, replacing the IP address with the IP of your Linode Linux VPS.\nssh root@ipaddress On your first connection, you will be asked to add the fingerprint, this is ok and you should say yes to this question. You will then be prompted for the root password that you configured in the previous steps.\nCongratulations, you are now connected to your Linux VPS on Linode!\nConnect to Linode from Windows In order to connect to Linode from Windows, I suggest that you use a 3rd party tool such as PuTTY, which you can download for free.\nOnce you have it downloaded and installed, go ahead and launch it. Fill in the IP address for your Linode VPS, give it a name under saved sessions, click Save and then click open to launch the session.\nOnce you click open, a terminal window will appear and you may be prompted to accept the thumbprint, go ahead and accept that. You will now see a prompt for a username, you will use root and then enter the password at the next prompt.\nIf everything went well, you will be connected to your Linode Linux VPN through PuTTY.\nUpdate The last thing we need to do before wrapping up part 1 of creating a Linode Linux VPS is to update the server OS. In this case we set up our server with Ubuntu so we will run the following commands as root.\napt update apt upgrade After this is complete, which may take a few minutes, we may need to reboot the server. Pay attention to the text on the screen, it will let you know if you need to reboot. If you do, just run the following command as root to restart the server. It should only take a few minutes before it\u0026rsquo;s back online and you can reconnect.\nreboot Conclusion Check out Part 2 of this guide to secure SSH with keys and firewalls for Ubuntu and Linode.\nYou now have a Linode Linux VPS server up and running and have successfully connected to the server using SSH. That’s it for this guide. Follow on to Part 2 and I will show you how to secure SSH on your VPS with private keys and disable SSH login for the root account.\n","permalink":"http://localhost:1313/create-a-linode-linux-vps/","summary":"This is a multi-part series. Part 1 (this guide) is the basics of setting up the VPS on Linode. Part 2 covers SSH and Firewalls, and Part 3 covers installing Apache, PHP, MySQL, and setting up a domain name for our Linode VPS.\nPersonally, I use Linode Linux VPS\u0026rsquo;s (virtual private servers) to run multiple app projects, and websites and for testing certain technologies. Linode is one of the easiest platforms to get started with Linux servers in my opinion and a great place to learn about and deploy your projects.","title":"Create a Linode Linux VPS - 2022 Quickstart Guide"},{"content":"If you\u0026rsquo;re like me, you want to protect your systems from all sorts of attacks. We all know that multi-factor authentication is a great tool to better protect your computers, services, and accounts. This guide will walk you through how to setup a Yubikey on Manjaro Linux. What is Yubikey? Yubikey is a hardware device, typically USB, which serves as a multi-factor authentication method. You plug the device into your USB port and when authenticating to a system, you will tap it. These devices come in various forms, such as USB-A, USB-C, NFC etc. For this guide, I assume you already have a Yubikey device, if not you can grab one from their official site. I\u0026rsquo;m using the Yubikey 5 NFC for my example. Let\u0026rsquo;s get started setting up our Yubikey on Manjaro.\nhttps://www.youtube.com/watch?v=dbysj18RMII\nInstall Required Packages for Yubikey We need to install a few packages that are going to make using the Yubikey for authentication possible. Fire up your terminal and run the following command.\nsudo pacman -S autoconf automake libtool pkg-config libfido2 pam-u2f Collect and Store the Yubikey Keys It is recommended that you have more than one Yubikey, in case something happens to your primary. I have 3 total so I will be repeating this process 3 times, once for each key. We need to create a directory in our profile and then a u2f_keys file to store all of our keys. In your terminal, run the following command to create the folder.\nmkdir -p ~/.config/Yubico Next, make sure that your first Yubikey is plugged into your computer, then run the following command. Once you run this command, you may be prompted for a pin, if you\u0026rsquo;ve set one up. After this, your Yubikey will blink, and once you touch the device, the key will be stored in the key file.\npamu2fcfg \u0026gt; ~/.config/Yubico/u2f_keys If you have multiple Yubikey\u0026rsquo;s, insert the next one now and repeat the above command. This time, be sure to change the \u0026gt; to \u0026raquo;, otherwise, you will overwrite the previous key you set up.\npamu2fcfg \u0026gt;\u0026gt; ~/.config/Yubico/u2f_keys Setup Yubikey for Sudo Now that we have our keys stored, we are ready to setup the Yubikey to be used for running sudo commands. Before you proceed, it\u0026rsquo;s a good idea to open a second terminal window and run \u0026ldquo;sudo -s\u0026rdquo; in that terminal to get a root shell in case anything goes wrong. Leave this second terminal open just in case. In your other terminal, open up the file /etc/pam.d/sudo with your favorite editor.\nsudo nano /etc/pam.d/sudo You will want to add the following line to this file. Once this line is added, running a sudo command with your Yubikey plugged in will cause it to blink, once you tap it, the command will run. It will not ask for a password unless you don\u0026rsquo;t have the Yubikey plugged in.\nauth sufficient pam_u2f.so cue [cue_prompt=Tap your Yubikey] Go ahead and open a new terminal, then type a sudo command such as \u0026ldquo;sudo ls\u0026rdquo; to test it out. You should notice the prompt to tap the Yubikey, then the command completes without asking for a password.\nSetup Yubikey for Login to Manjaro Linux The next thing we want to use our Yubikey for is logging into the desktop. This is very easy to setup and similar to what we did with sudo. The file we want to edit is /etc/pam.d/gdm-password. This file applies to GDM, if you are using the KDE version of Manjaro you will want to edit /etc/pam.d/kde and /etc/pam.d/sddm instead. You will find multip \u0026ldquo;auth\u0026rdquo; lines in this file, we want to enter our line after all of the other \u0026ldquo;auth\u0026rdquo; lines like shown below. The Arch documentation on this references using \u0026ldquo;nouserok\u0026rdquo;, this will only be required if multiple users log in to this station and some do not have a Yubikey. If you are the only user, you don\u0026rsquo;t need to worry about this. Another note here is about home directory encryption, if you have this enabled, it\u0026rsquo;s likely you won\u0026rsquo;t be able to log in after making this change. You can refer to the official documentation for notes on encryption.\nauth required pam_u2f.so cue [cue_prompt=Tap Your Yubikey] You can now lock your computer and then log in. You should be prompted for the password and then to tap your Yubikey. If you run into issues, you can switch to another terminal by pressing Ctrl+Alt+F3 for example. From here you can log in and edit the file to remove the line you just added and gain access to your system again.\nSetup Yubikey for Terminal Login Next, we will enable Yubikey for terminal-based logins. Many of you may never even use the terminal without the GUI interface, but it\u0026rsquo;s a good idea to protect these logins with the Yubikey as well. We can do this by editing the file /etc/pam.d/login, and adding the following line after the other \u0026ldquo;auth\u0026rdquo; lines.\nauth required pam_u2f.so cue [cue_prompt=Tap Your Yubikey] You can switch to a terminal by pressing Ctrl+Alt+F3 to test this out. Once finished you can press Ctrl+Alt+F1 to get back to your desktop environment.\nSetup Yubikey for Other Auth Prompts in Manjaro Linux There are other prompts that you can setup Yubikey for on Manjaro Linux. Sometimes you receive prompts for your password when using the package manager or partition manager for example. Good news! We can protect those with the Yubikey as well.\nTo set this up for Yubikey, we will want to edit the file /etc/pam.d/polkit-1, and add the following line.\nauth required pam_u2f.so cue [cue_prompt=Tap Your Yubikey] After saving the changes, try launching the partition manager or something similar that generates an auth prompt. You should now be asked for your password and the Yubikey. You can change the word \u0026ldquo;required\u0026rdquo; to \u0026ldquo;sufficient\u0026rdquo; in the file if you want to only use the Yubikey and not be asked for the password. If you don\u0026rsquo;t have the Yubikey plugged in, you will be asked for the password.\nSweet! Now you have setup your Yubikey to use with Manjaro Linux! If you have any questions, please drop a comment down below!\n","permalink":"http://localhost:1313/easy-setup-yubikey-on-manjaro-linux/","summary":"If you\u0026rsquo;re like me, you want to protect your systems from all sorts of attacks. We all know that multi-factor authentication is a great tool to better protect your computers, services, and accounts. This guide will walk you through how to setup a Yubikey on Manjaro Linux. What is Yubikey? Yubikey is a hardware device, typically USB, which serves as a multi-factor authentication method. You plug the device into your USB port and when authenticating to a system, you will tap it.","title":"Easy Setup Yubikey on Manjaro Linux"},{"content":"\rSo you need to deploy PowerShell scripts in Intune, also known as Microsoft Endpoint Manager, or MEM? We\u0026rsquo;ve got you covered with 3 different ways to get your PowerShell scripts to Intune endpoint machines. We will cover deploying a single PowerShell script to run one time, deploying proactive remediations, and deploying a PowerShell script packaged as a Win32 app.\nThere are a few reasons you may want to deploy PowerShell scripts to Intune endpoint devices, such as Windows 10 computers and servers.\nRemediate or resolve security vulnerabilities on endpoint devices.\nUse a PowerShell script to install a complex piece of software that needs additional configuration.\nRun a quick script to change registry keys, modify files, or change settings.\nWhatever your reason for needing to deploy a PowerShell script, one of these three methods will be perfect for your needs.\nDeploy a Single PowerShell Script to Run One Time The fastest and easiest method to deploy PowerShell scripts in Intune is to use the \u0026ldquo;Script\u0026rdquo; feature found under Devices in the Microsoft Endpoint Manager console. Using this feature, your PowerShell script will run one time and you will get some limited reporting. You will get feedback if the script ran or not, but you will not get reporting on if the script did what was intended necessarily.\nOpen your browser to the Microsoft Endpoint Manager/Intune site, and click Devices from the menu on the left. Next, find the Scripts link in the Devices sub-menu, and click Add at the top to add your PowerShell script.\nAfter clicking Add, you will select the platform you are deploying to, either Mac or Windows devices at the time of writing. Next, you will name your script and provide a description. Once this is complete, you will select your PowerShell script file and configure these additional options.\nConfigure PowerShell Script Options Run this script using the logged-on credentials.\nThis will run the script as the currently logged-in user. Useful for when you need to make registry changes to the HKEY Current User registry hive with PowerShell. Enforce script signature check.\nThis will enforce code signing restrictions, meaning that your code must be signed. By default, the script will run with the ByPass Execution Policy mode. Run the script in a 64-bit PowerShell host.\nIn some situations, this may be needed, particularly when modifying registry keys. Without this option, you may be trying to modify keys in the SOFTWARE registry hive and your script is actually modifying the WOW6432Node hive instead. After you\u0026rsquo;ve selected your script and the necessary options, you will then assign the script to users or devices. That\u0026rsquo;s it, now you have your PowerShell script uploaded to Intune.\nUsing Proactive Remediations to Deploy a PowerShell Script in Intune As I stated earlier, Proactive Remediations are perfect for resolving security vulnerabilities. PowerShell scripts that are added to Intune using this method will include a detection script and a remediation script. The detection script is used to verify if the device needs to be remediated, if not, then nothing happens. If the detection script determines the device needs to be remediated, then the remediation script will be run on the device.\nProactive Remediation Script Requirements PowerShell Script Encoding Format UTF-8 Another important note here is that the scripts must be in UTF-8 encoding format, not UTF-8-BOM which the PowerShell ISE editor typically saves the scripts in. You can use an editor like Visual Studio Code or Notepad++ to set or change the encoding of a new or existing PowerShell script.\nPowerShell Exit Code Requirement For our detection script to work properly, we need to use the proper exit code to tell Intune if it needs to be remediated or not. As you can see in the screenshot above, the script uses \u0026ldquo;Exit 0\u0026rdquo; to say no we don\u0026rsquo;t need to remediate and \u0026ldquo;Exit 1\u0026rdquo; to say that it does need to be remediated.\nUse Exit code 1 so that Intune will run your remediation script.\nUse Exit code 0 to say that remediation is not needed.\nIn our example PowerShell script below, which we are using for a Proactive Remediation, we are looking for a file located on the C:\\ drive that is named Proactive_Remediation_Test.txt. Our detection script checks for the existence of this file. If the file is not found on the device, it returns with \u0026ldquo;Exit 1\u0026rdquo;, which means the device needs to be remediated. If the file is found, it returns with \u0026ldquo;Exit 0\u0026rdquo;, which means the machine is good and nothing additional needs to be done.\nIntune Proactive Remediation - Creating a Detection Script # PowerShell Proactive Remediation Detection Script If (Test-Path \u0026#34;C:\\Proactive_Remediation_Test.txt\u0026#34; -PathType Leaf) { Write-Host \u0026#34;Exists\u0026#34; Exit 0 } Else { Write-Host \u0026#34;File Not Found\u0026#34; Exit 1 } Intune Proactive Remediation - Creating a Remediation Script Our remediation script is very simple in this case, as it just creates the text file.\n# PowerShell Remediation Script New-Item -Path \u0026#34;C:\\Proactive_Remediation_Test.txt\u0026#34; -ItemType File Creating the PowerShell Script Proactive Remediation Package To upload your PowerShell scripts and create a proactive remediation, go to reports, then endpoint analytics, and choose Proactive Remediations from the menu. From here, you will click create script package from the top menu.\nNow you will configure your script package on the following pages.\nCreate a name for your script package and provide a description.\nUpload your detection and remediation scripts.\nConfigure options such as running the script as the logged-in user, signature check, etc. If you need more details about these options, see the previous section where those were discussed in more detail.\nApply Scope Tags\nAssign the Proactive Remediation to a specific user or device groups and configure the run frequency. This is how often you want to run the detection on each device.\nReview and Finish, congrats. You have added PowerShell scripts in Intune using Proactive Remediations.\nDeploy PowerShell Scripts in Intune as a Win32 App Our last method for deploying PowerShell scripts in Intune is to package them as a Win32 app package. This method is very flexible and is commonly used for complex app installs. If you have an MSI that you need to install with further customization, this can be a great option for you.\nYou can package a single PowerShell script that completes whatever action you need. You should also consider creating a uninstall script that will serve as a way to reverse or remove whatever action your install script completes.\nYou may also want to consider a detection script that will help Intune detect whether your app is installed correctly or not.\nInstall Script (Required)\nUninstall Script (Optional but recommended)\nDetection Script (Optional depending on what your app does)\nDownload the Win32 Content Prep Tool for Intune To package PowerShell scripts as a Win32 App, we need to use the Win32 Content Prep Tool provided by Microsoft. Go ahead and download the tool and extract it to a location on your local machine. Using a command prompt, navigate to the directory where you extracted the tool and run the \u0026ldquo;IntuneWinApp.exe\u0026rdquo; executable file.\nUsing the Win32 Content Prep Tool to Package a PowerShell Script After running the IntuneWinApp utility, you will be prompted for a source directory, this is the directory where your PowerShell script and any other needed files are.\nNext, you will be prompted for a setup file. If the PowerShell script is the first thing that needs to run, you will input the PowerShell script file name, including the file extensions, such as \u0026ldquo;.ps1\u0026rdquo;.\nLastly, you will be asked for the output directory. This is where you want to output the Win32 app package file that will we upload to Intune. This can be anywhere but I typically use the same directory that I used for the source directory. You can answer \u0026ldquo;no\u0026rdquo; to the catalog folder option unless you have a specific need for it.\nCreating a PowerShell Win32 App in Intune At this point, you should have a \u0026ldquo;.intunwin\u0026rdquo; file that can be uploaded to Intune. This is how we will use a Win32 app package to get PowerShell scripts in Intune.\nIn Microsoft Endpoint Manager, click on Apps from the left-side menu. On the Apps page, select \u0026ldquo;Windows\u0026rdquo; from the menu and then click \u0026ldquo;Add\u0026rdquo; from the top menu.\nNext, you will select \u0026ldquo;Win32\u0026rdquo; as the app type from the dropdown box.\nOn the following page, you will upload the \u0026ldquo;intunewin\u0026rdquo; file that you created using the Win32 Content Prep tool earlier.\nAfter uploading the package, you will then be prompted to name the app, provide a description, etc. Fill out the required information and proceed to the next page.\nWe now need to tell Intune how to execute our Win32 PowerShell script package. We do this by calling the PowerShell executable using the ByPass ExecutionPolicy mode and the name of our PowerShell script. In the following example, replace \u0026ldquo;install.ps1\u0026rdquo; with your script name. You can use this for the uninstall command as well, just replace the script name.\nPowershell.exe -ExecutionPolicy ByPass -File .\\install.ps1 Continue on through the process to configure the required system architecture and the minimum Windows version to target. For the detection rule, if you created a custom detection script, you will upload this here. Otherwise, you can use a built-in option to verify a registry key or that a file or folder exists for example. Finish the setup by assigning the app, and setting up any dependencies or supersedence rules.\nConclusion That\u0026rsquo;s it, you now know how to successfully deploy PowerShell script in Intune using three different methods. If you have any questions or need more detail on anything, please leave a comment down below. Thanks!\n","permalink":"http://localhost:1313/powershell-scripts-in-intune/","summary":"So you need to deploy PowerShell scripts in Intune, also known as Microsoft Endpoint Manager, or MEM? We\u0026rsquo;ve got you covered with 3 different ways to get your PowerShell scripts to Intune endpoint machines. We will cover deploying a single PowerShell script to run one time, deploying proactive remediations, and deploying a PowerShell script packaged as a Win32 app.\nThere are a few reasons you may want to deploy PowerShell scripts to Intune endpoint devices, such as Windows 10 computers and servers.","title":"Deploy PowerShell Scripts in Intune - 3 Easy Methods"},{"content":"If you are setting up a Proxmox Active Directory lab environment and are looking to install a Windows Domain Controller on Proxmox, this is the guide for you. Today we will walk through the installation and configuration of Windows Server 2019 and promote it to be a domain controller, all inside Proxmox. After completing this guide you will have a functional domain controller that you can then manage devices, virtual machines, users, and groups. Let\u0026rsquo;s go ahead and hop into Proxmox and create a new VM. Be sure to have a Windows Server 2019 ISO to install the OS with before proceeding. If you don\u0026rsquo;t have that, you can grab an evaluation copy from Microsoft.\nProxmox Virtual Server Setup Below is a screenshot of how I have configured my virtual machine for the Windows Server 2019 Domain Controller on Proxmox, you can copy these settings if you\u0026rsquo;d like.\nRemember to assign the Windows server ISO to the VM before powering it on, then you can follow along for the rest of the installation and configuration.\nWindows Server 2019 Install on Proxmox After the initial OS install is complete, the first boot into the OS will ask you set up an administrator password. You can now log in to your new Windows 2019 Server and start the configuration for a Domain Controller.\nOnce logged in, let us go ahead and rename the computer so it is not the default name that the windows install gave it. Right-click on the start button and choose Run. In the box type in sysdm.cpl and press enter. In the System Properties dialog box, click on Change next to the option to rename the computer and give the system an appropriate name such as DC01 for example. The system will want to restart, go ahead and do this.\nYou will also want to configure a static IP address in most cases.\nConfigure Domain Controller on Proxmox We are now ready to promote the server to a Domain Controller which is actually a pretty simple task. Let\u0026rsquo;s do that now.\nIn Server Manager, you should see an option to Add Roles and Features on the main page. If not, you can choose the Manage menu at the top right corner of the Server Manager page and find it there. Click Add Roles and Features to launch the wizard.\nChoose Role-based or Feature-based installation\nChoose your server from the list. Depending on your environment you may have more than one choice here.\nSelect Active Directory Domain Services and DNS Server from the list of options.\nOn the next screen, you can keep the default options unless you have something specific to install for your use case.\nContinue to click next through the information pages that come next. You will come to a confirmation page where you can click install, go ahead and complete the installation.\nOnce the installation has completed, you will have the option to promote the server to a domain controller, go ahead and choose this option.\nIf this is your first domain controller for your network, choose to Add a new Forest and supply the domain name.\nOn the next page, you will need to select the functional level of the domain controller and forest. I’m choosing 2008 R2 here, only because I know that I plan to add a Linux Domain Controller later and 2008 is a requirement for that. You can keep the default here or whichever option suits the needs of your environment. You will also set up a Restore Mode password, which is the password needed for AD restoration if the need ever arises.\nComplete the process by accepting the default options through the remaining screens. When you reach the final screen, click Install to complete the Installation. The server will reboot during this process.\nAfter restarting the service, you should now be connected to the domain. You can verify this on the system properties page.\nYour domain controller on Proxmox is now complete, you can proceed with creating domain user accounts.\nCreate OU\u0026rsquo;s and a Domain User Account We will proceed with creating some Organizational Units and a Domain Admin account. To do this, we should launch Active Directory Users and Computers. This can be found in the start menu or in the Server Manager under Tools.\nIf we right-click on our domain name, in my case, cdlabs.net, then choose New and Organizational Unit, we can create a new OU called HomeLab. You can call this whatever you like. Then right-click the new OU and create 2 more underneath HomeLab named Computers and Users like so.\nNow, we can create our domain admin user. Right-click on the Users OU and go to New, then choose user. Fill out the details for the new user account. Ensure you select a secure password, as this user will have a lot of control with domain admin rights.\nOnce your new user is created, you can right-click on the user and choose to add to a group. In the dialog box, type domain admins and press enter.\nAs a final step, you will want to set up a static IP address for your domain controller so that you can point your endpoints to the DC as their DNS server when joining the domain. The settings for this will be dependent on your environment.\nAt this point, you have successfully installed and configured a Windows Domain Controller on Proxmox and you can now build additional VMs to join your Windows domain. In a future post, I will show you how to join your On-Prem domain controller to Azure AD and begin syncing them. If you have any questions or want to see a specific guide, leave those in the comments. Thanks!\n","permalink":"http://localhost:1313/set-up-windows-domain-controller-on-proxmox/","summary":"If you are setting up a Proxmox Active Directory lab environment and are looking to install a Windows Domain Controller on Proxmox, this is the guide for you. Today we will walk through the installation and configuration of Windows Server 2019 and promote it to be a domain controller, all inside Proxmox. After completing this guide you will have a functional domain controller that you can then manage devices, virtual machines, users, and groups.","title":"Quickly Set Up a Windows Domain Controller on Proxmox - 2022 Guide"},{"content":"If you are a C# developer like me and you also use or would like to use Linux as your OS, this guide is for you. Today we will be walking through setting up dotnet in Linux and VSCode. I am using Manjaro Linux as my distribution, you may be able to take away information from this post and apply it to other distributions as well.\nIf you haven\u0026rsquo;t installed VSCode on Manjaro yet, check out our guide for that as well. We also just added a guide on installing JetBrains Rider for Linux as well, if you prefer a fully featured .NET IDE.\nGuide: Build Your 1st .NET C# GUI Linux App\nhttps://www.youtube.com/watch?v=QppKSrsuPZ8\nInstalling the dotnet sdk in Manjaro The first thing we need to get started with dotnet in Linux is to install the dotnet-sdk package. In Manjaro, this package is available in the community repository and the AUR repository as well. Go ahead and launch Add/Remove Software in Manjaro, then do a search for dotnet-sdk and install it.\nVerify dotnet Is Installed on Linux After the installation completes, we can open a terminal to verify the installation is good. We do this by typing the following command.\ndotnet --list-dsks If the installation was good, we should see a dotnet-sdk version and its location listed in the terminal output. Here we see that I have installed version 6.0.109 of the dotnet-sdk in Linux.\nInstall Multiple Versions of dotnet SDK If you find yourself needing to install multiple versions of the sdk on the same machine. The easiest way is to use the script referenced in this Microsoft document. This dotnet-install script will install the version you tell it and you can pass an install path by using the \u0026ldquo;\u0026ndash;install-dir\u0026rdquo; flag to pass in the directory that is shown when running \u0026ldquo;dotnet \u0026ndash;list-sdks\u0026rdquo;. In my example above, that would be /usr/share/dotnet/sdk. You can run the below command to install the current LTS version in addition to what you installed above. For more options refer to the Microsoft document.\nsudo ./dotnet-install.sh -Channel LTS --install-dir /usr/share/dotnet/sdk Now you can open a new terminal, then run \u0026ldquo;dotnet \u0026ndash;list-sdks\u0026rdquo; again to see that the additional dotnet sdk has been installed.\nTest dotnet with VSCode Let\u0026rsquo;s go ahead and fire up Visual Studio Code or JetBrains Rider. If you don\u0026rsquo;t already have it installed, I\u0026rsquo;ll link to a guide on installing VSCode on Linux below. JetBrains Rider will give you an experience similar to the fully featured Visual Studio IDE on Windows. Use the link above for a guide on installing Rider for Linux.\nInstalling VSCode in Manjaro\nOnce you have VSCode open, create a new folder for your C# Hello World program then open a new terminal in VScode, run the command dotnet new console. In the terminal, make sure you are inside the new folder that you created when running the command. Once you\u0026rsquo;ve done this, VSCode may recommend installing extensions, if so, go ahead a do that.\nRunning dotnet new console initializes a new dotnet console app. This will generate the appropriate project files in your directory. The command dotnet is the heart of the dotnet CLI, you can read more about it and it\u0026rsquo;s options on Microsofts dotnet site.\ndotnet new console If you are running dotnet-sdk 6 or higher, the program.cs file that is generated by dotnet console new, will be simplified with only a call to Console.WriteLine function in it. If you are running an older dotnet-sdk, you may need to use the code snippet below for testing.\nGo ahead and type the following code into your program.cs file for the C# Hello World Program if you are using an older dotnet-sdk version.\nnamespace HelloWorld { class program { static void Main(string[] args) { Console.WriteLine(\u0026#34;Hello World From Linux!\u0026#34;); } } } You are supposed to get a prompt to install the debugger and other tools that will allow you to run the application from the VSCode interface but in my experience, I didn\u0026rsquo;t get this. So to add it manually, go to Run in the top menu and choose Add Configuration.\nIn the popup, choose .NET 5+ and .NET Core from the options. This will add a launch.json file and .vscode folder to your project directory.\nRunning a dotnet Application on Linux in VSCode You are now ready to test run your first dotnet in Linux application. In the terminal of VSCode, make sure you are in your projects folder, then execute the dotnet run command. This should print Hello World! to the terminal window.\nConclusion Congrats, you have now installed dotnet in Linux and you are now ready to further explore writing dotnet and C# applications on Linux in VSCode. If you are wanting to develop cross-platform GUI apps that run on Linux. I highly suggest that you check out Avalonia UI. Soon we will have a guide on Avalonia UI to help get you start creating GUI apps for Linux.\n","permalink":"http://localhost:1313/dotnet-in-linux/","summary":"If you are a C# developer like me and you also use or would like to use Linux as your OS, this guide is for you. Today we will be walking through setting up dotnet in Linux and VSCode. I am using Manjaro Linux as my distribution, you may be able to take away information from this post and apply it to other distributions as well.\nIf you haven\u0026rsquo;t installed VSCode on Manjaro yet, check out our guide for that as well.","title":"Easily Install dotNet In Linux - 2023 Guide"},{"content":"\rIf you are a Linux user, then you have probably heard of chmod. But what is it, and how can you use it? Being a Linux user you also know how important the syntax of commands is, so we will discuss the proper chmod syntax that you should use. In this blog post, we will discuss the basics of chmod and show you how to use it in a few simple steps.\nYou might be interested in learning about other common commands, check out our guide on using the tail command in Linux.\nWhat is chmod? Chmod is a Linux command that stands for \u0026ldquo;change mode\u0026rdquo;. This command is used to change the permissions of a file or directory. With chmod, you can give different levels of access to different users. For example, you can give read and write permissions to one user, and read-only permissions to another. You can also apply file and folder permissions to groups using chmod.\nLet\u0026rsquo;s break down the structure and syntax for chmod in Linux so you can use it effectively as a Linux admin.\nLinux File Permissions Using ls -la We need to understand a bit about Linux file permissions and how to view them. These references below are based on what user and group have rights to the file. You can view this by using the directory listing command, ls, with the -la option. An example output is shown below for reference.\nIn the screenshot above, looking at the area where the root user is shown, root on the left side represents the user who owns the file and the root on the right represents the group. In this case, they are both root, this will not always be the case.\nAlso in the screenshot, you will see the specific read, write and execute permissions for the user, group, and everyone else (also referred to as \u0026ldquo;others\u0026rdquo;).\ndrwxr-xr-x In the above permission listing, the first character \u0026ldquo;d\u0026rdquo;, represents the file type. The characters following that represent the permission set for the user, group and others. The first set of 3 characters after the file type is for the user/owner of the file or directory. The next set is for the group and the last set is for \u0026ldquo;others\u0026rdquo; or everyone else. Each set will have 3 characters, one for read, write and execute permission. If a particular permission is enabled, the respective letter will be shown, if it is disabled or not allowed then a dash, \u0026ldquo;-\u0026rdquo;, will be present instead. In the example above, you can see that the write permission is not allowed for the group and \u0026ldquo;others\u0026rdquo;, where the owner has all 3 permissions allowed.\nTo recap these options, let\u0026rsquo;s go over each permission type.\nr\nr represents the read permission. If it\u0026rsquo;s enabled you will see an \u0026ldquo;r\u0026rdquo;, otherwise, it will be a \u0026ldquo;-\u0026rdquo; for not enabled. w\nw represents the write permission. If it\u0026rsquo;s enabled you will see a \u0026ldquo;w\u0026rdquo;, otherwise, it will be a \u0026ldquo;-\u0026rdquo; for not enabled. x\nx represents the execute permission. If it\u0026rsquo;s enabled you will see an \u0026ldquo;x\u0026rdquo;, otherwise, it will be a \u0026ldquo;-\u0026rdquo; for not enabled. Now we can move on to chmod and the chmod syntax to be used in Linux.\nchmod Syntax chmod [options] mode file The syntax for the chmod command can look quite different if you use a symbolic/text (r,w,x) and (u,g,o,a) or the numeric method such as 777 or 755 for example. Both are valid and will work in the same way, it is very much about user preference and which one you can remember. We will cover both here so you can decide which chmod syntax would like to use.\nchmod Symbolic Mode Syntax The first method of using the chmod command is to use the symbolic mode, where we use letters for the user, group etc. and also letters for the permissions such as r, w, and x. In the example below, we are giving read, write and execute permissions to the owner. Read and execute permissions to the group and read permission to everyone else.\nchmod u=rwx,g=rx,o=r /path/to/test/file The above command combined user, group and others into one line. You can set these seperately as well. Another example of how to use the chmod command with symbolic mode is to use the + to add and the - to remove permissions. In the following example, we add write permission to the group and execute permission to everyone else.\nchmod g+w /path/to/test/file chmod o+x /path/to/test/file -u\nThis option stands for \u0026ldquo;user\u0026rdquo;. With this option, you can change the permissions for the owner of the file. -g\nThis option stands for \u0026ldquo;group\u0026rdquo;. With this option, you can change the permissions -o\nThis option stands for \u0026ldquo;others\u0026rdquo;. With this option, you can change the permissions for all other users. -a\nThis option stands for \u0026ldquo;all\u0026rdquo;. With this option, you can change the permissions for all users. chmod Numeric Mode Syntax As I mentioned earlier, we can use chmod with numeric values representing user, groups and others. We will also use number to represent the individual permissions instead of the characters r, w, and x.\nLet\u0026rsquo;s look at an example for better understanding. The following chmod command gives the owner full permission to read, write and execute. The group receives read and execute permissions, while everyone else only receives read permission.\nchmod 754 /path/to/test/file But where do these numbers come from and how does chmod translate them to permissions? Let\u0026rsquo;s take a look.\nExecute has a value of 1. So one is equivelent to an x in the symbolic mode.\nWrite has a value of 2. Two is equivelent to a w.\nRead has a value of 4. Four is equivelent to an r.\nIn our example, we gave full read, write and execute permission to our user/owner of the file. If we add 1, 2 and 4 together we get 7. In numeric mode we use 3 numbers, the first is for the user/owner, second for the group and last for all others. So in our example, we gave the user a 7, representing full permission. We made the same caclulations for the group and all others in the example.\nSome very common chmod syntax you will see are 777 and 755. Let\u0026rsquo;s take a look at those.\nchmod 777 Chmod 777 will apply full read, write and execute permissions to everyone. This is a dangerous permission set, as everyone has full control of the file. Be careful with this option.\nchmod 755 Chmod 755 will apply full permission to the user/owner while giving the group and everyone else read and execute permission. This is much safer that 777, since only the owner would be able to modify or delete the file.\nchmod 400 Chmod 400 gives only the user/owner read permission, everyone else is completely restricted. This option is fairly common when protecting an SSH private key. Once the file is created, it can be locked down using chmod 400 for better protection.\nThere is pretty cool chmod calculator that exists to help you decide what to use if you have trouble, be sure to check that out.\nchmod Recursive Use One last thing I would like to mention is using chmod recursively. All of our examples have been used for one file or directory. Chmod is much more powerful, as you can apply file or directory permissions recursively so that it changes for all files or folders within the directory that you provide. We do so using the -R option. Let\u0026rsquo;s look at an example of using chmod recursively. Imagine we have a folder called test and we want to apply the same permissions to that folder and everying inside of it. We could use the following.\nchmod -R 755 /test Conclusion We have covered the basic chmod syntax here and the many ways you can use it on your Linux machine. Remember, chmod is powerful, especially when used in combination with the sudo command. Be sure you are telling the machine to do what you really want it to do, otherwise you can really do some damage by changing the wrong permissions. I would suggest practicing on a virtual machine before making changes on a real machine if you are unsure.\n","permalink":"http://localhost:1313/chmod-syntax-in-linux/","summary":"If you are a Linux user, then you have probably heard of chmod. But what is it, and how can you use it? Being a Linux user you also know how important the syntax of commands is, so we will discuss the proper chmod syntax that you should use. In this blog post, we will discuss the basics of chmod and show you how to use it in a few simple steps.","title":"chmod Syntax in Linux Explained"},{"content":"\rWhat is the Tail Command? Linux has a built-in command called tail that can be used to view the last few lines of any file. Tail stands for “tail’ or “finalize” and it is used to show the last few lines of a file or stream. There are several situations when you might want to use tail. For example, you might use it while reading logs from another system, as an archive viewer - which shows the latest part of files - or even as a way of keeping track of changes made in your code by using commit logs. In this article, we will explain everything you need to know about tail command in Linux.\nCommon Tail Command Options Tail - Default Action Simply running to tail command with a filename and no other options will display the last 10 lines of the file in the terminal window. The test file has 15 lines in it, as you can see, only the last 10 lines are printed on the screen.\ntail filename Tail -n Displaying a Specific Number of Lines Maybe you want to run the tail command to get something other than the default 10 lines. This is exactly what the -n option is for. You can specify the exact number of lines that you want tail to output in the terminal. In the example below, we request 15 lines which is the entire document in this case.\ntail -n 15 filename Tail -f Track or Watch for Changes to a File This is probably one of the most useful functions of the tail command in Linux. Using the -f option allows us to monitor a file for any new lines added. This is sometimes referred to as the \u0026ldquo;follow\u0026rdquo; command. Imagine you want to monitor a log file, using the -f option with tail can serve this purpose. In the first screenshot below, we see that we are monitoring the tailTest.txt file. We also have the file open in nano, prepared to add a new line as an example.\ntail -f filename Now we will add \u0026ldquo;Line 16\u0026rdquo; to the file. The tail window that is running the -f option should automatically update the output to show the new line added. This happens because using tail -f creates a live monitor on the file.\nAs we can see, tail picked up the change of us adding Line 16 to the file. You can continue monitoring for changes to the file. To end the monitoring in tails, you can press Ctrl+C in the terminal window.\nNext Step With the Tail Command The tail command in Linux can be combined with other commands using the pipe |. Piping commands together can combine functionality and make tasks easier and more efficient for a Linux administrator. You can use the ls command for directory listings and pipe the output into the tail command. This will show a limited number of lines from the ls command output for instance.\nls -ltr | tail -n 3 Get creative with the tail command. What other commands would be useful to pipe with tail?\nWrapup Tail is a useful command in Linux that can be used to see the last few lines of a file before the file itself is finished. You can use the tail command in several situations, such as reading logs from another system, watching an archive, or even writing commit logs for your code. We hope you enjoyed reading about tail command in Linux. If you want to learn more about Linux, check out our other articles on various topics. From tips and tricks to command line tricks and everything in between, we will make sure to cover them all.\n","permalink":"http://localhost:1313/tail-command-in-linux/","summary":"What is the Tail Command? Linux has a built-in command called tail that can be used to view the last few lines of any file. Tail stands for “tail’ or “finalize” and it is used to show the last few lines of a file or stream. There are several situations when you might want to use tail. For example, you might use it while reading logs from another system, as an archive viewer - which shows the latest part of files - or even as a way of keeping track of changes made in your code by using commit logs.","title":"Using the Tail Command in Linux"},{"content":"\rHow to install Node JS on Linux\nIf you are a Javascript developer and you use Linux, how to install Node.JS is probably a question that you have. Fortunately for you, it is actually easy to install node js on Linux. We already have a guide that explains how to install NodeJS on Manjaro Linux so today we will be explaining how to install Node.JS on Ubuntu and other Debian-based Linux distributions.\nInstall Node Version Manager The easiest way to install Node.JS on Linux and also to manage it is by using Node Version Manager, NVM. So, we will first install NVM on Ubuntu because this will provide an easy way to install any version of Node.JS on Ubuntu without any additional work from us.\nFirst, you will need to open a terminal window on your Linux desktop. Now, run the following command in the terminal. This single command will download the Node Version Manager install script and execute it as well.\ncurl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.39.1/install.sh | bash After the installation of NVM is complete, you can try typing the following into the terminal to verify the install completed. If the command does not work, you may need to close the terminal window and open a new one to refresh the session.\nnvm Install Node.JS on Linux Once you have confirmed that you have NVM installed, we can use it to install Node JS.\nMost users will want to install the long-term support version, also known as LTS. To use NVM to install the LTS version we use the following command in the terminal.\nnvm install --lts If you want to install a specific version of NodeJS, you can use the following command, replace the version number with the version you want to install.\nnvm install 18.4.0 Using NVM, you can install multiple versions of Node.JS. When you have multiple versions installed, you can switch between them using NVM. To tell NVM to use version 16.18.0 we run the following command.\nnvm use 16.18.0 There are other options that can be used with NVM as well, I have listed some of the more common commands here.\n# Directly run a node app from nvm nvm run 6.10.3 app.js nvm exec 4.8.3 node app.js # Install the latest available version nvm install node nvm use node # Uninstall a specific version nvm uinstall 16.18.0 Verify NodeJS is Installed Now that we have used NVM to install Node JS, we should verify it was installed. Using the Linux terminal run the following command which should return the version is installed.\nnode -v The output in the terminal should look similar to the screenshot below. If you get an error, try closing the terminal window and opening a new one.\nCongratulations, you now have Node.JS installed using NVM on Ubuntu Linux! You\u0026rsquo;re ready to get coding!\n","permalink":"http://localhost:1313/linux-how-to-install-node-js/","summary":"How to install Node JS on Linux\nIf you are a Javascript developer and you use Linux, how to install Node.JS is probably a question that you have. Fortunately for you, it is actually easy to install node js on Linux. We already have a guide that explains how to install NodeJS on Manjaro Linux so today we will be explaining how to install Node.JS on Ubuntu and other Debian-based Linux distributions.","title":"How to Install Node.JS on Linux using NVM- 2023 Guide"},{"content":"The browser wars are still real, Chrome and Firefox fanboys stand aside. I actually prefer Edge, as it\u0026rsquo;s built on Chromium and performs fairly well, and it includes many features like sleeping tabs and fast startup. It also easily syncs my favorites and extensions which is a nice touch. There is something that seems wrong about installing a Microsoft product on Linux, but I already use VS Code, and to be honest, who cares what other people think? I\u0026rsquo;m installing Edge and if you want to as well, then follow along with me, it\u0026rsquo;s not too difficult.\nEnable AUR The first thing we need to do to make the installation simple is to enable the AUR repository if it\u0026rsquo;s not already enabled. AUR is the community-maintained repository that we can enable to gain access to more software, like Edge for example. It\u0026rsquo;s easy to enable, don\u0026rsquo;t worry. First, we need to launch Add/Remove Software.\nOnce we have Add/Remove Software open, we want to click the three dots at the top right, then choose preferences.\nIn the preferences screen, we want to select the Third Party tab at the top, then enable AUR Support and also enable Check for Updates.\nThat\u0026rsquo;s all that is needed for enabled AUR, so now we can proceed with installing Edge.\nInstalling Edge Back in the Add/Remove Software, you can close out of the preferences screen, then click the search icon at the top left of the window. Type edge into the search box and press enter. Then on the left select AUR so you get results from the AUR repository.\nChoose the option for microsoft-edge-stabe-bin and on the next page click on build. After clicking build, an apply button will appear at the bottom right of the window. Click apply to process the installation of Edge on our Manjaro machine. You may see an additional popup after clicking apply, this is telling you any dependencies that will be installed, click apply at the top right of this window to continue.\nRunning Microsoft Edge on Manjaro Once this completes, you should now have Microsoft Edge installed on your Manjaro Linux machine. You can find it in the applications menu under Internet. You can also launch it from a terminal by running the command microsoft-edge-stable.\n","permalink":"http://localhost:1313/how-to-install-edge-on-manjaro/","summary":"The browser wars are still real, Chrome and Firefox fanboys stand aside. I actually prefer Edge, as it\u0026rsquo;s built on Chromium and performs fairly well, and it includes many features like sleeping tabs and fast startup. It also easily syncs my favorites and extensions which is a nice touch. There is something that seems wrong about installing a Microsoft product on Linux, but I already use VS Code, and to be honest, who cares what other people think?","title":"How to Install Edge on Manjaro"},{"content":"It\u0026rsquo;s important to have a VPN connection to protect your machine, privacy, and your information these days. Yes, even on Linux. I am an ExpressVPN customer and was happy to find that installing ExpressVPN on Linux is simple.\nWhy use ExpressVPN? The most important thing when choosing a VPN provider is privacy and security. For me, a \u0026ldquo;no logging\u0026rdquo; policy is a must and so are third-party audits of the claims. In late 2022, ExpressVPN had third-party auditors test their no-logging claims and their security, you can review the reports yourself here. Ultimately, it\u0026rsquo;s up to you who you choose to trust, so do your research on available VPN providers.\nDoes ExpressVPN Work on Linux? Yes, ExpressVPN works on all distributions of Linux, including Ubuntu, Fedora, Linux Mint, Manjaro, etc. ExpressVPN is easy to install and set up on Linux, both in a command line and GUI format.\nIs There a GUI ExpressVPN App for Linux? While there isn\u0026rsquo;t an official GUI app for Linux, there are multiple opensource apps that have been created. We will discuss how to install these in this article in case you prefer to use a GUI.\nDownloading the Linux ExpressVPN Installer Head over to the ExpressVPN download page and log in to your account to find the installer for your distribution of Linux. Under the \u0026ldquo;set up your devices\u0026rdquo; section, choose \u0026ldquo;Linux\u0026rdquo;.\nOn the Linux download page, you will find a list of available downloads. Select the one for your distribution of Linux and download it.\nInstalling ExpressVPN on Linux Now that you have the installer downloaded, we can proceed to install the package. Below is a breakdown of how to complete the ExpressVPN install for Ubuntu, Fedora, and Arch distros such as Manjaro and EndeavourOS. Remember, for other Debian/Ubuntu variants, just choose the Ubuntu install and use the Ubuntu instructions throughout the rest of this article.\nUbuntu Install If you are on Ubuntu or other variants like Linux Mint or PopOS, then you have a \u0026ldquo;.deb\u0026rdquo; file, and the easiest way to install this file is with dpkg. In your terminal run the following command from the directory where you downloaded the ExpressVPN \u0026ldquo;.deb\u0026rdquo; file to.\nsudo dpkg -i expressvpn_3.39.0.8-1_amd64.deb It is now installed, you can skip down to the section on activating ExpressVPN or installing the optional GUI app if you prefer.\nFedora Install On Fedora, you will download the \u0026ldquo;.rpm\u0026rdquo; file from the ExpressVPN website in the previous section. To start the installation, right-click on the file and choose the option to \u0026ldquo;Open with Software Install\u0026rdquo;. From there, choose install.\nAfter the installation completes, you can proceed to the next section to install the optional GUI app or the section for the command line activation of ExpressVPN.\nArch, Manjaro, and EveavourOS Install Open up a terminal and navigate to where you downloaded the installer, then run the following command, make sure you replace the filename with your file name for the package.\nsudo pacman -U expressvpn-3.32.0.5-1-x86_64.pkg.tar.xz You can now proceed to the section of this article on installing the optional GUI app or the section on activating ExpressVPN.\nExpressVPN Linux GUI App If you prefer to use a GUI form of the ExpressVPN app on Linux, you can. You will still need to install the base ExpressVPN install that we set up in the previous section. The install process for the GUI app will be different based on the Linux distro, so we have broken down the steps for each below.\nGUI Install for Ubuntu To install the GUI ExpressVPN app on Ubuntu, we need to clone a Git repo so you will need to have the \u0026ldquo;git\u0026rdquo; package installed. You can do this with the command below.\nsudo apt install git Next, we need to clone the Git repo to our \u0026ldquo;/opt\u0026rdquo; directory.\ncd /opt sudo git clone https://gitlab.com/vojko.pribudic/expressvpn-gui-gtk.git Once you have cloned the Git repo, we need to copy the \u0026ldquo;expressvpn-gui-gtk\u0026rdquo; file to the \u0026ldquo;/usr/bin\u0026rdquo; directory.\ncd expressvpn-gui-gtk sudo cp expressvpn-gui-gtk /usr/bin Before we proceed, you need to find out if you where your python executable is, you can do this by using the \u0026ldquo;which\u0026rdquo; command. Try running which for both \u0026ldquo;python\u0026rdquo; and \u0026ldquo;python3\u0026rdquo;. We will use this information to edit the launcher that will be in the app menu.\nAs you can see, I have Python3, found under \u0026ldquo;/usr/bin/python3\u0026rdquo;. You may have something different, the important part is whether it is Python3 of just Python.\nNow we need to edit the \u0026ldquo;.desktop\u0026rdquo; file to ensure the line that executes the script is correct for your machine. Using nano and sudo, open the \u0026ldquo;.desktop\u0026rdquo; file for editing. Find the line that starts with \u0026ldquo;Exec\u0026rdquo;, edit the python command if needed. In my case, I updated it to Python3.\nsudo nano expressvpn-gui-gtk.desktop After making the necessary changes, we need to copy this file to \u0026ldquo;/usr/share/applications\u0026rdquo; so that it will show up in your app launcher.\nsudo cp expressvpn-gui-gtk.desktop /usr/share/applications Once you have done this, open the app launcher in Ubuntu and check for ExpressVPN. If you don\u0026rsquo;t see it listed, make sure you copied the file properly and also check that you updated the Python execution line in the \u0026ldquo;.desktop\u0026rdquo; file to match your system.\nBecause of the way this app is written, it needs to write a \u0026ldquo;settings.dat\u0026rdquo; file to the /opt/expressvpn-gui-gtk foler. For this reason, and for the app to work, you need to grant extra permissions to this folder, at least for the first time you run it.\nsudo chmod 777 /opt/expressvpn-gui-gtk/ After you have successfully run this program and confirmed it is working, you can run this command again with \u0026ldquo;755\u0026rdquo; to reset the permissions.\nBefore you launch the ExpressVPN GUI app for the first time, we need to install one last dependency using APT.\nsudo apt-get install gir1.2-appindicator3-0.1 You can now run the app from the app launcher menu. You will be asked to activate ExpressVPN if you haven\u0026rsquo;t already done that through the console app. Then you will see a tray icon by your clock to interact with the app. Don\u0026rsquo;t forget to change the folder permissions back to 755 if you had changed that earlier.\nGUI Install for Fedora Installing the GUI app on Fedora is similar to Ubuntu. You should already have Git installed on Fedora but if you don\u0026rsquo;t, you can install it using dnf from that command line.\nsudo dnf install git Next, we need to clone the Git repo to our \u0026ldquo;/opt\u0026rdquo; directory.\ncd /opt sudo git clone https://gitlab.com/vojko.pribudic/expressvpn-gui-gtk.git Once you have cloned the Git repo, we need to copy the \u0026ldquo;expressvpn-gui-gtk\u0026rdquo; file to the \u0026ldquo;/usr/bin\u0026rdquo; directory.\ncd expressvpn-gui-gtk sudo cp expressvpn-gui-gtk /usr/bin Before we proceed, you need to find out if you where your python executable is, you can do this by using the \u0026ldquo;which\u0026rdquo; command. Try running which for both \u0026ldquo;python\u0026rdquo; and \u0026ldquo;python3\u0026rdquo;. We will use this information to edit the launcher that will be in the app menu.\nOn my Fedora system, I have both, each points to Python version 3 though. You may have something different, the important part is whether the name is Python3 or just Python.\nIf you only have \u0026ldquo;Python3\u0026rdquo;, you need to edit the \u0026ldquo;.desktop\u0026rdquo; file to ensure the line that executes the script is correct for your machine. Using nano and sudo, open the \u0026ldquo;.desktop\u0026rdquo; file for editing. Find the line that starts with \u0026ldquo;Exec\u0026rdquo;, edit the python command if needed.\nsudo nano expressvpn-gui-gtk.desktop After making the necessary changes, we need to copy this file to \u0026ldquo;/usr/share/applications\u0026rdquo; so that it will show up in your app launcher.\nsudo cp expressvpn-gui-gtk.desktop /usr/share/applications Once you have done this, open the Fedora app launcher menu and check for ExpressVPN. If you don\u0026rsquo;t see it listed, make sure you copied the file properly and also check that you updated the Python execution line in the \u0026ldquo;.desktop\u0026rdquo; file to match your system.\nBecause of the way this app is written, it needs to write a \u0026ldquo;settings.dat\u0026rdquo; file to the /opt/expressvpn-gui-gtk foler. For this reason, and for the app to work, you need to grant extra permissions to this folder, at least for the first time you run it.\nsudo chmod 777 /opt/expressvpn-gui-gtk/ After you have successfully run this program and confirmed it is working, you can run this command again with \u0026ldquo;755\u0026rdquo; to reset the permissions.\nBefore you launch the ExpressVPN GUI app for the first time, we need to install one last dependency using APT.\nsudo dnf install libappindicator-gtk3 You can now run the app from the app launcher menu. You will be asked to activate ExpressVPN if you haven\u0026rsquo;t already done that through the console app. Then you will see a tray icon by your clock to interact with the app. Don\u0026rsquo;t forget to change the folder permissions back to 755 if you had changed that earlier.\nGUI Install for Arch, Manjaro, and EndeavourOS To install the GUI helper application, you will need to enable the AUR repository and then install the package expressvpn-gui. The GUI app will allow you to activate your ExpressVPN subscription along with connecting and disconnecting. It also includes a helpful tray icon, which shows the connection status as well.\nExpressVPN Browser Extension If you don\u0026rsquo;t want to install the GUI app on your Linux machine, you can use the browser extension as well. The official ExpressVPN browser extension is available for most major browsers like Firefox, Chrome and Edge. You can get this from the browser extension store or from the ExpressVPN download page as well. The extension will allow you to manage your ExpressVPN client like you would with the desktop GUI application.\nUsing ExpressVPN on Linux from the Command Line If you don\u0026rsquo;t want to use the GUI app, I understand. The official ExpressVPN software offers many command line options. You\u0026rsquo;ll start by activating the client using your activation code.\nActivate ExpressVPN on Linux Run the following command to activate the app, you will be asked for you code that you get from your \u0026ldquo;My Account\u0026rdquo; page on the ExpressVPN website.\nexpressvpn activate Now we can connect. If you want to use the smart location, just run the following command to connect.\nConnect to ExpressVPN on Linux expressvpn connect Keep in mind that by default, if the VPN connection drops it will kill internet connectivity thanks to the Network Lock feature provided by ExpressVPN. You can turn this off by disconnecting from VPN, running the command to disable Network Lock, then connecting to VPN again.\nDisconnect from VPN and other Commands expressvpn disconnect expressvpn preferences set network_lock off expressvpn connect If you want to connect to a specific location offered by ExpressVPN, you can run the following command to first get a list of locations and then provide that location to the expressvpn connect command as follows. In the example, we are connecting to Chicago which has an alias of \u0026ldquo;such\u0026rdquo;.\nexpressvpn list all expressvpn connect usch Lastly, to check the status of your ExpressVPN connection you can run the following command, which will show which location you are connected to.\nexpressvpn status There are many other options and configurations available from ExpressVPN on Manjaro and Linux, to see a full list, check out the Linux Express VPN documentation.\n","permalink":"http://localhost:1313/install-expressvpn-on-manjaro-linux/","summary":"It\u0026rsquo;s important to have a VPN connection to protect your machine, privacy, and your information these days. Yes, even on Linux. I am an ExpressVPN customer and was happy to find that installing ExpressVPN on Linux is simple.\nWhy use ExpressVPN? The most important thing when choosing a VPN provider is privacy and security. For me, a \u0026ldquo;no logging\u0026rdquo; policy is a must and so are third-party audits of the claims.","title":"Install ExpressVPN on Linux"},{"content":"If you are a developer or student, you may be programming in Java and using VS Code to do your coding. Setting up your environment can be a confusing but important task and today we will cover the steps to get you up and running with Java in VS Code.\nFirst, make sure you have VS Code installed on Manjaro, if you need help with that you can follow my guide on doing so.\nNext, we need to install Java on Manjaro, which is simple thanks to the pacman package manager. Depending on the version of Java you wish to install there will be a slight variation to the install command. I\u0026rsquo;ve provided a few examples below to get you started.\nInstalling Java on Manjaro Latest OpenJDK The following command will install the latest version of OpenJDK and JRE available in the package manager, currently version 18.\nsudo pacman -S jre-openjdk-headless jre-openjdk jdk-openjdk openjdk-doc openjdk-src OpenJDK 8 This command will install the older, version 8 OpenJDK in case you need this for your development project.\nsudo pacman -S jre8-openjdk-headless jre8-openjdk jdk8-openjdk openjdk8-doc openjdk8-src Once you have complete the install, you can confirm by running the command \u0026ldquo;java -version\u0026rdquo;, without the quotes, which should print out the currently installed version of java.\nSetup VS Code for Java Development The easiest way to get rolling with VS Code and Java in Manjaro is to launch VS Code and create a HelloWorld.java file. VS Code will detect that you are developing in the Java language and will offer to install necessary extensions for you. This box will display at the bottom right of your VS Code window, like in the following screenshot. You can proceed by clicking Install.\nVS Code Java Extensions Setup\nAt the time of writing 6 extensions are installed by VS Code that will help you with your Java development.\nLanguage Support for Java (Developer: Redhat)\nDebugger for Java (Developer: Microsoft)\nTest Runner for Java (Developer: Microsoft)\nMaven for Java (Developer: Microsoft)\nProject Manager for Java (Developer: Microsoft)\nItelliCode (Developer: Microsoft)\nOnce the extensions have finished installing, you can go back to your HelloWorld.java file to write the code and test that everything is functioning. Go ahead and paste the following code into the editor if needed.\nclass HelloWorld { public static void main(String[] args) { System.out.println(\u0026#34;Hello, World!\u0026#34;); } } Once you have your code inserted, you will find a Run button along the top bar at the right of the screen. You can press this button to launch your code which should result in Hello World being printed in the terminal window at the bottom of VS Code.\nAwesome, you now have your environment setup to develop in Java using VS Code in Manjaro Linux. Feel free to explore other extensions that can help with coding as well. If you have any recommended extensions, let us know in the comments!\n","permalink":"http://localhost:1313/install-java-for-vs-code-on-manjaro-linux/","summary":"If you are a developer or student, you may be programming in Java and using VS Code to do your coding. Setting up your environment can be a confusing but important task and today we will cover the steps to get you up and running with Java in VS Code.\nFirst, make sure you have VS Code installed on Manjaro, if you need help with that you can follow my guide on doing so.","title":"Install Java for VS Code on Manjaro Linux"},{"content":"Many developers today choose Microsoft Visual Studio Code as their preferred text editor and IDE. VSCode is a multi-platform tool that is powerful in terms of editing and extended editing capabilities. On top of the already feature rich client, there are many official and community based extensions that expand it\u0026rsquo;s capabilities. This guide will explain how to install VSCode on Manjaro Linux.\nhttps://www.youtube.com/watch?v=QppKSrsuPZ8\nInstall VSCode Flatpak Installing VSCode as a Flatpak is an excellent option for Manjaro Linux users. It\u0026rsquo;s just as easy as the Snap method and the performance and manageability is even better. This is the method I\u0026rsquo;ve used to install VSCode on my Manjaro PC, so I recommend you try it out. You will need to enable Flatpak support on Manjaro first, if you haven\u0026rsquo;t already. If you need help, we already have a guide on setting up Flatpak on Manjaro.\nOnce you have Flatpak support setup, open up your terminal and run the following command to install VSCode.\nflatpak install flathub com.visualstudio.code Running the VSCode Flatpak In order to run VSCode, you can either find it in your app launcher or run the following command in the terminal.\nflatpak run com.visualstudio.code Install VSCode Through Snap I don\u0026rsquo;t like snap! Ok, you can install VSCode from the AUR as well.\nBy far the easiest way to install VS Code on Manjaro Linux is to use the Snap version. Snap versions of apps are bundled with everything they need, including dependencies, that an application needs to run on essentially any distribution of Linux. These apps also run in a sandbox to be more secure. For VS Code, in order to avoid file access issues, we must install with the \u0026ndash;classic flag to allow access to files across the filesystem and not just in the sandbox environment.\nFirst we need to check that you have snap installed, at a shell prompt, run the command \u0026ldquo;snap version\u0026rdquo; without the quotes. If you get a response with the snap version, you\u0026rsquo;re good to move on. If snap isn\u0026rsquo;t installed, run the following commands to complete that installation before proceeding.\nInstall Snap sudo pacman -S snapd sudo systemctl enable snapd sudo systemctl start snap\u0026lt;/code\u0026gt; Now you should have Snap installed and you can confirm with the \u0026ldquo;snap version\u0026rdquo; version command. You may need to log out and back in if it\u0026rsquo;s still not working.\nOnce everything is good with your Snap install, we need to create a symbolic link from /snap to /var/lib/snapd/snap. This is required since we are using the \u0026ndash;classic flag during the install of VS Code. Run the following command to setup the symbolic link.\nsudo ln -s /var/lib/snapd/snap /snap Now everything is setup and we can finally install VS Code on our Manjaro Linux machine. Run the following command to complete that install.\nInstalling VS Code from Snap sudo snap install code --classic Install VSCode from AUR Before installing apps from the AUR, you should understand the risks involved as well as why sometimes the alternatives like Flatpak are better. Read through our article that discusses the concerns with the AUR.\nInstalling VS Code from the AUR is pretty simple, go ahead and launch the package manager. Enable the AUR if you haven\u0026rsquo;t already, this can be done through the preference menu of the package manager. Choose Third-Party at the top and then enable AUR support.\nNow that you have the AUR enabled. Go back and use the search function in the package manager to search for \u0026ldquo;visual-studio-code-bin\u0026rdquo;, which should return a result for you.\nGo ahead and select this option to install VS Code using the AUR on Manjaro. Once the installation is completed, you\u0026rsquo;re ready to go.\nHow to Run VSCode on Manjaro Once the installation is finished, depending on your exact environment, you may see Visual Studio Code in your applications menu. Also, you can launch VS Code from a shell prompt by running the command \u0026ldquo;code\u0026rdquo;, without the quotes. You can also run the command \u0026ldquo;code .\u0026rdquo;, to launch VS Code using the current directory as the working directory which can be useful.\nThat\u0026rsquo;s it, now you have VS Code installed in Manjaro Linux and the app will get updates through the snapd service so you always have the latest version available.\n","permalink":"http://localhost:1313/install-vs-code-on-manjaro-linux/","summary":"Many developers today choose Microsoft Visual Studio Code as their preferred text editor and IDE. VSCode is a multi-platform tool that is powerful in terms of editing and extended editing capabilities. On top of the already feature rich client, there are many official and community based extensions that expand it\u0026rsquo;s capabilities. This guide will explain how to install VSCode on Manjaro Linux.\nhttps://www.youtube.com/watch?v=QppKSrsuPZ8\nInstall VSCode Flatpak Installing VSCode as a Flatpak is an excellent option for Manjaro Linux users.","title":"Install VSCode on Manjaro Linux"},{"content":"Recently I set up Proxmox on an old PC so that I could create a home lab. One of the VMs is for development that I would need to access remotely through some sort of remote viewing utility. The VM is running Manjaro Linux and while I could use TeamViewer to accomplish remote abilities, I\u0026rsquo;ve found that it doesn\u0026rsquo;t always provide the best performance so I wanted to explore other options. One of the more common options for Manjaro is TigerVNC so that is the remote access tool I decided to go with for my setup. This quick guide will help you install TigerVNC on Manjaro Linux so that you can remotely connect to and view your desktop, just as if you are sitting at the machine with a monitor, keyboard, and mouse directly connected to it.\nWhile this guide is targeted at Manjaro, you can likely adapt it to work for other Linux distributions such as Ubuntu by swapping out commands like pacman for apt install for example.\nRDP Instead of VNC Instead of VNC, you may want to consider trying out RDP. RDP has been known as a Windows remote desktop technology, but open-source Linux-compatible versions exist. One of these is XRDP, in many cases, it performs better than VNC.\nCheck out our guide on installing XRDP on Linux if you\u0026rsquo;re interested in trying it out.\nHow to Install TigerVNC Install TigerVNC sudo pacman -S tigervnc Set a Password for Remote Connections vncpasswd Designate user and virtual desktop assignments sudo nano /etc/tigervnc/vncserver.users Inside this document, you will assign a virtual desktop to specific users. You do this using the format of :1=username\nThe colon at the beginning of the line is required, the number following the colon represents the virtual desktop which also represents the port that will be used for remote connections. For example, :1 is port 5901, :2 is pot 5902.\nSetup User Config In the user home directory, we will create the config file to tell TigerVNC what desktop environment to use and the resolution.\nnano ~/.vnc/config Add or edit the following lines that are in the file. Replace xfce with the desktop window manager that you use.\nsession=xfce geometry=1920x1080 Create a Service to Run TigerVNC on System Startup sudo nano /etc/systemd/system/tigervnc@:1.service Replace the number 1 in the command above with the desktop you chose previously.\nPaste the text below into the file, and replace testuser with the user account name that you are configuring this for.\n[Unit] Description=Remote desktop service After=syslog.target network.target [Service] Type=simple User=testuser PAMName=login PIDFile=/home/testuser/.vnc/%H%i.pid ExecStart=/usr/bin/vncserver :1 ExecStop=/usr/bin/vncserver -kill %i [Install] WantedBy=multi-user.target Enable the Service sudo systemctl enable tigervnc@\\:1.service Don\u0026rsquo;t forget to change the number 1 to whatever you used previously.\nTake note of the IP address for your Manjaro install. You can check this in many ways, such as the ifconfig command from a shell prompt.\nRestart Manjaro\nConnecting to VNC on Manjaro On the machine you will be connecting to the VNC instance on Manjaro from, such as your Windows device, you will need to download and install a VNC client such as TightVNC which is what I will be using in this example.\nOnce you have the client downloaded and installed, it is time to connect. You will be using the IP address you collected earlier and the port such as 5901, depending on what virtual desktop you chose in the earlier steps.\nYou should now be remotely connected to your Manjaro Linux installation remotely using TigerVNC. If you were unable to connect, verify the IP address and port. If you are still having trouble connecting, you may want to test disabling the firewall in Manjaro if you had it set to active.\n","permalink":"http://localhost:1313/install-vnc-on-manjaro-for-remote-access/","summary":"Recently I set up Proxmox on an old PC so that I could create a home lab. One of the VMs is for development that I would need to access remotely through some sort of remote viewing utility. The VM is running Manjaro Linux and while I could use TeamViewer to accomplish remote abilities, I\u0026rsquo;ve found that it doesn\u0026rsquo;t always provide the best performance so I wanted to explore other options.","title":"Install VNC on Manjaro for Remote Access"},{"content":"If you plan on getting into Javascript development and you use Manjaro, you will likely run across the need to install NodeJS on Manjaro Linux. It\u0026rsquo;s quite simple to do on Manjaro, especially when using NVM - Node Version Manager. NVM allows you to easily install, update and switch between different releases of NodeJS, such as LTS, which is what we will be installing today. Typically you would want to develop on LTS for better support unless you really need the newest features not available in LTS, or you are simply testing some new functionality.\nReady to start coding using NodeJS on Manjaro? Check out our guide on installing VScode on Manjaro Linux If you\u0026rsquo;re not the reading type, check out our simple video guide on how to install NodeJS on Manjaro Linux on the credibleDEV YouTube channel.\nhttps://youtu.be/f1Yqrg8gyKY\nInstall NVM Manjaro Linux In order to install NodeJS on Manjaro, we will first install the Node Version Manager, NVM, by running the following command in a terminal.\nsudo pacman -S nvm Next, run the following two commands to complete the setup of NVM on Manjaro. If you are using something other than ZSH, you will need to edit this line to match your shell type, such as bashrc.\nInstall NVM on EndeavourOS On EndeavourOS, you may not find NVM using pacman, instead you can do one of the following.\nIf you have yay or some other AUR helper you can try this.\nyay -S nvm Now close your terminal and re-open it.\nDidn\u0026rsquo;t work for you? Try following the same instructions used for Ubuntu and other Linux distros below. You may need to close your terminal and re-open it after following those steps as well.\nInstall NVM for Ubuntu and Other Linux Distributions If you are trying to install the Node Version Manager on another Linux distribution such as Ubuntu or something Debian based, you can run the following command in the terminal to get NVM. You may need to close and open a new terminal after the installation completes.\ncurl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.39.3/install.sh | bash Once the installation is complete, you can close your terminal window and then launch a new one in the case that running the command nvm reports that it is not found. After launching a new terminal the nvm command should be working.\nInstall NodeJS on Manjaro Linux, Ubuntu and Other Linux Distributions Now that we have NVM installed, we can move on the installing NodeJS. These commands will work on Manjaro Linux and other distributions such as Ubuntu as well. As I stated before, we are going to install the latest LTS version, which is done with the following command.\nNVM Command Not Found If you try to run the following command and get \u0026ldquo;nvm command not found\u0026rdquo;. You can fix this error by running one of the following commands, whichever matches the shell that you are running. Most commonly this is bash for example. After running the command, open a new terminal and the \u0026ldquo;nvm\u0026rdquo; command will be working.\necho \u0026#39;source /usr/share/nvm/init-nvm.sh\u0026#39; \u0026gt;\u0026gt; ~/.bashrc echo \u0026#39;source /usr/share/nvm/init-nvm.sh\u0026#39; \u0026gt;\u0026gt; ~/.zshrc Install NodeJS Using NVM nvm install --lts Once the installation is complete, you can verify that node and npm are both installed with the following commands. Which should return the currently installed version of each.\nCheck if NodeJS and NPM are Installed We can check if Node is installed by running the following command which will check the NodeJS version. If the command in successful then it is installed and will report the version to the terminal. Since NPM is included with Node, we will also verify that it is installed as well with the second command.\nnode -v npm -v If you wish to install multiple versions of NodeJS on your Linux system, you can do so by using some of these nvm commands. To find more commands refer to the NVM documentation or by running nvm \u0026ndash;help in your terminal.\nnvm install 19.6.0 - This installs a specific version\nnvm install node - This installs the latest available version (Possibly not an LTS version)\nnvm use \u0026ndash;lts - Tells the system to use the installed LTS version of node\nnvm use 19.6.0 - Tells the system to use this specific version of node\nNPM - Node Package Manager Now that you have NodeJS installed on your Manjaro Linux system, you also have access to the Node Package Manager, known as NPM. Since NPM is included with the installation of NodeJS, there is no need to install NPM separately, you\u0026rsquo;re ready to go. With NPM, you can easily install packages to extend the apps and programs that you write using Javascript. You can read more about how to use NPM on their docs page, but the syntax to install packages from NPM is simple.\nnpm install \u0026#34;package name\u0026#34; Just replace \u0026ldquo;package name\u0026rdquo; with the name of the NPM package that you want to install. You can search the large database of packages using the search bar on the NPM site. Some of my favorite NPM packages are Express and PM2. Express allows you to quickly spin up a NodeJS web server and PM2 allows you to easily manage them.\nNPM Command Not Found If you see this error, it means that either the install failed or the location of NPM is not in your path. The simplest thing to verify this would be to close your terminal, open a new one and try again or reboot. You can also use the \u0026ldquo;which\u0026rdquo; command in the terminal to try and locate the NPM executable to confirm that it is installed. You would type \u0026ldquo;which npm\u0026rdquo; into the terminal, you should then see the location such as, \u0026ldquo;/home/thecd/.nvm/versions/node/v18.14.0/bin/npm\u0026rdquo;. If you don\u0026rsquo;t get a location back, then something went wrong during the NodeJS install.\nUninstall NodeJS To uninstall NodeJS, you can use NVM again, using the uninstall option it provides. In this example, we are uninstalling the LTS version of Node. If you need to uninstall a specific version number, just replace \u0026ldquo;\u0026ndash;lts\u0026rdquo; with the version number, such as \u0026ldquo;v18.14.0\u0026rdquo;.\nnvm uninstall --lts If you have any questions about NodeJS or writing Javascript code, leave a comment down below\n","permalink":"http://localhost:1313/how-to-install-nodejs-on-manjaro-linux/","summary":"If you plan on getting into Javascript development and you use Manjaro, you will likely run across the need to install NodeJS on Manjaro Linux. It\u0026rsquo;s quite simple to do on Manjaro, especially when using NVM - Node Version Manager. NVM allows you to easily install, update and switch between different releases of NodeJS, such as LTS, which is what we will be installing today. Typically you would want to develop on LTS for better support unless you really need the newest features not available in LTS, or you are simply testing some new functionality.","title":"Install NodeJS on Manjaro Linux - 2023 Update"},{"content":"I like many others, use a Linux virtual machine in VirtualBox from my Windows PC to do development work. There are many Linux distributions out there and many choose Ubuntu or some variant of it, I\u0026rsquo;ve chosen Manjaro which is an Arch based Linux. Completing tasks in Manjaro can be a bit different than in Ubuntu and other Debian Linux variants. One of those tasks is sharing a folder from my Windows PC through VirtualBox to my Manjaro Linux virtual machine. It\u0026rsquo;s not difficult, just a slight bit different and I will show you here how to share a windows folder with your Manjaro or Arch based Linux VM in VirtualBox.\nBefore proceeding with the following steps, make sure that you have the VirtualBox Guest Additions installed on your Manjaro or Arch Linux virtual machine. You can install these required tools with the following command.\nsudo pacman -Sy virtualbox-guest-utils Create the Folder in Windows The first step here is to either locate or create the folder you want to share from your Windows OS.\nIn my example here, it will be a folder in my Windows user directory called \u0026ldquo;Projects\u0026rdquo;. C:\\Users\\username\\Projects\nCreate a Folder on Your Manjaro/Arch Linux VM Next, we need to create a folder within the Manjaro VM, where the folder from Windows will appear.\nFor my example, I have created a folder within my Manjaro user account folder called \u0026ldquo;Shared_Projects\u0026rdquo;. cd /home/username/Shared_Projects\nTo create this folder you could use the following command from the Manjaro terminal prompt.\nmkdir ~/Shared_Projects The ~ symbol is used here to represent the currently logged-in user\u0026rsquo;s home folder. You can choose any folder you want however, this is just an example.\nAdd the User Account to the VBOXSF User Group When VirtualBox links the Windows folder to our Manjaro folder, it does so using the vboxsf group, which means that our user account must be a member of this group, otherwise, you will get permission errors. Adding a user to the vboxsf group just takes one command.\nsudo usermod --append --groups vboxsf username Run this command by replacing the username with your Manjaro Linux accounts username and this will make that account a member of the proper group to obtain access to the share folder files.\nSetup the Share Folder in VirtualBox In VirtualBox, we need to configure the folder we are sharing from Windows, along with the folder we are attaching it to in Manjaro. So open up VirtualBox and head to the settings of your virtual machine. In settings, you will find an option for \u0026ldquo;Shared Folders\u0026rdquo;. Click that option then on the right side you will see a folder icon with a plus symbol on it, this allows you to add new share folders. Click that icon to create your new shared folder.\nIn the folder path field, you put the path to the Windows folder you are sharing, it\u0026rsquo;s easier to just browse to the path by using the dropdown.\nFolder Name is filled out automatically, no changes are needed here.\nCheck the Auto-mount box so that your folder is automatically available in Manjaro each time you boot up.\nIn the mount point field, this is where you put the path to the folder you created on Manjaro. We used the users home directory and a folder called Shared_Projects within it. So the path is /home/username/Shared_Projects.\nClick ok to close the box, make sure the folder shows up under \u0026ldquo;Machine Folders\u0026rdquo; and not \u0026ldquo;Transient Folders\u0026rdquo;.\nYou can now power on or restart your Manjaro Linux VM and you will be able to access your newly created shared folder.\n","permalink":"http://localhost:1313/how-to-share-a-folder-from-windows-to-arch-linux-guest-os-in-virtualbox/","summary":"I like many others, use a Linux virtual machine in VirtualBox from my Windows PC to do development work. There are many Linux distributions out there and many choose Ubuntu or some variant of it, I\u0026rsquo;ve chosen Manjaro which is an Arch based Linux. Completing tasks in Manjaro can be a bit different than in Ubuntu and other Debian Linux variants. One of those tasks is sharing a folder from my Windows PC through VirtualBox to my Manjaro Linux virtual machine.","title":"How To Share a Folder From Windows to Arch Linux Guest OS in VirtualBox"},{"content":"\rIf you have been using VMware Horizon Instant Clone VMs for any length of time, it is likely that you have run across the VM status of, \u0026ldquo;Already Used\u0026rdquo;. Typically, fixing the Already Used status is not as straightforward as just removing the VM from the Horizon View Admin page as other issues are.\nFix Already Used Status in VMware Horizon In order to fix machines in this status, you will need to log in and locate the machine in vCenter. Once you have located the problem VM, proceed to power off the machine. Once the VM is powered off in vCenter, you will then need to delete the VM using the \u0026ldquo;Delete from Disk\u0026rdquo; option. You can do this by using the right-click menu on the VM.\nOnce you have completed this work in vCenter, hop back over to the Horizon View admin console page and proceed to remove the VM there as well. Once the VM rebuilds it will no longer have the Already Used error.\nPermanent Fix for Already Used State in VMware Horizon The fix provided above resolves the issue for a VM but does not keep it from occurring again. In order to fully resolve the issue, we must understand what is happening. The usual case for this issue is when a VM is left in a dirty state, caused by users shutting down the VM and not cleanly logging off or something unexpected happens with the VM causing a failure in clean logoff.\nWhen your VM pool in Horizon is configured so that when users log off, the VM is recomposed, failure to cleanly log off or shutting down the VM can break this process of recomposing the VM.\nTo improve your chances of not seeing the Already Used issue again, you could remove the shutdown button from the OS that the VM runs.\nAnother solution involves editing a View LDAP value called pae-DirtyVMPolicy. This is found under OU=Server Groups, DC=vdi, DC=vmware, DC=int. The value is 0 by default which tells Horizon to set the VM as Already Used when the VM did not have a clean logoff. You can alter this value to 1 or 2, 1 will tell Horizon to let the VM be available without a recompose, and 2 will tell Horizon the refresh the dirty VM\u0026rsquo;s.\nYou can also find more information about this issue in this VMware Knowledgebase Article: The View virtual machine is not accessible and the View Administration console shows the virtual machine status as Already Used\n","permalink":"http://localhost:1313/vmware-horizon-vm-already-used-status/","summary":"If you have been using VMware Horizon Instant Clone VMs for any length of time, it is likely that you have run across the VM status of, \u0026ldquo;Already Used\u0026rdquo;. Typically, fixing the Already Used status is not as straightforward as just removing the VM from the Horizon View Admin page as other issues are.\nFix Already Used Status in VMware Horizon In order to fix machines in this status, you will need to log in and locate the machine in vCenter.","title":"VMware Horizon VM Already Used Status"},{"content":"In your VMware Horizon VDI Environment, you can run into a range of different errors. Many of these errors either resolve themselves or can be resolved just by recovering or removing the machine from within the Horizon Administrator console. However, some VMware Horizon errors such as VC_FAULT_FATAL - The name already exists, cannot be resolved in this way.\nHow to Fix the VC_FAULT_FATAL Error Whenever you see this particular error, this means that Horizon is trying to create a new VM but can\u0026rsquo;t because a VM with that name already exists. This can happen for many reasons but most commonly, the VC_FAULT_FATAL - The name already exists error occurs because Horizon can no longer communicate with the VM in vSphere. At some point, it lost sync with the VM and now the communication between Horizon and vSphere for this VM is broken.\nThe simplest way to resolve the VC_FAULT_FATAL - The name already exists error is to power off and remove the VM from the vSphere inventory. Just locate the VM in question within vSphere, make sure it\u0026rsquo;s powered off, then right-click on the machine and choose \u0026ldquo;Remove from Inventory as shown here.\nAfter removing the VM from inventory, you will need to go back to the Horizon Administrator Console, and select and delete the VM there as well. This will resolve the VMware Horizon VC_FAULT_FATAL - The name already exists error message.\n","permalink":"http://localhost:1313/vmware-horizon-vc_fault_fatal-name-already-exists-error/","summary":"In your VMware Horizon VDI Environment, you can run into a range of different errors. Many of these errors either resolve themselves or can be resolved just by recovering or removing the machine from within the Horizon Administrator console. However, some VMware Horizon errors such as VC_FAULT_FATAL - The name already exists, cannot be resolved in this way.\nHow to Fix the VC_FAULT_FATAL Error Whenever you see this particular error, this means that Horizon is trying to create a new VM but can\u0026rsquo;t because a VM with that name already exists.","title":"VMware Horizon VC_FAULT_FATAL - Name Already Exists Error"},{"content":"SCCM Compliance rule evaluation for a new rule can sometimes be slow or maybe you just need to manually evaluate compliance baselines or rules on a machine or group of machines.\nRegardless of your reasoning, the PowerShell script below can help you achieve the goal of manually and remotely kicking off SCCM compliance rule evaluations.\nTo make this reusable in the future, we will create a simple function that we can call along with a hostname to do the dirty work for us.\nfunction Invoke-ForceEvaluation { param ( [Parameter(Mandatory=$true, HelpMessage=\u0026#34;Computer Name\u0026#34;,ValueFromPipeline=$true)] $ComputerName ) $Baselines = Get-WmiObject -ComputerName $ComputerName -Namespace root\\ccm\\dcm -Class SMS_DesiredConfiguration $Baselines | % { ([wmiclass]\u0026#34;\\\\$ComputerName\\root\\ccm\\dcm:SMS_DesiredConfiguration\u0026#34;).TriggerEvaluation($_.Name, $_.Version) } } foreach($hostname in (Get-Content C:\\path to our txt file with hostnames)) { Invoke-ForceEvaluation $hostname } If you need to call it on a single machine, you can take out the foreach loop and call the function by itself passing a single hostname.\nTo clarify, this script will evaluate every baseline that is assigned to the target machine. Ensure that you know what baselines are going to run prior to running this to avoid unexpected results.\nIf you\u0026rsquo;d like to know more about SCCM or how to do something that I haven\u0026rsquo;t covered, please let me know in the comments.\n","permalink":"http://localhost:1313/powershell-force-compliance-baseline-evaluation/","summary":"SCCM Compliance rule evaluation for a new rule can sometimes be slow or maybe you just need to manually evaluate compliance baselines or rules on a machine or group of machines.\nRegardless of your reasoning, the PowerShell script below can help you achieve the goal of manually and remotely kicking off SCCM compliance rule evaluations.\nTo make this reusable in the future, we will create a simple function that we can call along with a hostname to do the dirty work for us.","title":"PowerShell Force Compliance Baseline Evaluation"},{"content":"It\u0026rsquo;s common when building a backend to access a database for API\u0026rsquo;s and other situations. Luckily with Python, there is an easy module for accessing a MySQL database to make queries. This post will show you how to use MySQL in Flask so that you can use databases in your app easily.\nInstall MySQL Package for Python Flask To install the required Python package for working with a MySQL database in Flask, we will use \u0026ldquo;pip\u0026rdquo;. I recommend doing this from a virtual environment, if you need help with that check out my post on setting up a Python Virtual Environment. The package that we want to install is called, flask-mysql-connector. This package will handle the communication between Flask and the MySQL database.\npip install flask-mysql-connector Next, we need to set up some environment variables to store the connection information.\nCheck out our post on setting up a Python Flask app on a production LiteSpeed Server.\nInstall Python-DotEnv We want to install the python-dotenv package so we can store our MySQL variables outside of our code. By storing our MySQL database connection details in a separate file provides a bit more security and gives us a central place to edit them in the future.\npip install python-dotenv Once this is installed, now we can create a .env file to hold these important variables to later access within our code. In your .env file include the lines below, replacing the values with your database details:\nDBHOST=localhost DBNAME=database_name DBUSER=username DBPASS=password Connect to a MySQL Database using Python Flask Now inside our Flask app where we want to connect to the MySQL database, we need to add a few imports at the top as follows. We will first import the dotenv and os packages so we can access our MySQL variables in the .env file. Next, we will import the flask mysql package to handle the MySQL database communication.\nfrom dotenv import load_env import os from flask_mysql_connector import MySQL Now that we have the imports taken care of, we can make a connection and query.\nFirst, let\u0026rsquo;s pull in the variables we created in the .env file.\napp.config[\u0026#39;MYSQL_USER\u0026#39;] = os.getenv(\u0026#39;DBUSER\u0026#39;) app.config[\u0026#39;MYSQL_DATABASE\u0026#39;] = os.getenv(\u0026#39;DBNAME\u0026#39;) app.config[\u0026#39;MYSQL_HOST\u0026#39;] = os.getenv(\u0026#39;DBHOST\u0026#39;) app.config[\u0026#39;MYSQL_PASSWORD\u0026#39;] = os.getenv(\u0026#39;DBPASS\u0026#39;) Next, we will initialize MySQL into our app by calling MySQL and passing in our app.\nmysql = MySQL(app) Now we have our variables set up and MySQL initialized in our app, we can set up a query.\nExample MySQL Flask Query Here we setup a sample query and tell Flask to connect with our MySQL database for the query.\nSAMPLE_QUERY = \u0026#39;select * from table_name where column_name=\u0026#34;some_value\u0026#34;\u0026#39; @app.route(\u0026#39;/db_test\u0026#39;) def db_test(): conn = mysql.connection cur = conn.cursor() cur.execute(SAMPLE_QUERY) output = cur.fetchall() return str(output) Nice, you\u0026rsquo;ve made your first MySQL query from your Python Flask app! Congrats! You can navigate to http://localhost:5000/db_test in your browser to see the output once you run your Flask app.\nIf you would like to know more or see a specific example, let me know in the comments!\n","permalink":"http://localhost:1313/use-mysql-in-python-flask/","summary":"It\u0026rsquo;s common when building a backend to access a database for API\u0026rsquo;s and other situations. Luckily with Python, there is an easy module for accessing a MySQL database to make queries. This post will show you how to use MySQL in Flask so that you can use databases in your app easily.\nInstall MySQL Package for Python Flask To install the required Python package for working with a MySQL database in Flask, we will use \u0026ldquo;pip\u0026rdquo;.","title":"MySQL and Flask Tutorial"},{"content":"Why Use VirtualEnv? Virtualenv allows you to separate specific packages from one project to another. This guide will show you how to easily install virtualenv on Arch Linux. Using Virtualenv allows for easier collaboration and prevents you from having issues with globally installed python packages.\nImagine you have project A that needs a specific version of a package and project B that needs a different version. By using virtualenv, you can have those specific packages installed for each project and keep them separated.\nSetup First, create a directory for your project and then cd into that directory.\nInstall Virtualenv Note: If you\u0026rsquo;re using Python 3.3 or newer, you do not need to do this since venv is included as part of the base packages.\npip install virtualenv Create a Python Virtual Environment Depending on how you installed it and what version you have, one of the following commands will create a new virtual environment called venv.\npython -m venv venv python3 -m venv venv virtualenv venv Activate the Virtual Environment Now that you have the virtual environment created, we still need to activate virtualenv in order to make use of the environment to install our packages.\n. venv/bin/activate After completing this step, you will notice that your terminal changes. Some will place (env) or (venv) at the beginning of your terminal line. Other terminals and terminal modifications may have different indications but something will change to indicate that you are now in the virtual environment.\nAt this point, you can proceed to install pip packages and they will be specific to this project.\npip install Flask Exit the Python Virtual Environment In case you need to leave or deactivate the virtualenv environment run the following command.\ndeactivate That\u0026rsquo;s it, now that you\u0026rsquo;re ready to start coding, check out our guide on installing VS Code for Manjaro Linux. If you have any questions or would like more information, please let me know in the comments.\n","permalink":"http://localhost:1313/install-virtualenv-on-arch-linux-for-python/","summary":"Why Use VirtualEnv? Virtualenv allows you to separate specific packages from one project to another. This guide will show you how to easily install virtualenv on Arch Linux. Using Virtualenv allows for easier collaboration and prevents you from having issues with globally installed python packages.\nImagine you have project A that needs a specific version of a package and project B that needs a different version. By using virtualenv, you can have those specific packages installed for each project and keep them separated.","title":"3 Easy Steps: Install VirtualEnv on Arch Linux for Python"},{"content":"Recently, I found myself needing to change the boot order of a VM in System Center Virtual Machine Manager. However, I couldn\u0026rsquo;t find an option to alter the boot order within the GUI properties of SCVMM.\nIt seems that the preferred method for changing the boot order for SCVMM\u0026rsquo;s is to use PowerShell.\nFor my use case, I needed to make the NIC the first boot device, as it turns out it\u0026rsquo;s pretty simple to do this. By doing the following, I made my NIC default, allowing me to PXE boot to SCCM for task sequencing.\nOpen up a PowerShell terminal\nFirst, we need to set a variable for the exact VM we want to modify.\n$VM = GetSCVirtualMachine -Name \u0026#34;name of your vm with the quotes\u0026#34; Next, we tell SCVMM to change the first boot device for this VM.\nSet-SCVirtualMachine -VM $VM -FirstBootDevice \u0026#34;NIC,0\u0026#34; That\u0026rsquo;s it, now the VM will boot to the network device first until it\u0026rsquo;s changed again. If you need to boot to the hard disk first, you could use SCSI,0,0 instead of NIC,0. Also note, you may need to change the numbers to match your specific VM.\n","permalink":"http://localhost:1313/scvmm-gen2-vm-change-boot-order/","summary":"Recently, I found myself needing to change the boot order of a VM in System Center Virtual Machine Manager. However, I couldn\u0026rsquo;t find an option to alter the boot order within the GUI properties of SCVMM.\nIt seems that the preferred method for changing the boot order for SCVMM\u0026rsquo;s is to use PowerShell.\nFor my use case, I needed to make the NIC the first boot device, as it turns out it\u0026rsquo;s pretty simple to do this.","title":"SCVMM Gen2 VM Change Boot Order"},{"content":"Send me a message\n","permalink":"http://localhost:1313/contact/","summary":"Send me a message","title":"Contact"}]